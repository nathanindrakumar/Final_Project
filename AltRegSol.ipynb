{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime, date, timedelta\n",
    "import torch\n",
    "import skorch\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from skorch.helper import DataFrameTransformer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "def identity_tokenizer(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "premium-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_train.txt\", \"rb\") as fp:   # Unpickling\n",
    "    x_train = pickle.load(fp)\n",
    "with open(\"y_train.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_train = pickle.load(fp)\n",
    "with open(\"x_test.txt\", \"rb\") as fp:   # Unpickling\n",
    "    x_test = pickle.load(fp)\n",
    "with open(\"y_test.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_test = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-eugene",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tamil-group",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-efbca8d0d68b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n\u001b[1;32m-> 1347\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    181\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    182\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, stop_words=\"english\",token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"log_model\", log_model)])\n",
    "\n",
    "\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-video",
   "metadata": {},
   "source": [
    "### Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "super-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.0633279672117206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_model = LinearRegression()\n",
    "\n",
    "\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"lin_model\", lin_model)])\n",
    "\n",
    "\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-wildlife",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "guided-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.9896362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge()\n",
    "\n",
    "\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"ridge_model\", ridge_model)])\n",
    "\n",
    "\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "suited-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-05 1.38949549e-05 1.93069773e-05 2.68269580e-05\n",
      " 3.72759372e-05 5.17947468e-05 7.19685673e-05 1.00000000e-04\n",
      " 1.38949549e-04 1.93069773e-04 2.68269580e-04 3.72759372e-04\n",
      " 5.17947468e-04 7.19685673e-04 1.00000000e-03 1.38949549e-03\n",
      " 1.93069773e-03 2.68269580e-03 3.72759372e-03 5.17947468e-03\n",
      " 7.19685673e-03 1.00000000e-02 1.38949549e-02 1.93069773e-02\n",
      " 2.68269580e-02 3.72759372e-02 5.17947468e-02 7.19685673e-02\n",
      " 1.00000000e-01 1.38949549e-01 1.93069773e-01 2.68269580e-01\n",
      " 3.72759372e-01 5.17947468e-01 7.19685673e-01 1.00000000e+00\n",
      " 1.38949549e+00 1.93069773e+00 2.68269580e+00 3.72759372e+00\n",
      " 5.17947468e+00 7.19685673e+00 1.00000000e+01 1.38949549e+01\n",
      " 1.93069773e+01 2.68269580e+01 3.72759372e+01 5.17947468e+01\n",
      " 7.19685673e+01 1.00000000e+02]\n"
     ]
    }
   ],
   "source": [
    "rangelist = np.logspace(-5, 2, 50)\n",
    "print(rangelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "reliable-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05 RMSE: 2.0167823\n",
      "1.3894954943731388e-05 RMSE: 2.0132132\n",
      "1.9306977288832496e-05 RMSE: 2.0154734\n",
      "2.6826957952797274e-05 RMSE: 2.0137775\n",
      "3.727593720314938e-05 RMSE: 2.0124006\n",
      "5.1794746792312125e-05 RMSE: 2.0130188\n",
      "7.196856730011514e-05 RMSE: 2.0124938\n",
      "0.0001 RMSE: 2.0127099\n",
      "0.00013894954943731373 RMSE: 2.0120583\n",
      "0.00019306977288832496 RMSE: 2.012334\n",
      "0.00026826957952797245 RMSE: 2.010891\n",
      "0.0003727593720314938 RMSE: 2.0105393\n",
      "0.0005179474679231213 RMSE: 2.0092287\n",
      "0.0007196856730011514 RMSE: 2.0082896\n",
      "0.001 RMSE: 2.006572\n",
      "0.0013894954943731374 RMSE: 2.005066\n",
      "0.0019306977288832496 RMSE: 2.003894\n",
      "0.0026826957952797246 RMSE: 2.0026326\n",
      "0.003727593720314938 RMSE: 2.0013375\n",
      "0.005179474679231208 RMSE: 2.0005932\n",
      "0.007196856730011514 RMSE: 1.9993536\n",
      "0.01 RMSE: 1.9985099\n",
      "0.013894954943731374 RMSE: 1.9977165\n",
      "0.019306977288832496 RMSE: 1.9968549\n",
      "0.026826957952797246 RMSE: 1.9960574\n",
      "0.03727593720314938 RMSE: 1.9952542\n",
      "0.05179474679231207 RMSE: 1.9945084\n",
      "0.07196856730011514 RMSE: 1.9937649\n",
      "0.1 RMSE: 1.9930938\n",
      "0.1389495494373136 RMSE: 1.9924332\n",
      "0.19306977288832497 RMSE: 1.9918381\n",
      "0.2682695795279722 RMSE: 1.9912937\n",
      "0.3727593720314938 RMSE: 1.990797\n",
      "0.5179474679231213 RMSE: 1.9903396\n",
      "0.7196856730011514 RMSE: 1.9899566\n",
      "1.0 RMSE: 1.9896362\n",
      "1.389495494373136 RMSE: 1.9893991\n",
      "1.9306977288832496 RMSE: 1.989253\n",
      "2.682695795279722 RMSE: 1.9892164\n",
      "3.727593720314938 RMSE: 1.9893041\n",
      "5.179474679231202 RMSE: 1.9895322\n",
      "7.196856730011514 RMSE: 1.989927\n",
      "10.0 RMSE: 1.9905114\n",
      "13.89495494373136 RMSE: 1.9913126\n",
      "19.306977288832496 RMSE: 1.9923579\n",
      "26.82695795279722 RMSE: 1.9936781\n",
      "37.27593720314938 RMSE: 1.9953086\n",
      "51.79474679231202 RMSE: 1.9972768\n",
      "71.96856730011514 RMSE: 1.9996157\n",
      "100.0 RMSE: 2.0023465\n",
      "Optimum parameters: 2.682695795279722 : 1.9892164\n"
     ]
    }
   ],
   "source": [
    "rmselist = []\n",
    "for r in rangelist:\n",
    "    ridge_model = Ridge(alpha = r)\n",
    "\n",
    "\n",
    "    def typechange(x):\n",
    "        return x.astype(dtype = np.float32)\n",
    "    typetransform = FunctionTransformer(typechange)\n",
    "\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"ridge_model\", ridge_model)])\n",
    "\n",
    "\n",
    "    pipe.fit(X=x_train, y=y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(r,'RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "    \n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", rangelist[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-thanksgiving",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "subject-boost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.0521414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_model = Lasso()\n",
    "\n",
    "\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"lasso_model\", lasso_model)])\n",
    "\n",
    "\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-documentary",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "naughty-hybrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.0521414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "ElasticNet_model = ElasticNet()\n",
    "\n",
    "\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, stop_words=\"english\",token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"ElasticNet_model\", ElasticNet_model)])\n",
    "\n",
    "\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-artwork",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataSciEnv]",
   "language": "python",
   "name": "conda-env-DataSciEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
