{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dying-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime, date, timedelta\n",
    "import torch\n",
    "import skorch\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from skorch.helper import DataFrameTransformer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skorch import NeuralNetRegressor\n",
    "import pickle\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "floral-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>Date</th>\n",
       "      <th>time</th>\n",
       "      <th>usedate</th>\n",
       "      <th>usedate1</th>\n",
       "      <th>usedate2</th>\n",
       "      <th>usedate3</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change1</th>\n",
       "      <th>Change2</th>\n",
       "      <th>Change3</th>\n",
       "      <th>Change4</th>\n",
       "      <th>Change5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1147845</th>\n",
       "      <td>2020 is almost ended\\n\\nBRAND NEW SEALED FACTO...</td>\n",
       "      <td>1.317031e+18</td>\n",
       "      <td>1317047077411737601</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>10:17:47</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>...</td>\n",
       "      <td>115393800.0</td>\n",
       "      <td>121.2800</td>\n",
       "      <td>121.5480</td>\n",
       "      <td>118.810</td>\n",
       "      <td>-2.260</td>\n",
       "      <td>-3.980</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.7000</td>\n",
       "      <td>-1.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318305</th>\n",
       "      <td>If you feel like Apple has no love for you by ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1361013406829060106</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>18:04:17</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>...</td>\n",
       "      <td>80576320.0</td>\n",
       "      <td>135.4900</td>\n",
       "      <td>136.0100</td>\n",
       "      <td>132.790</td>\n",
       "      <td>-2.300</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-2.0100</td>\n",
       "      <td>2.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772897</th>\n",
       "      <td>üì¢NEW RIP IS LIVEüì¢\\n\\n2W1B 051 - iPhone, Capita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1318150624626790402</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>11:22:53</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>...</td>\n",
       "      <td>120639300.0</td>\n",
       "      <td>119.9600</td>\n",
       "      <td>120.4190</td>\n",
       "      <td>115.660</td>\n",
       "      <td>-3.980</td>\n",
       "      <td>1.310</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-1.3500</td>\n",
       "      <td>1.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952614</th>\n",
       "      <td>#Apple has introduced a new #macOS version of ...</td>\n",
       "      <td>1.272588e+18</td>\n",
       "      <td>1272595399673630722</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>18:22:41</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>...</td>\n",
       "      <td>138808920.0</td>\n",
       "      <td>83.3125</td>\n",
       "      <td>86.4200</td>\n",
       "      <td>83.145</td>\n",
       "      <td>2.435</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.2287</td>\n",
       "      <td>1.8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33341</th>\n",
       "      <td>Good Dealüòç #MacBookPro #AppleEvent #Apple\\n\\nN...</td>\n",
       "      <td>1.389114e+18</td>\n",
       "      <td>1389114470304305154</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>07:07:52</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>...</td>\n",
       "      <td>75135100.0</td>\n",
       "      <td>132.0400</td>\n",
       "      <td>134.0700</td>\n",
       "      <td>131.830</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-3.340</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-0.6400</td>\n",
       "      <td>-2.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169957</th>\n",
       "      <td>Foreign Exchange History: How it All Started?\\...</td>\n",
       "      <td>1.316240e+18</td>\n",
       "      <td>1316312507431051264</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>09:38:52</td>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>...</td>\n",
       "      <td>151062300.0</td>\n",
       "      <td>121.0000</td>\n",
       "      <td>123.0300</td>\n",
       "      <td>119.620</td>\n",
       "      <td>0.190</td>\n",
       "      <td>1.990</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-3.98</td>\n",
       "      <td>1.3100</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531839</th>\n",
       "      <td>Tropicana Apple Juice, 10 oz., 24 Count\\n\\nSta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1339593079318200320</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>15:27:33</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>...</td>\n",
       "      <td>94359810.0</td>\n",
       "      <td>128.9000</td>\n",
       "      <td>129.5800</td>\n",
       "      <td>128.045</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-2.305</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-1.2000</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305376</th>\n",
       "      <td>\"emotional conclusion to a dazzling series!\"\\n...</td>\n",
       "      <td>1.303296e+18</td>\n",
       "      <td>1307074421098766336</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>21:50:00</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>...</td>\n",
       "      <td>287104900.0</td>\n",
       "      <td>110.4000</td>\n",
       "      <td>110.8800</td>\n",
       "      <td>106.090</td>\n",
       "      <td>-3.560</td>\n",
       "      <td>5.540</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>3.0500</td>\n",
       "      <td>3.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266310</th>\n",
       "      <td>3ÔºÖË∂Ö‰∏äÊòá„Åó„ÅüÈäòÊüÑ\\n4434  „Çµ„Éº„Éê„Éº„ÉØ„Éº„ÇØ„Çπ\\n4625  „Ç¢„Éà„Éü„ÇØ„Çπ\\n6777  ...</td>\n",
       "      <td>1.311853e+18</td>\n",
       "      <td>1311853293589725184</td>\n",
       "      <td>ja</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>02:19:32</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>...</td>\n",
       "      <td>144712000.0</td>\n",
       "      <td>112.8900</td>\n",
       "      <td>115.3700</td>\n",
       "      <td>112.220</td>\n",
       "      <td>0.130</td>\n",
       "      <td>2.590</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-1.2800</td>\n",
       "      <td>1.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634525</th>\n",
       "      <td>EP 42: @seanmagers and @keithrconrad discuss t...</td>\n",
       "      <td>1.346227e+18</td>\n",
       "      <td>1346226671293243393</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>22:47:04</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>143301900.0</td>\n",
       "      <td>133.5200</td>\n",
       "      <td>133.6116</td>\n",
       "      <td>126.760</td>\n",
       "      <td>-4.110</td>\n",
       "      <td>2.120</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-0.3800</td>\n",
       "      <td>-0.2100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508182 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  referenced_tweets  \\\n",
       "1147845  2020 is almost ended\\n\\nBRAND NEW SEALED FACTO...       1.317031e+18   \n",
       "2318305  If you feel like Apple has no love for you by ...                NaN   \n",
       "2772897  üì¢NEW RIP IS LIVEüì¢\\n\\n2W1B 051 - iPhone, Capita...                NaN   \n",
       "1952614  #Apple has introduced a new #macOS version of ...       1.272588e+18   \n",
       "33341    Good Dealüòç #MacBookPro #AppleEvent #Apple\\n\\nN...       1.389114e+18   \n",
       "...                                                    ...                ...   \n",
       "1169957  Foreign Exchange History: How it All Started?\\...       1.316240e+18   \n",
       "2531839  Tropicana Apple Juice, 10 oz., 24 Count\\n\\nSta...                NaN   \n",
       "1305376  \"emotional conclusion to a dazzling series!\"\\n...       1.303296e+18   \n",
       "1266310  3ÔºÖË∂Ö‰∏äÊòá„Åó„ÅüÈäòÊüÑ\\n4434  „Çµ„Éº„Éê„Éº„ÉØ„Éº„ÇØ„Çπ\\n4625  „Ç¢„Éà„Éü„ÇØ„Çπ\\n6777  ...       1.311853e+18   \n",
       "634525   EP 42: @seanmagers and @keithrconrad discuss t...       1.346227e+18   \n",
       "\n",
       "                          id lang        Date      time     usedate  \\\n",
       "1147845  1317047077411737601   en  2020-10-16  10:17:47  2020-10-16   \n",
       "2318305  1361013406829060106   en  2021-02-14  18:04:17  2021-02-16   \n",
       "2772897  1318150624626790402   en  2020-10-19  11:22:53  2020-10-19   \n",
       "1952614  1272595399673630722   en  2020-06-15  18:22:41  2020-06-15   \n",
       "33341    1389114470304305154   en  2021-05-03  07:07:52  2021-05-03   \n",
       "...                      ...  ...         ...       ...         ...   \n",
       "1169957  1316312507431051264   en  2020-10-14  09:38:52  2020-10-14   \n",
       "2531839  1339593079318200320   en  2020-12-17  15:27:33  2020-12-17   \n",
       "1305376  1307074421098766336   en  2020-09-18  21:50:00  2020-09-18   \n",
       "1266310  1311853293589725184   ja  2020-10-02  02:19:32  2020-10-02   \n",
       "634525   1346226671293243393   en  2021-01-04  22:47:04  2021-01-04   \n",
       "\n",
       "           usedate1    usedate2    usedate3  ...       Volume      Open  \\\n",
       "1147845  2020-10-19  2020-10-20  2020-10-21  ...  115393800.0  121.2800   \n",
       "2318305  2021-02-17  2021-02-18  2021-02-19  ...   80576320.0  135.4900   \n",
       "2772897  2020-10-20  2020-10-21  2020-10-22  ...  120639300.0  119.9600   \n",
       "1952614  2020-06-16  2020-06-17  2020-06-18  ...  138808920.0   83.3125   \n",
       "33341    2021-05-04  2021-05-05  2021-05-06  ...   75135100.0  132.0400   \n",
       "...             ...         ...         ...  ...          ...       ...   \n",
       "1169957  2020-10-15  2020-10-16  2020-10-19  ...  151062300.0  121.0000   \n",
       "2531839  2020-12-18  2020-12-21  2020-12-22  ...   94359810.0  128.9000   \n",
       "1305376  2020-09-21  2020-09-22  2020-09-23  ...  287104900.0  110.4000   \n",
       "1266310  2020-10-05  2020-10-06  2020-10-07  ...  144712000.0  112.8900   \n",
       "634525   2021-01-05  2021-01-06  2021-01-07  ...  143301900.0  133.5200   \n",
       "\n",
       "             High      Low  Change  Change1  Change2  Change3  Change4  \\\n",
       "1147845  121.5480  118.810  -2.260   -3.980     1.31     0.20  -1.7000   \n",
       "2318305  136.0100  132.790  -2.300   -0.410     0.51    -0.37  -2.0100   \n",
       "2772897  120.4190  115.660  -3.980    1.310     0.20    -1.70  -1.3500   \n",
       "1952614   86.4200   83.145   2.435    0.155    -0.89     0.08  -1.2287   \n",
       "33341    134.0700  131.830   0.500   -3.340    -1.10     1.85  -0.6400   \n",
       "...           ...      ...     ...      ...      ...      ...      ...   \n",
       "1169957  123.0300  119.620   0.190    1.990    -2.26    -3.98   1.3100   \n",
       "2531839  129.5800  128.045  -0.200   -2.305     3.21     0.27  -1.2000   \n",
       "1305376  110.8800  106.090  -3.560    5.540    -0.87    -4.50   3.0500   \n",
       "1266310  115.3700  112.220   0.130    2.590    -2.54     0.46  -1.2800   \n",
       "634525   133.6116  126.760  -4.110    2.120    -1.12     2.56  -0.3800   \n",
       "\n",
       "         Change5  \n",
       "1147845  -1.3500  \n",
       "2318305   2.1000  \n",
       "2772897   1.0400  \n",
       "1952614   1.8825  \n",
       "33341    -2.5600  \n",
       "...          ...  \n",
       "1169957   0.2000  \n",
       "2531839   0.6500  \n",
       "1305376   3.8500  \n",
       "1266310   1.6900  \n",
       "634525   -0.2100  \n",
       "\n",
       "[508182 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv('mergedfullwithmoredates.csv')\n",
    "from sklearn.model_selection import train_test_split  \n",
    "mergedbig, mergedsmall = train_test_split(merged, test_size=0.15, random_state=0)\n",
    "# mergedsmall.to_csv(\"mergedsmall.csv\", index = False)\n",
    "# mergedsmall = pd.read_csv('mergedsmall.csv')\n",
    "merged = mergedsmall\n",
    "merged.dropna()\n",
    "# Obtaining the tweet contents into a list\n",
    "all_tweets = merged[\"text\"]\n",
    "all_tweets = all_tweets.to_list()\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemming(tweet):\n",
    "    a = word_tokenize(tweet)\n",
    "    answer = list(map(lambda x: lemmatizer.lemmatize(x), a))\n",
    "    return answer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "crude-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "processed_tweets = []\n",
    "X = all_tweets\n",
    "for tweet in range(0, len(X)):  \n",
    "    \n",
    "\n",
    "    processed_tweet = re.sub(r\"http\\S+\", \"\", str(X[tweet]))\n",
    "\n",
    "    # Remove all the special characters\n",
    "    processed_tweet = re.sub(r'\\W', ' ', processed_tweet)\n",
    "    \n",
    "#     processed_tweet = re.sub(r'http\\S+', '', processed_tweet)\n",
    "    \n",
    "    \n",
    "#     processed_tweet = re.sub(r'co\\S+', '', processed_tweet) \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    " \n",
    "    # Remove single characters from the start\n",
    "#     processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet) \n",
    " \n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    " \n",
    "    # Removing prefixed 'b'\n",
    "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "    \n",
    "\n",
    "    \n",
    "    processed_tweet = re.sub(r'of|to|has|keep|ll', '', processed_tweet)\n",
    "    # Converting to Lowercase\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "    \n",
    "    processed_tweet = lemming(processed_tweet)\n",
    "    \n",
    "    processed_tweet = [word for word in processed_tweet if word not in stop_words]\n",
    "    \n",
    "    processed_tweet = TreebankWordDetokenizer().detokenize(processed_tweet)    \n",
    "    \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    processed_tweets.append(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "pointed-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged[['Change','Change1','Change2','Change3','Change4','Change5']]\n",
    "# X = df3\n",
    "# X = df2\n",
    "# X = df2array\n",
    "X = processed_tweets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "naval-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.1885\u001b[0m        \u001b[32m4.1607\u001b[0m  75.4138\n",
      "      2        \u001b[36m4.0550\u001b[0m        \u001b[32m4.1116\u001b[0m  71.8156\n",
      "      3        \u001b[36m4.0135\u001b[0m        \u001b[32m4.0859\u001b[0m  72.1005\n",
      "      4        \u001b[36m3.9949\u001b[0m        \u001b[32m4.0711\u001b[0m  70.5459\n",
      "      5        \u001b[36m3.9805\u001b[0m        \u001b[32m4.0484\u001b[0m  69.9495\n",
      "      6        \u001b[36m3.9659\u001b[0m        \u001b[32m4.0260\u001b[0m  70.4210\n",
      "      7        \u001b[36m3.9482\u001b[0m        \u001b[32m3.9760\u001b[0m  70.6778\n",
      "      8        \u001b[36m3.9278\u001b[0m        \u001b[32m3.9615\u001b[0m  70.7877\n",
      "      9        \u001b[36m3.9142\u001b[0m        \u001b[32m3.9526\u001b[0m  69.0504\n",
      "     10        \u001b[36m3.9045\u001b[0m        \u001b[32m3.9453\u001b[0m  74.5129\n",
      "Change RMSE: 1.9767237\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1           nan           nan  69.1494\n",
      "      2           nan           nan  69.5809\n",
      "      3           nan           nan  69.0235\n",
      "      4           nan           nan  69.0874\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-cea7f9e9b4c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlists\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"RMSE:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;36m0.825\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \"\"\"\n\u001b[1;32m--> 335\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    336\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    337\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \"\"\"\n\u001b[0;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "\n",
    "lists = ['Change','Change1','Change2','Change3','Change4','Change5']\n",
    "for pred in range(len(lists)):\n",
    "    y_train2 = y_train.iloc[:,pred]\n",
    "    y_test2 = y_test.iloc[:,pred]\n",
    "    y_train2 = y_train2.values.reshape(-1,1)\n",
    "    y_test2 = y_test2.values.reshape(-1,1)\n",
    "    y_train2 = y_train2.astype(np.float32)\n",
    "    y_test2 = y_test2.astype(np.float32)\n",
    "    in_dimension = 5844\n",
    "    hid_dimension = 10\n",
    "    out_dimension = 1\n",
    "\n",
    "\n",
    "    class PoleNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(PoleNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_dimension,hid_dimension)\n",
    "            self.fc2 = nn.Linear(hid_dimension,out_dimension)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        def forward(self, X):\n",
    "            hidden = self.fc1(X)\n",
    "            hidden = self.sigmoid(hidden)\n",
    "            output = self.fc2(hidden)\n",
    "            return output\n",
    "\n",
    "    from skorch import NeuralNetRegressor\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    x_trainshape = 5844\n",
    "    class RegressorModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                num_units=10,\n",
    "                nonlin=F.relu,\n",
    "        ):\n",
    "            super(RegressorModule, self).__init__()\n",
    "            self.num_units = num_units\n",
    "            self.nonlin = nonlin\n",
    "\n",
    "            self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "            self.nonlin = nonlin\n",
    "            self.dense1 = nn.Linear(num_units, 10)\n",
    "            self.output = nn.Linear(10, 1)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = self.nonlin(self.dense0(X))\n",
    "            X = F.relu(self.dense1(X))\n",
    "            X = self.output(X)\n",
    "            return X\n",
    "\n",
    "    pole_model = RegressorModule()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(pole_model.parameters(), lr = 0.1)\n",
    "\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=10, lr=0.1, callbacks =[('earlystopping',EarlyStopping())])\n",
    "    def typechange(x):\n",
    "        return x.astype(dtype = np.float32)\n",
    "    typetransform = FunctionTransformer(typechange)\n",
    "    def inputneuron(x):\n",
    "        x_trainshape = x.shape[1]\n",
    "    #     return x_trainshape\n",
    "    inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "    # pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "    # pipe = Pipeline([('net', net)])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "    # net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "    pipe.fit(X=x_train, y=y_train2)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    rmse = mean_squared_error(y_test2, y_pred, squared = False)\n",
    "    print(lists[pred], \"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-terry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataSciEnv]",
   "language": "python",
   "name": "conda-env-DataSciEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
