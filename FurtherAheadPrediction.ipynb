{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "arctic-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime, date, timedelta\n",
    "import torch\n",
    "import skorch\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from skorch.helper import DataFrameTransformer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skorch import NeuralNetRegressor\n",
    "import pickle\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "conditional-enterprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>Date</th>\n",
       "      <th>time</th>\n",
       "      <th>usedate</th>\n",
       "      <th>usedate1</th>\n",
       "      <th>usedate2</th>\n",
       "      <th>usedate3</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change1</th>\n",
       "      <th>Change2</th>\n",
       "      <th>Change3</th>\n",
       "      <th>Change4</th>\n",
       "      <th>Change5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1147845</th>\n",
       "      <td>2020 is almost ended\\n\\nBRAND NEW SEALED FACTO...</td>\n",
       "      <td>1.317031e+18</td>\n",
       "      <td>1317047077411737601</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>10:17:47</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>...</td>\n",
       "      <td>115393800.0</td>\n",
       "      <td>121.2800</td>\n",
       "      <td>121.5480</td>\n",
       "      <td>118.810</td>\n",
       "      <td>-2.260</td>\n",
       "      <td>-3.980</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.7000</td>\n",
       "      <td>-1.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318305</th>\n",
       "      <td>If you feel like Apple has no love for you by ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1361013406829060106</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>18:04:17</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>...</td>\n",
       "      <td>80576320.0</td>\n",
       "      <td>135.4900</td>\n",
       "      <td>136.0100</td>\n",
       "      <td>132.790</td>\n",
       "      <td>-2.300</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-2.0100</td>\n",
       "      <td>2.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772897</th>\n",
       "      <td>üì¢NEW RIP IS LIVEüì¢\\n\\n2W1B 051 - iPhone, Capita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1318150624626790402</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>11:22:53</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>...</td>\n",
       "      <td>120639300.0</td>\n",
       "      <td>119.9600</td>\n",
       "      <td>120.4190</td>\n",
       "      <td>115.660</td>\n",
       "      <td>-3.980</td>\n",
       "      <td>1.310</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-1.3500</td>\n",
       "      <td>1.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952614</th>\n",
       "      <td>#Apple has introduced a new #macOS version of ...</td>\n",
       "      <td>1.272588e+18</td>\n",
       "      <td>1272595399673630722</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>18:22:41</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>...</td>\n",
       "      <td>138808920.0</td>\n",
       "      <td>83.3125</td>\n",
       "      <td>86.4200</td>\n",
       "      <td>83.145</td>\n",
       "      <td>2.435</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.2287</td>\n",
       "      <td>1.8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33341</th>\n",
       "      <td>Good Dealüòç #MacBookPro #AppleEvent #Apple\\n\\nN...</td>\n",
       "      <td>1.389114e+18</td>\n",
       "      <td>1389114470304305154</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>07:07:52</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>...</td>\n",
       "      <td>75135100.0</td>\n",
       "      <td>132.0400</td>\n",
       "      <td>134.0700</td>\n",
       "      <td>131.830</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-3.340</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-0.6400</td>\n",
       "      <td>-2.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169957</th>\n",
       "      <td>Foreign Exchange History: How it All Started?\\...</td>\n",
       "      <td>1.316240e+18</td>\n",
       "      <td>1316312507431051264</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>09:38:52</td>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>...</td>\n",
       "      <td>151062300.0</td>\n",
       "      <td>121.0000</td>\n",
       "      <td>123.0300</td>\n",
       "      <td>119.620</td>\n",
       "      <td>0.190</td>\n",
       "      <td>1.990</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-3.98</td>\n",
       "      <td>1.3100</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531839</th>\n",
       "      <td>Tropicana Apple Juice, 10 oz., 24 Count\\n\\nSta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1339593079318200320</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>15:27:33</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>...</td>\n",
       "      <td>94359810.0</td>\n",
       "      <td>128.9000</td>\n",
       "      <td>129.5800</td>\n",
       "      <td>128.045</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-2.305</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-1.2000</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305376</th>\n",
       "      <td>\"emotional conclusion to a dazzling series!\"\\n...</td>\n",
       "      <td>1.303296e+18</td>\n",
       "      <td>1307074421098766336</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>21:50:00</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>...</td>\n",
       "      <td>287104900.0</td>\n",
       "      <td>110.4000</td>\n",
       "      <td>110.8800</td>\n",
       "      <td>106.090</td>\n",
       "      <td>-3.560</td>\n",
       "      <td>5.540</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>3.0500</td>\n",
       "      <td>3.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266310</th>\n",
       "      <td>3ÔºÖË∂Ö‰∏äÊòá„Åó„ÅüÈäòÊüÑ\\n4434  „Çµ„Éº„Éê„Éº„ÉØ„Éº„ÇØ„Çπ\\n4625  „Ç¢„Éà„Éü„ÇØ„Çπ\\n6777  ...</td>\n",
       "      <td>1.311853e+18</td>\n",
       "      <td>1311853293589725184</td>\n",
       "      <td>ja</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>02:19:32</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>...</td>\n",
       "      <td>144712000.0</td>\n",
       "      <td>112.8900</td>\n",
       "      <td>115.3700</td>\n",
       "      <td>112.220</td>\n",
       "      <td>0.130</td>\n",
       "      <td>2.590</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-1.2800</td>\n",
       "      <td>1.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634525</th>\n",
       "      <td>EP 42: @seanmagers and @keithrconrad discuss t...</td>\n",
       "      <td>1.346227e+18</td>\n",
       "      <td>1346226671293243393</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>22:47:04</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>143301900.0</td>\n",
       "      <td>133.5200</td>\n",
       "      <td>133.6116</td>\n",
       "      <td>126.760</td>\n",
       "      <td>-4.110</td>\n",
       "      <td>2.120</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-0.3800</td>\n",
       "      <td>-0.2100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501281 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  referenced_tweets  \\\n",
       "1147845  2020 is almost ended\\n\\nBRAND NEW SEALED FACTO...       1.317031e+18   \n",
       "2318305  If you feel like Apple has no love for you by ...                NaN   \n",
       "2772897  üì¢NEW RIP IS LIVEüì¢\\n\\n2W1B 051 - iPhone, Capita...                NaN   \n",
       "1952614  #Apple has introduced a new #macOS version of ...       1.272588e+18   \n",
       "33341    Good Dealüòç #MacBookPro #AppleEvent #Apple\\n\\nN...       1.389114e+18   \n",
       "...                                                    ...                ...   \n",
       "1169957  Foreign Exchange History: How it All Started?\\...       1.316240e+18   \n",
       "2531839  Tropicana Apple Juice, 10 oz., 24 Count\\n\\nSta...                NaN   \n",
       "1305376  \"emotional conclusion to a dazzling series!\"\\n...       1.303296e+18   \n",
       "1266310  3ÔºÖË∂Ö‰∏äÊòá„Åó„ÅüÈäòÊüÑ\\n4434  „Çµ„Éº„Éê„Éº„ÉØ„Éº„ÇØ„Çπ\\n4625  „Ç¢„Éà„Éü„ÇØ„Çπ\\n6777  ...       1.311853e+18   \n",
       "634525   EP 42: @seanmagers and @keithrconrad discuss t...       1.346227e+18   \n",
       "\n",
       "                          id lang        Date      time     usedate  \\\n",
       "1147845  1317047077411737601   en  2020-10-16  10:17:47  2020-10-16   \n",
       "2318305  1361013406829060106   en  2021-02-14  18:04:17  2021-02-16   \n",
       "2772897  1318150624626790402   en  2020-10-19  11:22:53  2020-10-19   \n",
       "1952614  1272595399673630722   en  2020-06-15  18:22:41  2020-06-15   \n",
       "33341    1389114470304305154   en  2021-05-03  07:07:52  2021-05-03   \n",
       "...                      ...  ...         ...       ...         ...   \n",
       "1169957  1316312507431051264   en  2020-10-14  09:38:52  2020-10-14   \n",
       "2531839  1339593079318200320   en  2020-12-17  15:27:33  2020-12-17   \n",
       "1305376  1307074421098766336   en  2020-09-18  21:50:00  2020-09-18   \n",
       "1266310  1311853293589725184   ja  2020-10-02  02:19:32  2020-10-02   \n",
       "634525   1346226671293243393   en  2021-01-04  22:47:04  2021-01-04   \n",
       "\n",
       "           usedate1    usedate2    usedate3  ...       Volume      Open  \\\n",
       "1147845  2020-10-19  2020-10-20  2020-10-21  ...  115393800.0  121.2800   \n",
       "2318305  2021-02-17  2021-02-18  2021-02-19  ...   80576320.0  135.4900   \n",
       "2772897  2020-10-20  2020-10-21  2020-10-22  ...  120639300.0  119.9600   \n",
       "1952614  2020-06-16  2020-06-17  2020-06-18  ...  138808920.0   83.3125   \n",
       "33341    2021-05-04  2021-05-05  2021-05-06  ...   75135100.0  132.0400   \n",
       "...             ...         ...         ...  ...          ...       ...   \n",
       "1169957  2020-10-15  2020-10-16  2020-10-19  ...  151062300.0  121.0000   \n",
       "2531839  2020-12-18  2020-12-21  2020-12-22  ...   94359810.0  128.9000   \n",
       "1305376  2020-09-21  2020-09-22  2020-09-23  ...  287104900.0  110.4000   \n",
       "1266310  2020-10-05  2020-10-06  2020-10-07  ...  144712000.0  112.8900   \n",
       "634525   2021-01-05  2021-01-06  2021-01-07  ...  143301900.0  133.5200   \n",
       "\n",
       "             High      Low  Change  Change1  Change2  Change3  Change4  \\\n",
       "1147845  121.5480  118.810  -2.260   -3.980     1.31     0.20  -1.7000   \n",
       "2318305  136.0100  132.790  -2.300   -0.410     0.51    -0.37  -2.0100   \n",
       "2772897  120.4190  115.660  -3.980    1.310     0.20    -1.70  -1.3500   \n",
       "1952614   86.4200   83.145   2.435    0.155    -0.89     0.08  -1.2287   \n",
       "33341    134.0700  131.830   0.500   -3.340    -1.10     1.85  -0.6400   \n",
       "...           ...      ...     ...      ...      ...      ...      ...   \n",
       "1169957  123.0300  119.620   0.190    1.990    -2.26    -3.98   1.3100   \n",
       "2531839  129.5800  128.045  -0.200   -2.305     3.21     0.27  -1.2000   \n",
       "1305376  110.8800  106.090  -3.560    5.540    -0.87    -4.50   3.0500   \n",
       "1266310  115.3700  112.220   0.130    2.590    -2.54     0.46  -1.2800   \n",
       "634525   133.6116  126.760  -4.110    2.120    -1.12     2.56  -0.3800   \n",
       "\n",
       "         Change5  \n",
       "1147845  -1.3500  \n",
       "2318305   2.1000  \n",
       "2772897   1.0400  \n",
       "1952614   1.8825  \n",
       "33341    -2.5600  \n",
       "...          ...  \n",
       "1169957   0.2000  \n",
       "2531839   0.6500  \n",
       "1305376   3.8500  \n",
       "1266310   1.6900  \n",
       "634525   -0.2100  \n",
       "\n",
       "[501281 rows x 23 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv('mergedfullwithmoredates.csv')\n",
    "from sklearn.model_selection import train_test_split  \n",
    "mergedbig, mergedsmall = train_test_split(merged, test_size=0.15, random_state=0)\n",
    "# mergedsmall.to_csv(\"mergedsmall.csv\", index = False)\n",
    "# mergedsmall = pd.read_csv('mergedsmall.csv')\n",
    "merged = mergedsmall\n",
    "merged = merged.dropna(subset=['Change1','Change2','Change3','Change4','Change5'])\n",
    "# Obtaining the tweet contents into a list\n",
    "all_tweets = merged[\"text\"]\n",
    "all_tweets = all_tweets.to_list()\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemming(tweet):\n",
    "    a = word_tokenize(tweet)\n",
    "    answer = list(map(lambda x: lemmatizer.lemmatize(x), a))\n",
    "    return answer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rational-mechanism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text                      0\n",
      "referenced_tweets    200519\n",
      "id                        0\n",
      "lang                      0\n",
      "Date                      0\n",
      "time                      0\n",
      "usedate                   0\n",
      "usedate1                  0\n",
      "usedate2                  0\n",
      "usedate3                  0\n",
      "usedate4                  0\n",
      "usedate5                  0\n",
      "Close/Last                0\n",
      "Volume                    0\n",
      "Open                      0\n",
      "High                      0\n",
      "Low                       0\n",
      "Change                    0\n",
      "Change1                   0\n",
      "Change2                   0\n",
      "Change3                   0\n",
      "Change4                   0\n",
      "Change5                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "synthetic-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "processed_tweets = []\n",
    "X = all_tweets\n",
    "for tweet in range(0, len(X)):  \n",
    "    \n",
    "\n",
    "    processed_tweet = re.sub(r\"http\\S+\", \"\", str(X[tweet]))\n",
    "\n",
    "    # Remove all the special characters\n",
    "    processed_tweet = re.sub(r'\\W', ' ', processed_tweet)\n",
    "    \n",
    "#     processed_tweet = re.sub(r'http\\S+', '', processed_tweet)\n",
    "    \n",
    "    \n",
    "#     processed_tweet = re.sub(r'co\\S+', '', processed_tweet) \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    " \n",
    "    # Remove single characters from the start\n",
    "#     processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet) \n",
    " \n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    " \n",
    "    # Removing prefixed 'b'\n",
    "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "    \n",
    "\n",
    "    \n",
    "    processed_tweet = re.sub(r'of|to|has|keep|ll', '', processed_tweet)\n",
    "    # Converting to Lowercase\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "    \n",
    "    processed_tweet = lemming(processed_tweet)\n",
    "    \n",
    "    processed_tweet = [word for word in processed_tweet if word not in stop_words]\n",
    "    \n",
    "    processed_tweet = TreebankWordDetokenizer().detokenize(processed_tweet)    \n",
    "    \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    processed_tweets.append(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "disciplinary-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged[['Change','Change1','Change2','Change3','Change4','Change5','usedate','usedate1','usedate2','usedate3','usedate4','usedate5']]\n",
    "# X = df3\n",
    "# X = df2\n",
    "# X = df2array\n",
    "X = processed_tweets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "neutral-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.1846\u001b[0m        \u001b[32m4.0698\u001b[0m  73.8954\n",
      "      2        \u001b[36m4.0142\u001b[0m        \u001b[32m4.0060\u001b[0m  74.4248\n",
      "      3        \u001b[36m3.9791\u001b[0m        \u001b[32m3.9769\u001b[0m  74.2980\n",
      "      4        \u001b[36m3.9619\u001b[0m        \u001b[32m3.9632\u001b[0m  74.2280\n",
      "      5        \u001b[36m3.9485\u001b[0m        \u001b[32m3.9586\u001b[0m  74.2141\n",
      "      6        \u001b[36m3.9380\u001b[0m        \u001b[32m3.9538\u001b[0m  73.5068\n",
      "      7        \u001b[36m3.9293\u001b[0m        3.9553  74.4788\n",
      "      8        \u001b[36m3.9212\u001b[0m        3.9790  73.9793\n",
      "      9        \u001b[36m3.9147\u001b[0m        3.9785  73.1921\n",
      "     10        \u001b[36m3.9083\u001b[0m        3.9682  74.5897\n",
      "Change RMSE: 1.9920682\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.6476\u001b[0m        \u001b[32m3.4830\u001b[0m  73.0193\n",
      "      2        \u001b[36m3.4972\u001b[0m        3.5298  73.8824\n",
      "      3        \u001b[36m3.4652\u001b[0m        3.5480  72.9294\n",
      "      4        \u001b[36m3.4475\u001b[0m        3.4897  73.9084\n",
      "      5        \u001b[36m3.4372\u001b[0m        \u001b[32m3.4482\u001b[0m  73.0073\n",
      "      6        \u001b[36m3.4294\u001b[0m        3.4616  72.9793\n",
      "      7        \u001b[36m3.4234\u001b[0m        \u001b[32m3.4063\u001b[0m  73.1971\n",
      "      8        \u001b[36m3.4179\u001b[0m        \u001b[32m3.4040\u001b[0m  73.8694\n",
      "      9        \u001b[36m3.4134\u001b[0m        \u001b[32m3.4008\u001b[0m  73.7885\n",
      "     10        \u001b[36m3.4093\u001b[0m        3.4029  73.3959\n",
      "Change1 RMSE: 1.8530582\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9771\u001b[0m        \u001b[32m3.9906\u001b[0m  72.9633\n",
      "      2        \u001b[36m3.8707\u001b[0m        \u001b[32m3.8517\u001b[0m  73.0363\n",
      "      3        \u001b[36m3.8304\u001b[0m        \u001b[32m3.8360\u001b[0m  67.2192\n",
      "      4        \u001b[36m3.8104\u001b[0m        \u001b[32m3.8261\u001b[0m  68.2862\n",
      "      5        \u001b[36m3.7984\u001b[0m        3.8293  68.6657\n",
      "      6        \u001b[36m3.7895\u001b[0m        \u001b[32m3.8251\u001b[0m  68.8226\n",
      "      7        \u001b[36m3.7813\u001b[0m        3.8288  68.6727\n",
      "      8        \u001b[36m3.7745\u001b[0m        3.8373  68.3810\n",
      "      9        \u001b[36m3.7676\u001b[0m        3.8425  68.3560\n",
      "     10        \u001b[36m3.7623\u001b[0m        3.8408  68.0234\n",
      "Change2 RMSE: 1.9547465\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.0284\u001b[0m        \u001b[32m4.5635\u001b[0m  68.2452\n",
      "      2        \u001b[36m3.8302\u001b[0m        \u001b[32m3.8279\u001b[0m  68.2981\n",
      "      3        \u001b[36m3.7804\u001b[0m        3.8913  68.7227\n",
      "      4        \u001b[36m3.7527\u001b[0m        3.8342  69.3920\n",
      "      5        \u001b[36m3.7347\u001b[0m        \u001b[32m3.8126\u001b[0m  68.5648\n",
      "      6        \u001b[36m3.7217\u001b[0m        \u001b[32m3.7968\u001b[0m  69.3101\n",
      "      7        \u001b[36m3.7127\u001b[0m        \u001b[32m3.7702\u001b[0m  68.4719\n",
      "      8        \u001b[36m3.7047\u001b[0m        3.7788  69.1043\n",
      "      9        \u001b[36m3.6980\u001b[0m        3.8318  68.5419\n",
      "     10        \u001b[36m3.6909\u001b[0m        \u001b[32m3.7501\u001b[0m  68.1632\n",
      "Change3 RMSE: 1.9309403\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9377\u001b[0m        \u001b[32m3.7899\u001b[0m  68.4490\n",
      "      2        \u001b[36m3.8089\u001b[0m        \u001b[32m3.7705\u001b[0m  68.3341\n",
      "      3        \u001b[36m3.7914\u001b[0m        \u001b[32m3.7588\u001b[0m  68.3521\n",
      "      4        \u001b[36m3.7807\u001b[0m        \u001b[32m3.7575\u001b[0m  68.5419\n",
      "      5        \u001b[36m3.7728\u001b[0m        3.7640  68.6388\n",
      "      6        \u001b[36m3.7670\u001b[0m        3.7619  68.3311\n",
      "      7        \u001b[36m3.7614\u001b[0m        \u001b[32m3.7511\u001b[0m  68.3970\n",
      "      8        \u001b[36m3.7562\u001b[0m        3.7540  68.5948\n",
      "      9        \u001b[36m3.7511\u001b[0m        3.7517  68.8046\n",
      "     10        \u001b[36m3.7461\u001b[0m        \u001b[32m3.7480\u001b[0m  68.7566\n",
      "Change4 RMSE: 1.9336934\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.1254\u001b[0m        \u001b[32m3.9654\u001b[0m  69.0034\n",
      "      2        \u001b[36m3.9829\u001b[0m        \u001b[32m3.9316\u001b[0m  68.5079\n",
      "      3        \u001b[36m3.9607\u001b[0m        \u001b[32m3.9242\u001b[0m  69.3360\n",
      "      4        \u001b[36m3.9494\u001b[0m        \u001b[32m3.9172\u001b[0m  69.5458\n",
      "      5        \u001b[36m3.9379\u001b[0m        \u001b[32m3.9070\u001b[0m  69.5159\n",
      "      6        \u001b[36m3.9284\u001b[0m        \u001b[32m3.9034\u001b[0m  69.2931\n",
      "      7        \u001b[36m3.9205\u001b[0m        \u001b[32m3.9005\u001b[0m  68.7447\n",
      "      8        \u001b[36m3.9140\u001b[0m        \u001b[32m3.8982\u001b[0m  69.0673\n",
      "      9        \u001b[36m3.9076\u001b[0m        \u001b[32m3.8934\u001b[0m  69.0354\n",
      "     10        \u001b[36m3.9021\u001b[0m        3.8947  69.0194\n",
      "Change5 RMSE: 1.9850181\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lists = ['Change','Change1','Change2','Change3','Change4','Change5']\n",
    "for pred in range(len(lists)):\n",
    "    y_train2 = y_train.iloc[:,pred]\n",
    "    y_test2 = y_test.iloc[:,pred]\n",
    "    y_train2 = y_train2.values.reshape(-1,1)\n",
    "    y_test2 = y_test2.values.reshape(-1,1)\n",
    "    y_train2 = y_train2.astype(np.float32)\n",
    "    y_test2 = y_test2.astype(np.float32)\n",
    "    in_dimension = 5766\n",
    "    hid_dimension = 10\n",
    "    out_dimension = 1\n",
    "\n",
    "\n",
    "    class PoleNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(PoleNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_dimension,hid_dimension)\n",
    "            self.fc2 = nn.Linear(hid_dimension,out_dimension)\n",
    "            self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "        def forward(self, X):\n",
    "            hidden = self.fc1(X)\n",
    "            hidden = self.sigmoid(hidden)\n",
    "            output = self.fc2(hidden)\n",
    "            return output\n",
    "\n",
    "    from skorch import NeuralNetRegressor\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    x_trainshape = 5766\n",
    "    class RegressorModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                num_units=10,\n",
    "                nonlin=F.relu,\n",
    "        ):\n",
    "            super(RegressorModule, self).__init__()\n",
    "            self.num_units = num_units\n",
    "            self.nonlin = nonlin\n",
    "\n",
    "            self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "            self.nonlin = nonlin\n",
    "            self.dense1 = nn.Linear(num_units, 10)\n",
    "            self.output = nn.Linear(10, 1)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = self.nonlin(self.dense0(X))\n",
    "            X = F.relu(self.dense1(X))\n",
    "            X = self.output(X)\n",
    "            return X\n",
    "\n",
    "    pole_model = RegressorModule()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(pole_model.parameters(), lr = 0.1)\n",
    "\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=10, lr=0.1, callbacks =[('earlystopping',EarlyStopping())])\n",
    "    def typechange(x):\n",
    "        return x.astype(dtype = np.float32)\n",
    "    typetransform = FunctionTransformer(typechange)\n",
    "    def inputneuron(x):\n",
    "        x_trainshape = x.shape[1]\n",
    "    #     return x_trainshape\n",
    "    inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "    # pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "    # pipe = Pipeline([('net', net)])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "    # net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "    pipe.fit(X=x_train, y=y_train2)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    rmse = mean_squared_error(y_test2, y_pred, squared = False)\n",
    "    print(lists[pred], \"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cooperative-shell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Days Ahead Modelled'),\n",
       " Text(0, 0.5, 'RMSE'),\n",
       " Text(0.5, 1.0, 'Days Ahead Modelled Against RMSE')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "changelist = [1.9920682,1.8530582,1.9547465,1.9309403,1.9336934,1.9850181]\n",
    "namelist = [0,1,2,3,4,5]\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "ax = sns.lineplot(x=namelist,y=changelist)\n",
    "ax.set(xlabel='Days Ahead Modelled',ylabel='RMSE',title='Days Ahead Modelled Against RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "postal-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352\n"
     ]
    }
   ],
   "source": [
    "print((y_train['Change1'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "baking-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.68 ]\n",
      " [ 1.02 ]\n",
      " [-0.41 ]\n",
      " ...\n",
      " [-0.04 ]\n",
      " [-1.48 ]\n",
      " [-1.115]]\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.6440\u001b[0m        \u001b[32m3.5357\u001b[0m  91.9690\n",
      "      2        \u001b[36m3.5008\u001b[0m        \u001b[32m3.4493\u001b[0m  90.5838\n",
      "      3        \u001b[36m3.4604\u001b[0m        \u001b[32m3.4269\u001b[0m  92.7691\n",
      "      4        \u001b[36m3.4342\u001b[0m        \u001b[32m3.4119\u001b[0m  91.9259\n",
      "      5        \u001b[36m3.4140\u001b[0m        \u001b[32m3.3922\u001b[0m  92.6357\n",
      "      6        \u001b[36m3.3979\u001b[0m        \u001b[32m3.3796\u001b[0m  92.2186\n",
      "      7        \u001b[36m3.3840\u001b[0m        \u001b[32m3.3778\u001b[0m  92.9888\n",
      "      8        \u001b[36m3.3704\u001b[0m        \u001b[32m3.3725\u001b[0m  93.8779\n",
      "      9        \u001b[36m3.3565\u001b[0m        \u001b[32m3.3667\u001b[0m  91.5221\n",
      "     10        \u001b[36m3.3423\u001b[0m        3.3676  91.0214\n",
      "RMSE: 1.8430073\n"
     ]
    }
   ],
   "source": [
    "y_train2 = y_train['Change1']\n",
    "y_test2 = y_test['Change1']\n",
    "y_train2 = y_train2.values.reshape(-1,1)\n",
    "y_test2 = y_test2.values.reshape(-1,1)\n",
    "y_train2 = y_train2.astype(np.float32)\n",
    "y_test2 = y_test2.astype(np.float32)\n",
    "print(y_test2)\n",
    "in_dimension = 5766\n",
    "hid_dimension = 10\n",
    "out_dimension = 1\n",
    "\n",
    "\n",
    "class PoleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dimension,hid_dimension)\n",
    "        self.fc2 = nn.Linear(hid_dimension,out_dimension)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        hidden = self.fc1(X)\n",
    "        hidden = self.sigmoid(hidden)\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "x_trainshape = 5766\n",
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=200,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 200)\n",
    "        self.output = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X\n",
    "\n",
    "pole_model = RegressorModule()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(pole_model.parameters(), lr = 0.1)\n",
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=10, lr=0.1, callbacks =[('earlystopping',EarlyStopping())])\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "def inputneuron(x):\n",
    "    x_trainshape = x.shape[1]\n",
    "#     return x_trainshape\n",
    "inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "# pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "# pipe = Pipeline([('net', net)])\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "# net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "pipe.fit(X=x_train, y=y_train2)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test2, y_pred, squared = False)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "wireless-swedish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit: [34181.875]\n",
      "Accuracy: 0.6234817813765182\n",
      "Sum Invested: [18243.033]\n",
      "Profitability: [1.8736948]\n"
     ]
    }
   ],
   "source": [
    "modelpreds = y_pred\n",
    "y = y_test2\n",
    "z = y_test['usedate1']\n",
    "unique = z.unique()\n",
    "profit = 0\n",
    "bullorbearcount = 0\n",
    "invested = 0\n",
    "for uni in unique:\n",
    "    predsum = 0\n",
    "    reala = 0\n",
    "    for i, (pred, real, date) in enumerate(zip(modelpreds, y, z)):\n",
    "        if date == uni:\n",
    "            predsum += pred\n",
    "            reala = real\n",
    "    invested += abs(predsum)\n",
    "    daychange = predsum * reala\n",
    "    profit += daychange\n",
    "    if predsum > 0 and reala > 0:\n",
    "        bullorbearcount += 1\n",
    "    elif predsum < 0 and reala < 0:\n",
    "        bullorbearcount += 1\n",
    "print(\"Profit:\", profit)\n",
    "print(\"Accuracy:\", (bullorbearcount/len(unique)))\n",
    "print(\"Sum Invested:\", invested)\n",
    "print(\"Profitability:\", (profit/invested))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sapphire-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.68 ]\n",
      " [ 1.02 ]\n",
      " [-0.41 ]\n",
      " ...\n",
      " [-0.04 ]\n",
      " [-1.48 ]\n",
      " [-1.115]]\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.6945\u001b[0m        \u001b[32m3.6557\u001b[0m  94.6431\n",
      "      2        \u001b[36m3.6279\u001b[0m        \u001b[32m3.5260\u001b[0m  100.6640\n",
      "      3        \u001b[36m3.5429\u001b[0m        \u001b[32m3.4892\u001b[0m  102.8788\n",
      "      4        \u001b[36m3.5119\u001b[0m        \u001b[32m3.4579\u001b[0m  104.0485\n",
      "      5        \u001b[36m3.4864\u001b[0m        \u001b[32m3.4469\u001b[0m  105.9376\n",
      "      6        \u001b[36m3.4632\u001b[0m        \u001b[32m3.4310\u001b[0m  120.5207\n",
      "      7        \u001b[36m3.4418\u001b[0m        \u001b[32m3.4128\u001b[0m  112.4609\n",
      "      8        \u001b[36m3.4231\u001b[0m        \u001b[32m3.4017\u001b[0m  105.9835\n",
      "      9        \u001b[36m3.4060\u001b[0m        \u001b[32m3.3922\u001b[0m  106.2992\n",
      "     10        \u001b[36m3.3900\u001b[0m        \u001b[32m3.3829\u001b[0m  107.8167\n",
      "     11        \u001b[36m3.3746\u001b[0m        \u001b[32m3.3714\u001b[0m  108.3721\n",
      "     12        \u001b[36m3.3610\u001b[0m        \u001b[32m3.3672\u001b[0m  107.7637\n",
      "     13        \u001b[36m3.3475\u001b[0m        \u001b[32m3.3595\u001b[0m  108.4081\n",
      "     14        \u001b[36m3.3358\u001b[0m        \u001b[32m3.3577\u001b[0m  108.7317\n",
      "     15        \u001b[36m3.3220\u001b[0m        3.3587  108.7567\n",
      "     16        \u001b[36m3.3094\u001b[0m        3.3619  109.0164\n",
      "     17        \u001b[36m3.2990\u001b[0m        3.3632  108.7137\n",
      "     18        \u001b[36m3.2875\u001b[0m        3.3671  109.9105\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "RMSE: 1.8416712\n"
     ]
    }
   ],
   "source": [
    "y_train2 = y_train['Change1']\n",
    "y_test2 = y_test['Change1']\n",
    "y_train2 = y_train2.values.reshape(-1,1)\n",
    "y_test2 = y_test2.values.reshape(-1,1)\n",
    "y_train2 = y_train2.astype(np.float32)\n",
    "y_test2 = y_test2.astype(np.float32)\n",
    "print(y_test2)\n",
    "in_dimension = 5766\n",
    "hid_dimension = 10\n",
    "out_dimension = 1\n",
    "\n",
    "\n",
    "class PoleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dimension,hid_dimension)\n",
    "        self.fc2 = nn.Linear(hid_dimension,out_dimension)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        hidden = self.fc1(X)\n",
    "        hidden = self.sigmoid(hidden)\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "x_trainshape = 5766\n",
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=200,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 200)\n",
    "        self.output = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X\n",
    "\n",
    "pole_model = RegressorModule()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(pole_model.parameters(), lr = 0.1)\n",
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "def inputneuron(x):\n",
    "    x_trainshape = x.shape[1]\n",
    "#     return x_trainshape\n",
    "inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "# pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "# pipe = Pipeline([('net', net)])\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "# net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "pipe.fit(X=x_train, y=y_train2)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test2, y_pred, squared = False)\n",
    "print(\"RMSE:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "leading-parallel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit: [37499.73]\n",
      "Accuracy: 0.7206477732793523\n",
      "Sum Invested: [17884.742]\n",
      "Profitability: [2.0967443]\n"
     ]
    }
   ],
   "source": [
    "modelpreds = y_pred\n",
    "y = y_test2\n",
    "z = y_test['usedate1']\n",
    "unique = z.unique()\n",
    "profit = 0\n",
    "bullorbearcount = 0\n",
    "invested = 0\n",
    "for uni in unique:\n",
    "    predsum = 0\n",
    "    reala = 0\n",
    "    for i, (pred, real, date) in enumerate(zip(modelpreds, y, z)):\n",
    "        if date == uni:\n",
    "            predsum += pred\n",
    "            reala = real\n",
    "    invested += abs(predsum)\n",
    "    daychange = predsum * reala\n",
    "    profit += daychange\n",
    "    if predsum > 0 and reala > 0:\n",
    "        bullorbearcount += 1\n",
    "    elif predsum < 0 and reala < 0:\n",
    "        bullorbearcount += 1\n",
    "print(\"Profit:\", profit)\n",
    "print(\"Accuracy:\", (bullorbearcount/len(unique)))\n",
    "print(\"Sum Invested:\", invested)\n",
    "print(\"Profitability:\", (profit/invested))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-jordan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataSciEnv]",
   "language": "python",
   "name": "conda-env-DataSciEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
