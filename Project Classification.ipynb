{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "focused-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime, date, timedelta\n",
    "import torch\n",
    "import skorch\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from skorch.helper import DataFrameTransformer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rough-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('merged.csv')\n",
    "\n",
    "all_tweets = merged[\"text\"]\n",
    "all_tweets = all_tweets.to_list()\n",
    "for tweet in all_tweets:\n",
    "    # Remove all the special characters\n",
    "    processed_tweet = re.sub(r'\\W', ' ', tweet)\n",
    " \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    " \n",
    "    # Remove single characters from the start\n",
    "    processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet) \n",
    " \n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    " \n",
    "    # Removing prefixed 'b'\n",
    "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "    \n",
    "    #removing common pronouns and prepositions\n",
    "    processed_tweet = re.sub(r'of|to|https|keep|128', '', processed_tweet)\n",
    " \n",
    "    # Converting to Lowercase\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "    \n",
    "    tweet = processed_tweet\n",
    "    \n",
    "tfidfv = TfidfVectorizer(max_features=2000)\n",
    "df2 = tfidfv.fit_transform(all_tweets)\n",
    "df2array = df2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acknowledged-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.04\n",
      "-4.57\n",
      "-0.12666603819921832\n",
      "[-4.5 -4.  -3.5 -3.  -2.5 -2.  -1.5 -1.  -0.5  0.   0.5  1.   1.5  2.\n",
      "  2.5  3.   3.5  4. ]\n",
      "[14 14 14 ... 11 11 11]\n"
     ]
    }
   ],
   "source": [
    "y = merged['Change']\n",
    "print(y.max())\n",
    "print(y.min())\n",
    "print(y.mean())\n",
    "bins = np.arange(start=-4.5, stop=4.5, step = 0.5)\n",
    "# bins = np.array([-1,1])\n",
    "print(bins)\n",
    "ybin = np.digitize(y, bins)\n",
    "print(ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "caring-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Selecting the data and splitting into train and test\n",
    "y = merged['Change']\n",
    "print(type(y))\n",
    "# X = df3\n",
    "# X = df2\n",
    "# X = df2array\n",
    "X = all_tweets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, ybin, test_size=0.2, random_state=0)\n",
    "\n",
    "# train_holdout_data.to_csv('train_holdout_data.csv', index=False)\n",
    "# x_holdout.to_csv('x_holdout.csv', index=False)\n",
    "# y_holdout.to_csv('y_holdout.csv', index=False)\n",
    "# train_data.to_csv('train_data.csv', index=False)\n",
    "# x_train.to_csv('x_train.csv', index=False)\n",
    "# y_train.to_csv('y_train.csv', index=False)\n",
    "# # x_test.to_csv('x_test.csv', index=False)\n",
    "# y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "# # train_holdout_data = pd.read_csv('train_holdout_data.csv')\n",
    "# # x_holdout = pd.read_csv('x_holdout.csv')\n",
    "# # y_holdout = pd.read_csv('y_holdout.csv')\n",
    "# # x_train = pd.read_csv('x_train.csv')\n",
    "# y_train = pd.read_csv('y_train.csv')\n",
    "# # x_test = pd.read_csv('x_test.csv')\n",
    "# y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "lined-victorian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4df839a06531>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_train)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "civil-fetish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.24928693667997717\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.31      0.25      3164\n",
      "           2       0.07      0.34      0.12      1339\n",
      "           3       0.18      0.31      0.23      3000\n",
      "           4       0.32      0.15      0.21      8315\n",
      "           5       0.26      0.33      0.29      5130\n",
      "           6       0.39      0.42      0.41      5965\n",
      "           7       0.26      0.14      0.18      6684\n",
      "           8       0.34      0.23      0.27      9299\n",
      "           9       0.24      0.36      0.29     14536\n",
      "          10       0.26      0.22      0.24      3858\n",
      "          11       0.26      0.22      0.24     11621\n",
      "          12       0.24      0.14      0.18      7409\n",
      "          13       0.25      0.30      0.27      2849\n",
      "          14       0.35      0.15      0.21      9095\n",
      "          15       0.20      0.30      0.24      3089\n",
      "          16       0.21      0.25      0.23      4407\n",
      "          18       0.21      0.28      0.24      3667\n",
      "\n",
      "    accuracy                           0.25    103427\n",
      "   macro avg       0.25      0.26      0.24    103427\n",
      "weighted avg       0.27      0.25      0.25    103427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(\n",
    "               input=\"array\",\n",
    "               norm=\"l2\",\n",
    "               max_features=None,\n",
    "               sublinear_tf=True,\n",
    "               stop_words=\"english\")),\n",
    "          (\"clf\", SGDClassifier(\n",
    "               loss=\"log\",\n",
    "               penalty=\"l2\",\n",
    "               class_weight=\"balanced\",\n",
    "               tol=0.001))])\n",
    "\n",
    "pipe.fit(x_train, y_train)\n",
    "\n",
    "pred_test = pipe.predict(x_test)\n",
    "pred_train = pipe.predict(x_train)\n",
    "print(\"test accuracy\", str(np.mean(pred_test == y_test)))\n",
    "print(metrics.classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-webster",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-cotton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
