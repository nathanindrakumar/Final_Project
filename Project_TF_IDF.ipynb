{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime, date, timedelta\n",
    "import torch\n",
    "import skorch\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from skorch.helper import DataFrameTransformer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skorch import NeuralNetRegressor\n",
    "import pickle\n",
    "import emoji\n",
    "from sklearn.model_selection import cross_validate\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "\n",
    "def profitestimator(model_predictions, actual_results, relevant_dates):\n",
    "    unique = relevant_dates.unique()\n",
    "    profit = 0\n",
    "    bullorbearcount = 0\n",
    "    invested = 0\n",
    "    for uni in unique:\n",
    "        predsum = 0\n",
    "        reala = 0\n",
    "        for i, (pred, real, date) in enumerate(zip(model_predictions, actual_results, relevant_dates)):\n",
    "            if date == uni:\n",
    "                predsum += pred\n",
    "                reala = real\n",
    "        invested += abs(predsum)\n",
    "        daychange = predsum * reala\n",
    "        profit += daychange\n",
    "        if predsum > 0 and reala > 0:\n",
    "            bullorbearcount += 1\n",
    "        elif predsum < 0 and reala < 0:\n",
    "            bullorbearcount += 1\n",
    "    print(\"Profit:\", profit)\n",
    "    print(\"Accuracy:\", (bullorbearcount/len(unique)))\n",
    "    print(\"Sum Invested:\", invested)\n",
    "    print(\"Profitability:\", (profit/invested))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-cannon",
   "metadata": {},
   "source": [
    "# Please ignore the below cells, they were for additional preprocessing and do not need to be run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "disciplinary-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('twitter_aapl_1.json',)\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "aapl = json.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "spanish-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "flataapl  = [val for sublist in aapl for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "middle-desire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': '2021-05-11T10:18:35.000Z', 'id': '1392061565185236994', 'text': 'RT @Nicochan33: Apple Execs Chose to Keep a Hack of 128 Million iPhones Quiet https://t.co/waR9tgHKCA #tech #feedly #apple #iphone #cyberse‚Ä¶'}\n"
     ]
    }
   ],
   "source": [
    "print(flataapl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "suitable-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>withheld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-11T10:18:35.000Z</td>\n",
       "      <td>1392061565185236994</td>\n",
       "      <td>RT @Nicochan33: Apple Execs Chose to Keep a Ha...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-11T10:18:30.000Z</td>\n",
       "      <td>1392061546751217671</td>\n",
       "      <td>RT @RoseLoveStyle: House of the Dragon, the pr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-11T10:18:25.000Z</td>\n",
       "      <td>1392061526614360066</td>\n",
       "      <td>RT @gtorges: Ich habe jetzt einiges an Materia...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-11T10:17:54.000Z</td>\n",
       "      <td>1392061393415909376</td>\n",
       "      <td>RT @iTech911: Future versions of #Apple's CarK...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-11T10:17:48.000Z</td>\n",
       "      <td>1392061371886485506</td>\n",
       "      <td>Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517126</th>\n",
       "      <td>2021-02-18T07:25:14.000Z</td>\n",
       "      <td>1362302135333969929</td>\n",
       "      <td>RT @mobitrade_: Original Apple Airpods Pro New...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517127</th>\n",
       "      <td>2021-02-18T07:25:08.000Z</td>\n",
       "      <td>1362302111027929089</td>\n",
       "      <td>#ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517128</th>\n",
       "      <td>2021-02-18T07:25:06.000Z</td>\n",
       "      <td>1362302102404542467</td>\n",
       "      <td>Sommige appels worden te snel slecht.\\n\\nhttps...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517129</th>\n",
       "      <td>2021-02-18T07:24:56.000Z</td>\n",
       "      <td>1362302061589708805</td>\n",
       "      <td>#apple #kia #StockMarkets https://t.co/ccRBBAKDtd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517130</th>\n",
       "      <td>2021-02-18T07:24:54.000Z</td>\n",
       "      <td>1362302053889019904</td>\n",
       "      <td>RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517131 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at                   id  \\\n",
       "0       2021-05-11T10:18:35.000Z  1392061565185236994   \n",
       "1       2021-05-11T10:18:30.000Z  1392061546751217671   \n",
       "2       2021-05-11T10:18:25.000Z  1392061526614360066   \n",
       "3       2021-05-11T10:17:54.000Z  1392061393415909376   \n",
       "4       2021-05-11T10:17:48.000Z  1392061371886485506   \n",
       "...                          ...                  ...   \n",
       "517126  2021-02-18T07:25:14.000Z  1362302135333969929   \n",
       "517127  2021-02-18T07:25:08.000Z  1362302111027929089   \n",
       "517128  2021-02-18T07:25:06.000Z  1362302102404542467   \n",
       "517129  2021-02-18T07:24:56.000Z  1362302061589708805   \n",
       "517130  2021-02-18T07:24:54.000Z  1362302053889019904   \n",
       "\n",
       "                                                     text withheld  \n",
       "0       RT @Nicochan33: Apple Execs Chose to Keep a Ha...      NaN  \n",
       "1       RT @RoseLoveStyle: House of the Dragon, the pr...      NaN  \n",
       "2       RT @gtorges: Ich habe jetzt einiges an Materia...      NaN  \n",
       "3       RT @iTech911: Future versions of #Apple's CarK...      NaN  \n",
       "4       Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #...      NaN  \n",
       "...                                                   ...      ...  \n",
       "517126  RT @mobitrade_: Original Apple Airpods Pro New...      NaN  \n",
       "517127  #ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ...      NaN  \n",
       "517128  Sommige appels worden te snel slecht.\\n\\nhttps...      NaN  \n",
       "517129  #apple #kia #StockMarkets https://t.co/ccRBBAKDtd      NaN  \n",
       "517130  RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact...      NaN  \n",
       "\n",
       "[517131 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(flataapl)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "premier-publicity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152369    {'copyright': False, 'country_codes': ['IN']}\n",
       "257375    {'copyright': False, 'country_codes': ['IN']}\n",
       "269997    {'copyright': False, 'country_codes': ['IN']}\n",
       "315545    {'copyright': False, 'country_codes': ['RU']}\n",
       "315578    {'copyright': False, 'country_codes': ['RU']}\n",
       "343775    {'copyright': False, 'country_codes': ['IN']}\n",
       "473481    {'copyright': False, 'country_codes': ['RU']}\n",
       "473719    {'copyright': False, 'country_codes': ['RU']}\n",
       "489545    {'copyright': False, 'country_codes': ['IN']}\n",
       "509238    {'copyright': False, 'country_codes': ['IN']}\n",
       "Name: withheld, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['withheld'].dropna()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "arabic-snowboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-11T10:18:35</td>\n",
       "      <td>1392061565185236994</td>\n",
       "      <td>RT @Nicochan33: Apple Execs Chose to Keep a Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-11T10:18:30</td>\n",
       "      <td>1392061546751217671</td>\n",
       "      <td>RT @RoseLoveStyle: House of the Dragon, the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-11T10:18:25</td>\n",
       "      <td>1392061526614360066</td>\n",
       "      <td>RT @gtorges: Ich habe jetzt einiges an Materia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-11T10:17:54</td>\n",
       "      <td>1392061393415909376</td>\n",
       "      <td>RT @iTech911: Future versions of #Apple's CarK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-11T10:17:48</td>\n",
       "      <td>1392061371886485506</td>\n",
       "      <td>Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517126</th>\n",
       "      <td>2021-02-18T07:25:14</td>\n",
       "      <td>1362302135333969929</td>\n",
       "      <td>RT @mobitrade_: Original Apple Airpods Pro New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517127</th>\n",
       "      <td>2021-02-18T07:25:08</td>\n",
       "      <td>1362302111027929089</td>\n",
       "      <td>#ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517128</th>\n",
       "      <td>2021-02-18T07:25:06</td>\n",
       "      <td>1362302102404542467</td>\n",
       "      <td>Sommige appels worden te snel slecht.\\n\\nhttps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517129</th>\n",
       "      <td>2021-02-18T07:24:56</td>\n",
       "      <td>1362302061589708805</td>\n",
       "      <td>#apple #kia #StockMarkets https://t.co/ccRBBAKDtd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517130</th>\n",
       "      <td>2021-02-18T07:24:54</td>\n",
       "      <td>1362302053889019904</td>\n",
       "      <td>RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517131 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id  \\\n",
       "0       2021-05-11T10:18:35  1392061565185236994   \n",
       "1       2021-05-11T10:18:30  1392061546751217671   \n",
       "2       2021-05-11T10:18:25  1392061526614360066   \n",
       "3       2021-05-11T10:17:54  1392061393415909376   \n",
       "4       2021-05-11T10:17:48  1392061371886485506   \n",
       "...                     ...                  ...   \n",
       "517126  2021-02-18T07:25:14  1362302135333969929   \n",
       "517127  2021-02-18T07:25:08  1362302111027929089   \n",
       "517128  2021-02-18T07:25:06  1362302102404542467   \n",
       "517129  2021-02-18T07:24:56  1362302061589708805   \n",
       "517130  2021-02-18T07:24:54  1362302053889019904   \n",
       "\n",
       "                                                     text  \n",
       "0       RT @Nicochan33: Apple Execs Chose to Keep a Ha...  \n",
       "1       RT @RoseLoveStyle: House of the Dragon, the pr...  \n",
       "2       RT @gtorges: Ich habe jetzt einiges an Materia...  \n",
       "3       RT @iTech911: Future versions of #Apple's CarK...  \n",
       "4       Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #...  \n",
       "...                                                   ...  \n",
       "517126  RT @mobitrade_: Original Apple Airpods Pro New...  \n",
       "517127  #ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ...  \n",
       "517128  Sommige appels worden te snel slecht.\\n\\nhttps...  \n",
       "517129  #apple #kia #StockMarkets https://t.co/ccRBBAKDtd  \n",
       "517130  RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact...  \n",
       "\n",
       "[517131 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.drop('withheld',axis=1)\n",
    "df1['created_at'] = df1['created_at'].map(lambda x: str(x)[:-5])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ahead-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"twitter_aapl_1_clean.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "killing-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061565185236994</td>\n",
       "      <td>RT @Nicochan33: Apple Execs Chose to Keep a Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061546751217671</td>\n",
       "      <td>RT @RoseLoveStyle: House of the Dragon, the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061526614360066</td>\n",
       "      <td>RT @gtorges: Ich habe jetzt einiges an Materia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061393415909376</td>\n",
       "      <td>RT @iTech911: Future versions of #Apple's CarK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061371886485506</td>\n",
       "      <td>Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517126</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302135333969929</td>\n",
       "      <td>RT @mobitrade_: Original Apple Airpods Pro New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517127</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302111027929089</td>\n",
       "      <td>#ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517128</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302102404542467</td>\n",
       "      <td>Sommige appels worden te snel slecht.\\n\\nhttps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517129</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302061589708805</td>\n",
       "      <td>#apple #kia #StockMarkets https://t.co/ccRBBAKDtd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517130</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302053889019904</td>\n",
       "      <td>RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517131 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date                   id  \\\n",
       "0       2021-05-11  1392061565185236994   \n",
       "1       2021-05-11  1392061546751217671   \n",
       "2       2021-05-11  1392061526614360066   \n",
       "3       2021-05-11  1392061393415909376   \n",
       "4       2021-05-11  1392061371886485506   \n",
       "...            ...                  ...   \n",
       "517126  2021-02-18  1362302135333969929   \n",
       "517127  2021-02-18  1362302111027929089   \n",
       "517128  2021-02-18  1362302102404542467   \n",
       "517129  2021-02-18  1362302061589708805   \n",
       "517130  2021-02-18  1362302053889019904   \n",
       "\n",
       "                                                     text  \n",
       "0       RT @Nicochan33: Apple Execs Chose to Keep a Ha...  \n",
       "1       RT @RoseLoveStyle: House of the Dragon, the pr...  \n",
       "2       RT @gtorges: Ich habe jetzt einiges an Materia...  \n",
       "3       RT @iTech911: Future versions of #Apple's CarK...  \n",
       "4       Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #...  \n",
       "...                                                   ...  \n",
       "517126  RT @mobitrade_: Original Apple Airpods Pro New...  \n",
       "517127  #ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ...  \n",
       "517128  Sommige appels worden te snel slecht.\\n\\nhttps...  \n",
       "517129  #apple #kia #StockMarkets https://t.co/ccRBBAKDtd  \n",
       "517130  RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact...  \n",
       "\n",
       "[517131 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"twitter_aapl_1_clean.csv\")\n",
    "# Only including this step for now, basically removes the time component, leaving only date\n",
    "df1['created_at'] = df1['created_at'].map(lambda x: str(x)[:-9])\n",
    "df1 = df1.rename(columns={\"created_at\" : \"Date\"})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "female-spice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-14\n",
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "# adapted from https://www.30secondsofcode.org/python/s/is-weekend\n",
    "def if_weekend(d = datetime.today()):\n",
    "    if d.weekday() == 5:\n",
    "        da = d + timedelta(days=2)\n",
    "        return da\n",
    "    elif d.weekday() == 6:\n",
    "        da = d + timedelta(days=1)\n",
    "        return da\n",
    "    elif d == date(2021,4,2):\n",
    "        return date(2021,4,5)\n",
    "    else:\n",
    "        return d\n",
    "print(if_weekend(date(2021,6,14)))\n",
    "print(type(date(2021,6,14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lesbian-garlic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>usedate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061565185236994</td>\n",
       "      <td>RT @Nicochan33: Apple Execs Chose to Keep a Ha...</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061546751217671</td>\n",
       "      <td>RT @RoseLoveStyle: House of the Dragon, the pr...</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061526614360066</td>\n",
       "      <td>RT @gtorges: Ich habe jetzt einiges an Materia...</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061393415909376</td>\n",
       "      <td>RT @iTech911: Future versions of #Apple's CarK...</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061371886485506</td>\n",
       "      <td>Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #...</td>\n",
       "      <td>2021-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517126</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302135333969929</td>\n",
       "      <td>RT @mobitrade_: Original Apple Airpods Pro New...</td>\n",
       "      <td>2021-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517127</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302111027929089</td>\n",
       "      <td>#ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ...</td>\n",
       "      <td>2021-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517128</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302102404542467</td>\n",
       "      <td>Sommige appels worden te snel slecht.\\n\\nhttps...</td>\n",
       "      <td>2021-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517129</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302061589708805</td>\n",
       "      <td>#apple #kia #StockMarkets https://t.co/ccRBBAKDtd</td>\n",
       "      <td>2021-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517130</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302053889019904</td>\n",
       "      <td>RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact...</td>\n",
       "      <td>2021-02-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517131 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                   id  \\\n",
       "0      2021-05-11  1392061565185236994   \n",
       "1      2021-05-11  1392061546751217671   \n",
       "2      2021-05-11  1392061526614360066   \n",
       "3      2021-05-11  1392061393415909376   \n",
       "4      2021-05-11  1392061371886485506   \n",
       "...           ...                  ...   \n",
       "517126 2021-02-18  1362302135333969929   \n",
       "517127 2021-02-18  1362302111027929089   \n",
       "517128 2021-02-18  1362302102404542467   \n",
       "517129 2021-02-18  1362302061589708805   \n",
       "517130 2021-02-18  1362302053889019904   \n",
       "\n",
       "                                                     text    usedate  \n",
       "0       RT @Nicochan33: Apple Execs Chose to Keep a Ha... 2021-05-11  \n",
       "1       RT @RoseLoveStyle: House of the Dragon, the pr... 2021-05-11  \n",
       "2       RT @gtorges: Ich habe jetzt einiges an Materia... 2021-05-11  \n",
       "3       RT @iTech911: Future versions of #Apple's CarK... 2021-05-11  \n",
       "4       Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #... 2021-05-11  \n",
       "...                                                   ...        ...  \n",
       "517126  RT @mobitrade_: Original Apple Airpods Pro New... 2021-02-18  \n",
       "517127  #ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ... 2021-02-18  \n",
       "517128  Sommige appels worden te snel slecht.\\n\\nhttps... 2021-02-18  \n",
       "517129  #apple #kia #StockMarkets https://t.co/ccRBBAKDtd 2021-02-18  \n",
       "517130  RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact... 2021-02-18  \n",
       "\n",
       "[517131 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Date']= pd.to_datetime(df1['Date'])\n",
    "df1['usedate'] = df1['Date'].map(lambda x: if_weekend(x))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "finished-chicago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usedate</th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>125.9100</td>\n",
       "      <td>126142800</td>\n",
       "      <td>123.5000</td>\n",
       "      <td>126.2700</td>\n",
       "      <td>122.7700</td>\n",
       "      <td>2.4100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>126.8500</td>\n",
       "      <td>88071230</td>\n",
       "      <td>129.4100</td>\n",
       "      <td>129.5400</td>\n",
       "      <td>126.8100</td>\n",
       "      <td>-2.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>130.2100</td>\n",
       "      <td>78973270</td>\n",
       "      <td>130.8500</td>\n",
       "      <td>131.2582</td>\n",
       "      <td>129.4750</td>\n",
       "      <td>-0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>129.7400</td>\n",
       "      <td>78128330</td>\n",
       "      <td>127.8900</td>\n",
       "      <td>129.7500</td>\n",
       "      <td>127.1300</td>\n",
       "      <td>1.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>128.1000</td>\n",
       "      <td>84000900</td>\n",
       "      <td>129.2000</td>\n",
       "      <td>130.4500</td>\n",
       "      <td>127.9700</td>\n",
       "      <td>-1.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>78.7400</td>\n",
       "      <td>135372520</td>\n",
       "      <td>78.2925</td>\n",
       "      <td>79.1250</td>\n",
       "      <td>77.5810</td>\n",
       "      <td>0.4475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>76.9275</td>\n",
       "      <td>166348360</td>\n",
       "      <td>75.0875</td>\n",
       "      <td>76.9750</td>\n",
       "      <td>75.0525</td>\n",
       "      <td>1.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>77.3850</td>\n",
       "      <td>158929080</td>\n",
       "      <td>76.1275</td>\n",
       "      <td>77.4475</td>\n",
       "      <td>75.3825</td>\n",
       "      <td>1.2575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>76.9125</td>\n",
       "      <td>200622560</td>\n",
       "      <td>78.0375</td>\n",
       "      <td>78.9875</td>\n",
       "      <td>75.8025</td>\n",
       "      <td>-1.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>77.8525</td>\n",
       "      <td>162301040</td>\n",
       "      <td>79.4575</td>\n",
       "      <td>79.9220</td>\n",
       "      <td>77.7275</td>\n",
       "      <td>-1.6050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       usedate  Close/Last     Volume      Open      High       Low  Change\n",
       "0   2021-05-11    125.9100  126142800  123.5000  126.2700  122.7700  2.4100\n",
       "1   2021-05-10    126.8500   88071230  129.4100  129.5400  126.8100 -2.5600\n",
       "2   2021-05-07    130.2100   78973270  130.8500  131.2582  129.4750 -0.6400\n",
       "3   2021-05-06    129.7400   78128330  127.8900  129.7500  127.1300  1.8500\n",
       "4   2021-05-05    128.1000   84000900  129.2000  130.4500  127.9700 -1.1000\n",
       "..         ...         ...        ...       ...       ...       ...     ...\n",
       "247 2020-05-18     78.7400  135372520   78.2925   79.1250   77.5810  0.4475\n",
       "248 2020-05-15     76.9275  166348360   75.0875   76.9750   75.0525  1.8400\n",
       "249 2020-05-14     77.3850  158929080   76.1275   77.4475   75.3825  1.2575\n",
       "250 2020-05-13     76.9125  200622560   78.0375   78.9875   75.8025 -1.1250\n",
       "251 2020-05-12     77.8525  162301040   79.4575   79.9220   77.7275 -1.6050\n",
       "\n",
       "[252 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = pd.read_csv(\"aapl2.csv\")\n",
    "price['Date'] = price['Date'].map(lambda x: parser.parse(x).isoformat())\n",
    "# Only including this step for now, basically removes the time component, leaving only date\n",
    "price['Date'] = price['Date'].map(lambda x: str(x)[:-9])\n",
    "price['Date']= pd.to_datetime(price['Date'])\n",
    "# Change me if looking to change examination scope\n",
    "price = price.rename(columns={\"Date\" : \"usedate\"})\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "removed-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x1f506730fa0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "fig_dims = (15, 6)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "sns.lineplot(x=price['usedate'],y=price['Change'])\n",
    "ax.set(xlabel='Dates',ylabel='Daily Price Change',title=\"Apple's Stock Price Change\")\n",
    "plt.xticks(rotation=45)\n",
    "ax.axhline(y=0, ls='-', c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecological-ontario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18383., 18444., 18506., 18567., 18628., 18687., 18748.]),\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "fig_dims = (15, 6)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "sns.lineplot(x=price['usedate'],y=price['Close/Last'])\n",
    "ax.set(xlabel='Dates',ylabel='Daily Price at Close',title=\"Apple's Stock Price Movement\")\n",
    "plt.xticks(rotation=45)\n",
    "# ax.axhline(y=0, ls='-', c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "quantitative-gender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18383., 18444., 18506., 18567., 18628., 18687., 18748.]),\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "fig_dims = (15, 6)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "sns.lineplot(x=price['usedate'],y=price['Volume'])\n",
    "ax.set(xlabel='Dates',ylabel='Daily Price Change',title=\"Apple's Stock Trading Volume Movement\")\n",
    "plt.xticks(rotation=45)\n",
    "# ax.axhline(y=0, ls='-', c='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "active-punch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>usedate</th>\n",
       "      <th>Close/Last</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061565185236994</td>\n",
       "      <td>RT @Nicochan33: Apple Execs Chose to Keep a Ha...</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>125.91</td>\n",
       "      <td>126142800</td>\n",
       "      <td>123.5</td>\n",
       "      <td>126.270</td>\n",
       "      <td>122.77</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061546751217671</td>\n",
       "      <td>RT @RoseLoveStyle: House of the Dragon, the pr...</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>125.91</td>\n",
       "      <td>126142800</td>\n",
       "      <td>123.5</td>\n",
       "      <td>126.270</td>\n",
       "      <td>122.77</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061526614360066</td>\n",
       "      <td>RT @gtorges: Ich habe jetzt einiges an Materia...</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>125.91</td>\n",
       "      <td>126142800</td>\n",
       "      <td>123.5</td>\n",
       "      <td>126.270</td>\n",
       "      <td>122.77</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061393415909376</td>\n",
       "      <td>RT @iTech911: Future versions of #Apple's CarK...</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>125.91</td>\n",
       "      <td>126142800</td>\n",
       "      <td>123.5</td>\n",
       "      <td>126.270</td>\n",
       "      <td>122.77</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>1392061371886485506</td>\n",
       "      <td>Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #...</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>125.91</td>\n",
       "      <td>126142800</td>\n",
       "      <td>123.5</td>\n",
       "      <td>126.270</td>\n",
       "      <td>122.77</td>\n",
       "      <td>2.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517126</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302135333969929</td>\n",
       "      <td>RT @mobitrade_: Original Apple Airpods Pro New...</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>129.71</td>\n",
       "      <td>96856750</td>\n",
       "      <td>129.2</td>\n",
       "      <td>129.995</td>\n",
       "      <td>127.41</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517127</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302111027929089</td>\n",
       "      <td>#ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ...</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>129.71</td>\n",
       "      <td>96856750</td>\n",
       "      <td>129.2</td>\n",
       "      <td>129.995</td>\n",
       "      <td>127.41</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517128</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302102404542467</td>\n",
       "      <td>Sommige appels worden te snel slecht.\\n\\nhttps...</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>129.71</td>\n",
       "      <td>96856750</td>\n",
       "      <td>129.2</td>\n",
       "      <td>129.995</td>\n",
       "      <td>127.41</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517129</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302061589708805</td>\n",
       "      <td>#apple #kia #StockMarkets https://t.co/ccRBBAKDtd</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>129.71</td>\n",
       "      <td>96856750</td>\n",
       "      <td>129.2</td>\n",
       "      <td>129.995</td>\n",
       "      <td>127.41</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517130</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>1362302053889019904</td>\n",
       "      <td>RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact...</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>129.71</td>\n",
       "      <td>96856750</td>\n",
       "      <td>129.2</td>\n",
       "      <td>129.995</td>\n",
       "      <td>127.41</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517131 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                   id  \\\n",
       "0      2021-05-11  1392061565185236994   \n",
       "1      2021-05-11  1392061546751217671   \n",
       "2      2021-05-11  1392061526614360066   \n",
       "3      2021-05-11  1392061393415909376   \n",
       "4      2021-05-11  1392061371886485506   \n",
       "...           ...                  ...   \n",
       "517126 2021-02-18  1362302135333969929   \n",
       "517127 2021-02-18  1362302111027929089   \n",
       "517128 2021-02-18  1362302102404542467   \n",
       "517129 2021-02-18  1362302061589708805   \n",
       "517130 2021-02-18  1362302053889019904   \n",
       "\n",
       "                                                     text    usedate  \\\n",
       "0       RT @Nicochan33: Apple Execs Chose to Keep a Ha... 2021-05-11   \n",
       "1       RT @RoseLoveStyle: House of the Dragon, the pr... 2021-05-11   \n",
       "2       RT @gtorges: Ich habe jetzt einiges an Materia... 2021-05-11   \n",
       "3       RT @iTech911: Future versions of #Apple's CarK... 2021-05-11   \n",
       "4       Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åüü§ó\\n#Apple #airtag #„Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ #... 2021-05-11   \n",
       "...                                                   ...        ...   \n",
       "517126  RT @mobitrade_: Original Apple Airpods Pro New... 2021-02-18   \n",
       "517127  #ios #Apple #swiftui \\nSwiftUI 2.0 Complex UI ... 2021-02-18   \n",
       "517128  Sommige appels worden te snel slecht.\\n\\nhttps... 2021-02-18   \n",
       "517129  #apple #kia #StockMarkets https://t.co/ccRBBAKDtd 2021-02-18   \n",
       "517130  RT @mobitrade_: iPhone 8 Neatly Used 64GB Fact... 2021-02-18   \n",
       "\n",
       "        Close/Last     Volume   Open     High     Low  Change  \n",
       "0           125.91  126142800  123.5  126.270  122.77    2.41  \n",
       "1           125.91  126142800  123.5  126.270  122.77    2.41  \n",
       "2           125.91  126142800  123.5  126.270  122.77    2.41  \n",
       "3           125.91  126142800  123.5  126.270  122.77    2.41  \n",
       "4           125.91  126142800  123.5  126.270  122.77    2.41  \n",
       "...            ...        ...    ...      ...     ...     ...  \n",
       "517126      129.71   96856750  129.2  129.995  127.41    0.51  \n",
       "517127      129.71   96856750  129.2  129.995  127.41    0.51  \n",
       "517128      129.71   96856750  129.2  129.995  127.41    0.51  \n",
       "517129      129.71   96856750  129.2  129.995  127.41    0.51  \n",
       "517130      129.71   96856750  129.2  129.995  127.41    0.51  \n",
       "\n",
       "[517131 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(df1, price, how='left', on='usedate')\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mature-budget",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          0\n",
       "id            0\n",
       "text          0\n",
       "usedate       0\n",
       "Close/Last    0\n",
       "Volume        0\n",
       "Open          0\n",
       "High          0\n",
       "Low           0\n",
       "Change        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "musical-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged.to_csv(\"merged.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-heart",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quarterly-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          .\\nDomain Name for sale\\n\\nhttps://t.co/f056Wp...\n",
      "1          .\\nDomain NameFor Sale\\n\\nhttps://t.co/a2N3rgJ...\n",
      "2          .\\nDomains For sale\\n\\nhttps://t.co/0YeRs3JJLb...\n",
      "3          .\\nDomain NameFor Sale\\n\\nhttps://t.co/a2N3rgJ...\n",
      "4          Savanna Drinkers ü§¶\\n\\n#R500 #RHOA #AceMagashul...\n",
      "                                 ...                        \n",
      "3387871    Download JOBIN THE PENGUIN! Awesome, retro-ins...\n",
      "3387872    2019 13\" 1.6GHz/128GB #Apple #MacBook Airs, re...\n",
      "3387873    How to use Apple Maps mobility trends data htt...\n",
      "3387874    AirPods Studio Could Come With Head And Neck D...\n",
      "3387875    Check it OUT Shades of Gray by Andy Holloman R...\n",
      "Name: text, Length: 3387876, dtype: object\n",
      ".\n",
      "Domain Name for sale\n",
      "\n",
      "https://t.co/f056WpEdXS\n",
      "\n",
      "#fluke #FlukeTV #domain #100DaysOfCode #javascript #python #Apple #vr #Microsoft #Linux #Marketing #Media #News #entrepreneur #Live #iptv  #Business #Startup #Startups #marketing #ott #tv #Entertainment #Live  #fitness #fun https://t.co/EyaFJNdVaa\n",
      ".\n",
      "Domain NameFor Sale\n",
      "\n",
      "https://t.co/a2N3rgJrnd\n",
      "\n",
      "#BTCE #btc #BtcExchange #BitcoinExchange #bitcoin #bitcointrading #cryptotrading #100DaysOfCode #javascript #python #Apple #vr #Microsoft #Linux #cryptocurrency #crypto #forex #trading #entrepreneur #Business #startups #startup https://t.co/w4gm6UursZ\n",
      ".\n",
      "Domains For sale\n",
      "\n",
      "https://t.co/0YeRs3JJLb\n",
      "https://t.co/ke7bPV3rhW\n",
      "https://t.co/sLmytllUpy\n",
      "\n",
      "#LearnData #Data #datascience #100DaysOfCode #javascript #python #Apple #vr #Microsoft #Linux #LearnDataScience #bigdata #ML #machinelearning #artificialintelligence #ai #deeplearning #It https://t.co/YpqZoElO6T\n"
     ]
    }
   ],
   "source": [
    "merged = pd.read_csv('mergedfull.csv')\n",
    "from sklearn.model_selection import train_test_split  \n",
    "# mergedbig, mergedsmall = train_test_split(merged, test_size=0.15, random_state=0)\n",
    "# # mergedsmall.to_csv(\"mergedsmall.csv\", index = False)\n",
    "# mergedsmall = pd.read_csv('mergedsmall.csv')\n",
    "# merged = mergedsmall\n",
    "# Obtaining the tweet contents into a list\n",
    "all_tweets = merged[\"text\"]\n",
    "print(all_tweets)\n",
    "all_tweets = all_tweets.to_list()\n",
    "print(all_tweets[0])\n",
    "print(all_tweets[1])\n",
    "print(all_tweets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caroline-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387876\n"
     ]
    }
   ],
   "source": [
    "print(len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prescription-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemming(tweet):\n",
    "    a = word_tokenize(tweet)\n",
    "    answer = list(map(lambda x: lemmatizer.lemmatize(x), a))\n",
    "    return answer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tired-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.gotrained.com/scraping-tweets-sentiment-analysis/\n",
    "# Basic cleaning of text before TF-IDF; this process will be improved later\n",
    "# for tweet in all_tweets:\n",
    "#     # Remove all the special characters\n",
    "#     processed_tweet = re.sub(r'\\W', ' ', tweet)\n",
    " \n",
    "#     # remove all single characters\n",
    "#     processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    " \n",
    "#     # Remove single characters from the start\n",
    "#     processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet) \n",
    " \n",
    "#     # Substituting multiple spaces with single space\n",
    "#     processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    " \n",
    "#     # Removing prefixed 'b'\n",
    "#     processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "    \n",
    "#     #removing common pronouns and prepositions\n",
    "#     processed_tweet = re.sub(r'of|to|https|keep|128', '', processed_tweet)\n",
    "#     processed_tweet = lemmatizer.lemmatize(processed_tweet)\n",
    "# #     lambda x: lemmatizer.lemmatize(x in processed_tweet)\n",
    "#     # Converting to Lowercase\n",
    "#     processed_tweet = processed_tweet.lower()\n",
    "    \n",
    "#     tweet = processed_tweet\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed_tweets = []\n",
    "X = all_tweets\n",
    "for tweet in range(0, len(X)):  \n",
    "    \n",
    "\n",
    "    processed_tweet = re.sub(r\"http\\S+\", \"\", str(X[tweet]))\n",
    "    # Replace all emojis with text\n",
    "    processed_tweet = emoji.demojize(processed_tweet)\n",
    "    # Remove all the special characters\n",
    "    processed_tweet = re.sub(r'\\W', ' ', processed_tweet)\n",
    "    \n",
    "#     processed_tweet = re.sub(r'http\\S+', '', processed_tweet)\n",
    "    \n",
    "    \n",
    "#     processed_tweet = re.sub(r'co\\S+', '', processed_tweet) \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    " \n",
    "    # Remove single characters from the start\n",
    "#     processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet) \n",
    " \n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    " \n",
    "    # Removing prefixed 'b'\n",
    "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "    \n",
    "\n",
    "    \n",
    "    processed_tweet = re.sub(r'of|to|has|keep|ll', '', processed_tweet)\n",
    "    # Converting to Lowercase\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "    \n",
    "    processed_tweet = lemming(processed_tweet)\n",
    "    \n",
    "    processed_tweet = [word for word in processed_tweet if word not in stop_words]\n",
    "    \n",
    "    processed_tweet = TreebankWordDetokenizer().detokenize(processed_tweet)    \n",
    "    \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    processed_tweets.append(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "killing-yahoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 almost ended brand new sealed factory unlocked iphone12 mini one lucky follower keep foowing amp retweeting itech911 ibuy ise iswap ifix apple 0262666226\n",
      "feel like apple love delivering heart month chaenge badge restart watch wait minute get apple applewatch chaenge\n",
      "new rip live 2w1b 051 iphone capitalism amazon tax gripe mondaythoughts mondaymorning mondaymotivation hamont btc bitcoin iphone12 apple aapl eefber spotify ps5 investing itunes sony weed cgc etf amzn spot nlpoli\n"
     ]
    }
   ],
   "source": [
    "print(processed_tweets[0])\n",
    "print(processed_tweets[1])\n",
    "print(processed_tweets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "steady-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t0.4292728384032796\n",
      "  (0, 35)\t0.12124039197976871\n",
      "  (0, 10)\t0.1608920722948683\n",
      "  (0, 18)\t0.10944655519053977\n",
      "  (0, 2)\t0.20185345693587373\n",
      "  (0, 19)\t0.11118314103040297\n",
      "  (0, 27)\t0.14174466035436126\n",
      "  (0, 20)\t0.18009614335635307\n",
      "  (0, 22)\t0.17675230126297767\n",
      "  (0, 32)\t0.14566038088197764\n",
      "  (0, 36)\t0.17255498994907567\n",
      "  (0, 14)\t0.14895846761009882\n",
      "  (0, 17)\t0.18473828717065588\n",
      "  (0, 34)\t0.20978625145182792\n",
      "  (0, 29)\t0.1323423398380978\n",
      "  (0, 13)\t0.12718304329981206\n",
      "  (0, 15)\t0.1547954720262441\n",
      "  (0, 25)\t0.176203565212804\n",
      "  (0, 16)\t0.1946395145827683\n",
      "  (0, 31)\t0.15431526510055965\n",
      "  (0, 30)\t0.14083914097260666\n",
      "  (0, 26)\t0.1769932888737439\n",
      "  (0, 24)\t0.13317174093098733\n",
      "  (0, 23)\t0.1494115451496236\n",
      "  (0, 12)\t0.1493900838660045\n",
      "  :\t:\n",
      "  (508180, 1)\t0.041239708319988785\n",
      "  (508180, 3)\t0.066804153993361\n",
      "  (508181, 5)\t0.22211222325535768\n",
      "  (508181, 18)\t0.2356039420801946\n",
      "  (508181, 19)\t0.16982049083678846\n",
      "  (508181, 27)\t0.20236100628970025\n",
      "  (508181, 20)\t0.2260078761173906\n",
      "  (508181, 22)\t0.12864236568311457\n",
      "  (508181, 32)\t0.10601330703514851\n",
      "  (508181, 36)\t0.2996887765943345\n",
      "  (508181, 14)\t0.1614310402606414\n",
      "  (508181, 17)\t0.11824534435371886\n",
      "  (508181, 29)\t0.23648518800225884\n",
      "  (508181, 13)\t0.11473228781899153\n",
      "  (508181, 15)\t0.2162153149258937\n",
      "  (508181, 25)\t0.17665458463926617\n",
      "  (508181, 16)\t0.270277767709747\n",
      "  (508181, 31)\t0.1529353163458522\n",
      "  (508181, 30)\t0.26556448938368293\n",
      "  (508181, 26)\t0.24908886050384133\n",
      "  (508181, 24)\t0.231289029244089\n",
      "  (508181, 23)\t0.16257285204888874\n",
      "  (508181, 12)\t0.22817755581609808\n",
      "  (508181, 0)\t0.28238317351628134\n",
      "  (508181, 3)\t0.16988800245232194\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "tfidfv = TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')\n",
    "df2 = tfidfv.fit_transform(processed_tweets)\n",
    "print(df2)\n",
    "# df2array = df2.toarray()\n",
    "# print(df2array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "built-austin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 556)\t0.40357727068148264\n",
      "  (0, 88)\t0.34308710016633726\n",
      "  (0, 97)\t0.417333363196858\n",
      "  (0, 443)\t0.3951839877481259\n",
      "  (0, 674)\t0.3663719517401211\n",
      "  (0, 1770)\t0.3199229308458355\n",
      "  (0, 1783)\t0.31050472625527564\n",
      "  (0, 943)\t0.15704072326243243\n",
      "  (0, 1716)\t0.15129041849415864\n",
      "  (0, 1471)\t0.09239185493528781\n"
     ]
    }
   ],
   "source": [
    "print(type(df2))\n",
    "print(type(df2[-1]))\n",
    "print(type(df2[-1][-1]))\n",
    "print(df2[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clean-franchise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813202\n"
     ]
    }
   ],
   "source": [
    "print(df2.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "constant-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 943)\t0.1619164850216469\n",
      "  (0, 1667)\t0.24642359750991072\n",
      "  (0, 412)\t0.07984327940748012\n",
      "  (0, 863)\t0.07926270652557654\n",
      "  (0, 957)\t0.3644418579168204\n",
      "  (0, 1148)\t0.37252279088881424\n",
      "  (0, 24)\t0.44364094790152897\n",
      "  (0, 1243)\t0.19111331976332038\n",
      "  (0, 802)\t0.4405447542842643\n",
      "  (0, 1005)\t0.38259748006594846\n",
      "  (0, 1716)\t0.15598764620493955\n",
      "  (0, 189)\t0.14697293203863546\n",
      "  (0, 1471)\t0.09526041452797107\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(df2[0])\n",
    "\n",
    "print(df2array[0])\n",
    "print(type(df2[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df2array))\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print(df2array[0])\n",
    "np.set_printoptions(threshold = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aware-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt nicochan33 apple exec chose to keep hack of 128 million iphones quiet tech feedly apple iphone cyberse', 'rt roselovestyle house of the dragon the prequel to game of throne wa announced by casey bloys president of hbo gamesofthrones', 'rt gtorges ich habe jetzt einiges an material zu fuellmich amp co beim applesupport eingereicht hoffentlich verschwindet der podcast', 'rt itech911 future version of apple carkey could detect when it being used near wireless charger and alter how it work to avoid', 'Áô∫Â£≤Êó•„Å´‰∫àÁ¥Ñ„Åó„Å¶„Çà„ÅÜ„ÇÑ„ÅèÂ±ä„ÅÑ„Åü apple airtag „Ç±„Éº„Çπ„ÅØÁ¥îÊ≠£„Åò„ÇÉ„Å™„ÅÑ Âøò„Çå„ÇìÂùä ÂÆü„ÅØËøΩÂä†„Åß„ÇÇ„ÅÜ‰∏Ä„Å§Ë≤∑„Å£„Åü', 'rt nicochan33 apple exec chose to keep hack of 128 million iphones quiet tech feedly apple iphone cyberse', 'rt foxconcours_ apple macbook tente de gagner un macbookpro13 en participant ce concours pour tenter votre chance rt fo', 'rt taisy0 apple apple tv „Åßsiri„ÇíÂà©Áî®ÂèØËÉΩ„Å™ÂõΩ„ÇíÊã°Â§ß Ê∞ó„Å´„Å™„Çã Ë®ò„Å´„Å™„Çã apple', 'rt neodiycom how to fix apple macbookpro 2011 running windows10 10 64 bit audio sound driver problem macbook', 'rt indievideogames dino maker make dinos and level to share indiegame gamedev indiedev retro indievideogames io indiegames vi']\n"
     ]
    }
   ],
   "source": [
    "print(processed_tweets[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "middle-muslim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517131\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_tweets))\n",
    "print(type(processed_tweets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "statutory-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beautiful-reducing",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e96957eda679>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# https://programmerbackpack.com/tf-idf-explained-and-python-implementation/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdfnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidfv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"TF-IDF\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdfnew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TF-IDF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdfnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "# https://programmerbackpack.com/tf-idf-explained-and-python-implementation/\n",
    "dfnew = pd.DataFrame(df2[0].T.todense(), index=tfidfv.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "dfnew = dfnew.sort_values('TF-IDF', ascending=False)\n",
    "print (dfnew.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "altered-blank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517128</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517131 rows √ó 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     ...  1990  \\\n",
       "0        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "517126   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "517127   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "517128   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "517129   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "517130   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "        1991  1992  1993  1994  1995  1996  1997  1998  1999  \n",
       "0        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "517126   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "517127   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "517128   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "517129   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "517130   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[517131 rows x 2000 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying an alternative data implementation, I haven't used this in the later stages yet\n",
    "df3 = pd.DataFrame.sparse.from_spmatrix(df2)\n",
    "print(type(df3))\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfied-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Selecting the data and splitting into train and test\n",
    "y = merged[['Change','usedate']]\n",
    "y.to_csv('y.csv', index=False)\n",
    "print(type(y))\n",
    "# X = df3\n",
    "# X = df2\n",
    "# X = df2array\n",
    "X = processed_tweets\n",
    "with open(\"X.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(X, fp)\n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "y_traindates = y_train['usedate']\n",
    "y_testdates = y_test['usedate']\n",
    "y_train = y_train['Change']\n",
    "y_test = y_test['Change']\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "# train_data = train_data.sample(frac=x)\n",
    "# train_holdout_data.to_csv('train_holdout_data.csv', index=False)\n",
    "# x_holdout.to_csv('x_holdout.csv', index=False)\n",
    "# y_holdout.to_csv('y_holdout.csv', index=False)\n",
    "# train_data.to_csv('train_data.csv', index=False)\n",
    "\n",
    "with open(\"x_train.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(x_train, fp)\n",
    "with open(\"y_train.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_train, fp)\n",
    "with open(\"x_test.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(x_test, fp)\n",
    "with open(\"y_test.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_test, fp)\n",
    "with open(\"y_traindates.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_traindates, fp)\n",
    "with open(\"y_testdates.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_testdates, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powerful-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2710300\n",
      "677576\n",
      "252\n",
      "252\n"
     ]
    }
   ],
   "source": [
    "print(len(y_traindates))\n",
    "print(len(y_testdates))\n",
    "print(len(y_traindates.unique()))\n",
    "print(len(y_testdates.unique()))\n",
    "X = processed_tweets\n",
    "with open(\"X.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(X, fp)\n",
    "with open(\"X.txt\", \"rb\") as fp:   # Unpickling\n",
    "    X = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "experienced-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_train.txt\", \"rb\") as fp:   # Unpickling\n",
    "    x_train = pickle.load(fp)\n",
    "with open(\"y_train.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_train = pickle.load(fp)\n",
    "with open(\"x_test.txt\", \"rb\") as fp:   # Unpickling\n",
    "    x_test = pickle.load(fp)\n",
    "with open(\"y_test.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_test = pickle.load(fp)\n",
    "with open(\"y_traindates.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_traindates = pickle.load(fp)\n",
    "with open(\"y_testdates.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_testdates = pickle.load(fp)\n",
    "\n",
    "# x_train.to_csv('x_train.csv', index=False)\n",
    "# y_train.to_csv('y_train.csv', index=False)\n",
    "# x_test.to_csv('x_test.csv', index=False)\n",
    "# y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "# # # train_holdout_data = pd.read_csv('train_holdout_data.csv')\n",
    "# # # x_holdout = pd.read_csv('x_holdout.csv')\n",
    "# # # y_holdout = pd.read_csv('y_holdout.csv')\n",
    "# x_train = pd.read_csv('x_train.csv')\n",
    "# y_train = pd.read_csv('y_train.csv')\n",
    "# x_test = pd.read_csv('x_test.csv')\n",
    "# y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dangerous-gauge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406545\n"
     ]
    }
   ],
   "source": [
    "# y_train = pd.Series(y_train)\n",
    "# y_test = pd.Series(y_test)\n",
    "print(len(x_train))\n",
    "# print(type(y_train.values))\n",
    "# print(np.isnan(X).sum())\n",
    "# print(y.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "absent-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406545\n"
     ]
    }
   ],
   "source": [
    "# x_train = torch.from_numpy(x_train)\n",
    "# x_test = torch.from_numpy(x_test)\n",
    "# y_train = torch.from_numpy(y_train.values)\n",
    "# y_test = torch.from_numpy(y_test.values)\n",
    "print(len(x_train))\n",
    "# print(x_train)\n",
    "# print(x_test)\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reasonable-trace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-42a2226c82f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(x_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "print(x_train.dtype)\n",
    "print(x_test.dtype)\n",
    "print(y_train.dtype)\n",
    "print(y_test.dtype)\n",
    "# print(x_test[100000][0])\n",
    "# if 'X' in x_train:\n",
    "#     print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "binding-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.astype(np.float32)\n",
    "# y_test = y_test.astype(np.float32)\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "# y_train = y_train.squeeze()\n",
    "# y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "directed-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(y_train.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "excessive-landscape",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-a8b81fe93964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# x_train1 = x_train.astype(np.float32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# y_train1 = y_train.astype(np.float32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "# x_train1 = x_train.astype(np.float32)\n",
    "# y_train1 = y_train.astype(np.float32)\n",
    "print(x_train.dtype)\n",
    "print(x_test.dtype)\n",
    "print(y_train.dtype)\n",
    "print(y_test.dtype)\n",
    "print(x_train1.dtype)\n",
    "print(y_train1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "academic-depth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float32'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-7197c060c3b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "# for x in y_train[0]:\n",
    "#     if type(x) != \"class 'numpy.float32'\":\n",
    "#         print(\"double\")\n",
    "print(type(x_train[0]))\n",
    "print(type(y_train))\n",
    "print(type(y_train[0]))\n",
    "print(type(y_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "capital-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainarray = y_train.values.tolist()\n",
    "y_testarray = y_test.values.tolist()\n",
    "# y_trainarray = y_train.to_numpy()\n",
    "# y_testarray = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "loved-voltage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "tfidfv = TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, stop_words=\"english\",token_pattern=r'[^\\s]+')\n",
    "x_train1 = tfidfv.fit_transform(x_train)\n",
    "x_test1 = tfidfv.fit_transform(x_test)\n",
    "x_train2 = x_train1.astype(dtype = np.float32)\n",
    "x_test2 = x_test1.astype(dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "flush-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5205\n",
      "(413704, 1)\n",
      "[[ 1.33]\n",
      " [-2.01]\n",
      " [ 1.14]\n",
      " ...\n",
      " [-3.29]\n",
      " [-2.73]\n",
      " [-1.33]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train2.shape[1])\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "answering-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "# tokenise me pls\n",
    "a = [word_tokenize(x) for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "valued-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373108\n"
     ]
    }
   ],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "print(len(set(flatten(a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "limiting-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.1936\u001b[0m        \u001b[32m4.1083\u001b[0m  69.3092\n",
      "      2        \u001b[36m4.0193\u001b[0m        \u001b[32m4.0278\u001b[0m  68.9264\n",
      "      3        \u001b[36m3.9803\u001b[0m        \u001b[32m3.9981\u001b[0m  68.6171\n",
      "      4        \u001b[36m3.9616\u001b[0m        \u001b[32m3.9833\u001b[0m  69.7552\n",
      "      5        \u001b[36m3.9440\u001b[0m        \u001b[32m3.9760\u001b[0m  68.5739\n",
      "      6        \u001b[36m3.9295\u001b[0m        \u001b[32m3.9626\u001b[0m  70.2413\n",
      "      7        \u001b[36m3.9161\u001b[0m        3.9787  72.2498\n",
      "      8        \u001b[36m3.9055\u001b[0m        \u001b[32m3.9452\u001b[0m  73.4044\n",
      "      9        \u001b[36m3.8966\u001b[0m        \u001b[32m3.9397\u001b[0m  70.3450\n",
      "     10        \u001b[36m3.8888\u001b[0m        \u001b[32m3.9324\u001b[0m  70.0576\n"
     ]
    }
   ],
   "source": [
    "# import torch.nn.functional as F\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "\n",
    "in_dimension = 5844\n",
    "hid_dimension = 10\n",
    "out_dimension = 1\n",
    "\n",
    "\n",
    "class PoleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dimension,hid_dimension)\n",
    "        self.fc2 = nn.Linear(hid_dimension,out_dimension)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        hidden = self.fc1(X)\n",
    "        hidden = self.sigmoid(hidden)\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "x_trainshape = 5844\n",
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X\n",
    "\n",
    "pole_model = RegressorModule()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(pole_model.parameters(), lr = 0.1)\n",
    "\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=10, lr=0.1, callbacks =[('earlystopping',EarlyStopping())])\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "def inputneuron(x):\n",
    "    x_trainshape = x.shape[1]\n",
    "#     return x_trainshape\n",
    "inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "# pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "# pipe = Pipeline([('net', net)])\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "# net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "democratic-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9736353"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "placed-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2394\u001b[0m        \u001b[32m4.2297\u001b[0m  72.4814\n",
      "      2        \u001b[36m4.1567\u001b[0m        \u001b[32m4.1073\u001b[0m  70.6289\n",
      "      3        \u001b[36m4.0670\u001b[0m        \u001b[32m4.0913\u001b[0m  72.2662\n",
      "      4        \u001b[36m4.0426\u001b[0m        \u001b[32m4.0363\u001b[0m  70.4901\n",
      "      5        \u001b[36m4.0162\u001b[0m        4.0882  70.8557\n",
      "      6        \u001b[36m4.0003\u001b[0m        4.0989  70.7887\n",
      "      7        \u001b[36m3.9910\u001b[0m        4.0867  71.7170\n",
      "      8        \u001b[36m3.9837\u001b[0m        4.0710  70.4721\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "5 RMSE: 2.0023932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2401\u001b[0m        \u001b[32m4.2351\u001b[0m  67.6599\n",
      "      2        \u001b[36m4.1687\u001b[0m        \u001b[32m4.0918\u001b[0m  69.9882\n",
      "      3        \u001b[36m4.0694\u001b[0m        \u001b[32m4.0911\u001b[0m  70.2413\n",
      "      4        \u001b[36m4.0430\u001b[0m        \u001b[32m4.0353\u001b[0m  67.6599\n",
      "      5        \u001b[36m4.0176\u001b[0m        4.0835  67.9217\n",
      "      6        \u001b[36m4.0010\u001b[0m        4.0947  68.4621\n",
      "      7        \u001b[36m3.9883\u001b[0m        4.0795  67.3682\n",
      "      8        \u001b[36m3.9796\u001b[0m        4.0551  68.7278\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "10 RMSE: 1.9989355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2416\u001b[0m        \u001b[32m4.2414\u001b[0m  71.0854\n",
      "      2        \u001b[36m4.1907\u001b[0m        \u001b[32m4.1663\u001b[0m  71.9156\n",
      "      3        \u001b[36m4.0650\u001b[0m        \u001b[32m4.0707\u001b[0m  71.7418\n",
      "      4        \u001b[36m4.0051\u001b[0m        \u001b[32m4.0529\u001b[0m  73.6199\n",
      "      5        \u001b[36m3.9785\u001b[0m        \u001b[32m4.0387\u001b[0m  74.5445\n",
      "      6        \u001b[36m3.9599\u001b[0m        \u001b[32m4.0109\u001b[0m  74.4860\n",
      "      7        \u001b[36m3.9452\u001b[0m        \u001b[32m4.0011\u001b[0m  72.7338\n",
      "      8        \u001b[36m3.9340\u001b[0m        \u001b[32m3.9897\u001b[0m  74.2163\n",
      "      9        \u001b[36m3.9245\u001b[0m        3.9910  73.9905\n",
      "     10        \u001b[36m3.9156\u001b[0m        \u001b[32m3.9788\u001b[0m  77.6048\n",
      "     11        \u001b[36m3.9071\u001b[0m        \u001b[32m3.9715\u001b[0m  80.6734\n",
      "     12        \u001b[36m3.8989\u001b[0m        3.9742  79.0142\n",
      "     13        \u001b[36m3.8918\u001b[0m        \u001b[32m3.9690\u001b[0m  73.4953\n",
      "     14        \u001b[36m3.8852\u001b[0m        \u001b[32m3.9654\u001b[0m  76.5282\n",
      "     15        \u001b[36m3.8782\u001b[0m        \u001b[32m3.9570\u001b[0m  76.6049\n",
      "     16        \u001b[36m3.8717\u001b[0m        \u001b[32m3.9564\u001b[0m  76.4651\n",
      "     17        \u001b[36m3.8648\u001b[0m        3.9569  76.1926\n",
      "     18        \u001b[36m3.8588\u001b[0m        \u001b[32m3.9553\u001b[0m  75.4409\n",
      "     19        \u001b[36m3.8527\u001b[0m        3.9587  72.4091\n",
      "     20        \u001b[36m3.8469\u001b[0m        3.9591  73.7127\n",
      "20 RMSE: 1.9807051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2388\u001b[0m        \u001b[32m4.2285\u001b[0m  79.2169\n",
      "      2        \u001b[36m4.1538\u001b[0m        \u001b[32m4.0881\u001b[0m  82.6719\n",
      "      3        \u001b[36m4.0580\u001b[0m        \u001b[32m4.0388\u001b[0m  80.6415\n",
      "      4        \u001b[36m4.0214\u001b[0m        4.0607  78.5574\n",
      "      5        \u001b[36m3.9960\u001b[0m        4.0691  79.6206\n",
      "      6        \u001b[36m3.9774\u001b[0m        4.0555  79.3489\n",
      "      7        \u001b[36m3.9633\u001b[0m        \u001b[32m4.0255\u001b[0m  83.3891\n",
      "      8        \u001b[36m3.9495\u001b[0m        \u001b[32m4.0152\u001b[0m  86.1895\n",
      "      9        \u001b[36m3.9376\u001b[0m        \u001b[32m4.0000\u001b[0m  82.5287\n",
      "     10        \u001b[36m3.9261\u001b[0m        \u001b[32m3.9926\u001b[0m  81.2770\n",
      "     11        \u001b[36m3.9152\u001b[0m        \u001b[32m3.9858\u001b[0m  76.3901\n",
      "     12        \u001b[36m3.9058\u001b[0m        \u001b[32m3.9794\u001b[0m  75.5199\n",
      "     13        \u001b[36m3.8961\u001b[0m        \u001b[32m3.9675\u001b[0m  75.6628\n",
      "     14        \u001b[36m3.8879\u001b[0m        \u001b[32m3.9488\u001b[0m  76.4510\n",
      "     15        \u001b[36m3.8784\u001b[0m        3.9522  75.5859\n",
      "     16        \u001b[36m3.8699\u001b[0m        \u001b[32m3.9445\u001b[0m  76.0484\n",
      "     17        \u001b[36m3.8612\u001b[0m        \u001b[32m3.9424\u001b[0m  77.9874\n",
      "     18        \u001b[36m3.8527\u001b[0m        \u001b[32m3.9357\u001b[0m  75.8865\n",
      "     19        \u001b[36m3.8443\u001b[0m        \u001b[32m3.9351\u001b[0m  74.9615\n",
      "     20        \u001b[36m3.8373\u001b[0m        3.9358  75.1563\n",
      "40 RMSE: 1.9745121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2396\u001b[0m        \u001b[32m4.2318\u001b[0m  77.2851\n",
      "      2        \u001b[36m4.1572\u001b[0m        \u001b[32m4.0760\u001b[0m  78.9254\n",
      "      3        \u001b[36m4.0541\u001b[0m        \u001b[32m4.0428\u001b[0m  79.0983\n",
      "      4        \u001b[36m4.0071\u001b[0m        4.0507  78.8875\n",
      "      5        \u001b[36m3.9791\u001b[0m        \u001b[32m4.0120\u001b[0m  79.5298\n",
      "      6        \u001b[36m3.9628\u001b[0m        \u001b[32m4.0018\u001b[0m  79.2811\n",
      "      7        \u001b[36m3.9483\u001b[0m        \u001b[32m3.9941\u001b[0m  79.8515\n",
      "      8        \u001b[36m3.9364\u001b[0m        \u001b[32m3.9899\u001b[0m  79.5398\n",
      "      9        \u001b[36m3.9252\u001b[0m        \u001b[32m3.9884\u001b[0m  79.9694\n",
      "     10        \u001b[36m3.9132\u001b[0m        3.9889  79.7476\n",
      "     11        \u001b[36m3.9021\u001b[0m        \u001b[32m3.9795\u001b[0m  80.4539\n",
      "     12        \u001b[36m3.8905\u001b[0m        \u001b[32m3.9694\u001b[0m  80.4579\n",
      "     13        \u001b[36m3.8787\u001b[0m        \u001b[32m3.9550\u001b[0m  80.7416\n",
      "     14        \u001b[36m3.8674\u001b[0m        \u001b[32m3.9468\u001b[0m  80.5318\n",
      "     15        \u001b[36m3.8566\u001b[0m        \u001b[32m3.9402\u001b[0m  80.9014\n",
      "     16        \u001b[36m3.8454\u001b[0m        \u001b[32m3.9303\u001b[0m  81.0353\n",
      "     17        \u001b[36m3.8341\u001b[0m        \u001b[32m3.9296\u001b[0m  80.7326\n",
      "     18        \u001b[36m3.8236\u001b[0m        \u001b[32m3.9207\u001b[0m  80.2201\n",
      "     19        \u001b[36m3.8134\u001b[0m        \u001b[32m3.9174\u001b[0m  80.7486\n",
      "     20        \u001b[36m3.8032\u001b[0m        \u001b[32m3.9174\u001b[0m  81.6966\n",
      "60 RMSE: 1.9710656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2385\u001b[0m        \u001b[32m4.2273\u001b[0m  78.9924\n",
      "      2        \u001b[36m4.1531\u001b[0m        \u001b[32m4.0923\u001b[0m  81.6567\n",
      "      3        \u001b[36m4.0585\u001b[0m        \u001b[32m4.0410\u001b[0m  81.7755\n",
      "      4        \u001b[36m4.0240\u001b[0m        4.0445  81.5857\n",
      "      5        \u001b[36m3.9996\u001b[0m        4.0733  83.1641\n",
      "      6        \u001b[36m3.9807\u001b[0m        4.0608  82.2281\n",
      "      7        \u001b[36m3.9653\u001b[0m        \u001b[32m4.0281\u001b[0m  82.5797\n",
      "      8        \u001b[36m3.9526\u001b[0m        \u001b[32m4.0105\u001b[0m  82.2950\n",
      "      9        \u001b[36m3.9415\u001b[0m        \u001b[32m3.9936\u001b[0m  86.7859\n",
      "     10        \u001b[36m3.9311\u001b[0m        \u001b[32m3.9923\u001b[0m  88.0426\n",
      "     11        \u001b[36m3.9206\u001b[0m        \u001b[32m3.9882\u001b[0m  89.2056\n",
      "     12        \u001b[36m3.9096\u001b[0m        3.9940  87.6016\n",
      "     13        \u001b[36m3.8988\u001b[0m        \u001b[32m3.9787\u001b[0m  90.7241\n",
      "     14        \u001b[36m3.8877\u001b[0m        \u001b[32m3.9711\u001b[0m  88.6361\n",
      "     15        \u001b[36m3.8764\u001b[0m        \u001b[32m3.9510\u001b[0m  89.7344\n",
      "     16        \u001b[36m3.8655\u001b[0m        \u001b[32m3.9487\u001b[0m  88.9202\n",
      "     17        \u001b[36m3.8552\u001b[0m        \u001b[32m3.9473\u001b[0m  90.1149\n",
      "     18        \u001b[36m3.8440\u001b[0m        \u001b[32m3.9381\u001b[0m  90.1402\n",
      "     19        \u001b[36m3.8322\u001b[0m        \u001b[32m3.9367\u001b[0m  89.9144\n",
      "     20        \u001b[36m3.8209\u001b[0m        \u001b[32m3.9320\u001b[0m  90.0512\n",
      "80 RMSE: 1.9754355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2391\u001b[0m        \u001b[32m4.2305\u001b[0m  91.1037\n",
      "      2        \u001b[36m4.1597\u001b[0m        \u001b[32m4.0905\u001b[0m  91.6197\n",
      "      3        \u001b[36m4.0615\u001b[0m        \u001b[32m4.0427\u001b[0m  93.8118\n",
      "      4        \u001b[36m4.0231\u001b[0m        4.0615  87.9053\n",
      "      5        \u001b[36m3.9935\u001b[0m        4.0699  86.8324\n",
      "      6        \u001b[36m3.9718\u001b[0m        \u001b[32m4.0330\u001b[0m  87.2140\n",
      "      7        \u001b[36m3.9548\u001b[0m        \u001b[32m4.0091\u001b[0m  86.8603\n",
      "      8        \u001b[36m3.9406\u001b[0m        \u001b[32m3.9947\u001b[0m  87.4048\n",
      "      9        \u001b[36m3.9273\u001b[0m        \u001b[32m3.9923\u001b[0m  89.1830\n",
      "     10        \u001b[36m3.9141\u001b[0m        \u001b[32m3.9760\u001b[0m  89.6615\n",
      "     11        \u001b[36m3.9023\u001b[0m        \u001b[32m3.9703\u001b[0m  91.9635\n",
      "     12        \u001b[36m3.8905\u001b[0m        \u001b[32m3.9540\u001b[0m  91.1741\n",
      "     13        \u001b[36m3.8788\u001b[0m        \u001b[32m3.9364\u001b[0m  98.2098\n",
      "     14        \u001b[36m3.8668\u001b[0m        \u001b[32m3.9312\u001b[0m  100.5317\n",
      "     15        \u001b[36m3.8557\u001b[0m        \u001b[32m3.9287\u001b[0m  102.9728\n",
      "     16        \u001b[36m3.8440\u001b[0m        \u001b[32m3.9212\u001b[0m  102.4360\n",
      "     17        \u001b[36m3.8328\u001b[0m        \u001b[32m3.9139\u001b[0m  103.2598\n",
      "     18        \u001b[36m3.8209\u001b[0m        \u001b[32m3.9078\u001b[0m  104.4199\n",
      "     19        \u001b[36m3.8086\u001b[0m        \u001b[32m3.9056\u001b[0m  103.0884\n",
      "     20        \u001b[36m3.7965\u001b[0m        \u001b[32m3.9020\u001b[0m  101.5969\n",
      "100 RMSE: 1.966813\n",
      "Optimum parameters: 100 : 1.966813\n"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "num_unitslist = [5,10,20,40,60,80,100]\n",
    "rmselist = []\n",
    "x_trainshape = 5844\n",
    "for num in num_unitslist:\n",
    "    class RegressorModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                num_units=num,\n",
    "                nonlin=F.relu,\n",
    "        ):\n",
    "            super(RegressorModule, self).__init__()\n",
    "            self.num_units = num_units\n",
    "            self.nonlin = nonlin\n",
    "\n",
    "            self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "            self.nonlin = nonlin\n",
    "            self.dense1 = nn.Linear(num_units, num)\n",
    "            self.output = nn.Linear(num, 1)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = self.nonlin(self.dense0(X))\n",
    "            X = F.relu(self.dense1(X))\n",
    "            X = self.output(X)\n",
    "            return X\n",
    "\n",
    "    pole_model = RegressorModule()\n",
    "\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    def typechange(x):\n",
    "        return x.astype(dtype = np.float32)\n",
    "    typetransform = FunctionTransformer(typechange)\n",
    "    def inputneuron(x):\n",
    "        x_trainshape = x.shape[1]\n",
    "    #     return x_trainshape\n",
    "    inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "    # pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "    # pipe = Pipeline([('net', net)])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "    # net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "    pipe.fit(X=x_train, y=y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(num,'RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "\n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", num_unitslist[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-lawrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2400\u001b[0m        \u001b[32m4.2349\u001b[0m  92.0159\n",
      "      2        \u001b[36m4.1679\u001b[0m        \u001b[32m4.0870\u001b[0m  85.9619\n",
      "      3        \u001b[36m4.0655\u001b[0m        \u001b[32m4.0463\u001b[0m  86.0232\n",
      "      4        \u001b[36m4.0245\u001b[0m        4.0825  86.8104\n",
      "      5        \u001b[36m3.9895\u001b[0m        4.0646  86.8074\n",
      "      6        \u001b[36m3.9685\u001b[0m        \u001b[32m4.0370\u001b[0m  87.0012\n",
      "      7        \u001b[36m3.9520\u001b[0m        \u001b[32m4.0186\u001b[0m  87.0961\n",
      "      8        \u001b[36m3.9378\u001b[0m        \u001b[32m4.0053\u001b[0m  87.8753\n",
      "      9        \u001b[36m3.9241\u001b[0m        \u001b[32m3.9896\u001b[0m  88.3648\n",
      "     10        \u001b[36m3.9113\u001b[0m        \u001b[32m3.9748\u001b[0m  88.3633\n",
      "     11        \u001b[36m3.8975\u001b[0m        \u001b[32m3.9638\u001b[0m  88.4677\n",
      "     12        \u001b[36m3.8857\u001b[0m        \u001b[32m3.9472\u001b[0m  89.1810\n",
      "     13        \u001b[36m3.8727\u001b[0m        \u001b[32m3.9304\u001b[0m  88.9892\n",
      "     14        \u001b[36m3.8604\u001b[0m        \u001b[32m3.9296\u001b[0m  89.3078\n",
      "     15        \u001b[36m3.8487\u001b[0m        \u001b[32m3.9196\u001b[0m  89.7979\n",
      "     16        \u001b[36m3.8358\u001b[0m        \u001b[32m3.9140\u001b[0m  89.1660\n",
      "     17        \u001b[36m3.8247\u001b[0m        \u001b[32m3.9087\u001b[0m  90.3907\n",
      "     18        \u001b[36m3.8131\u001b[0m        \u001b[32m3.9043\u001b[0m  89.6515\n",
      "     19        \u001b[36m3.8003\u001b[0m        \u001b[32m3.9040\u001b[0m  89.7783\n",
      "     20        \u001b[36m3.7892\u001b[0m        \u001b[32m3.9036\u001b[0m  90.4496\n",
      "100 RMSE: 1.9672356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2404\u001b[0m        \u001b[32m4.2367\u001b[0m  93.9621\n",
      "      2        \u001b[36m4.1729\u001b[0m        \u001b[32m4.0900\u001b[0m  98.7672\n",
      "      3        \u001b[36m4.0641\u001b[0m        \u001b[32m4.0396\u001b[0m  100.5494\n",
      "      4        \u001b[36m4.0201\u001b[0m        4.0662  101.3396\n",
      "      5        \u001b[36m3.9864\u001b[0m        4.0495  102.4774\n",
      "      6        \u001b[36m3.9644\u001b[0m        \u001b[32m4.0194\u001b[0m  102.0998\n",
      "      7        \u001b[36m3.9469\u001b[0m        \u001b[32m4.0126\u001b[0m  103.4984\n",
      "      8        \u001b[36m3.9320\u001b[0m        \u001b[32m3.9969\u001b[0m  103.5693\n",
      "      9        \u001b[36m3.9183\u001b[0m        \u001b[32m3.9880\u001b[0m  104.2886\n",
      "     10        \u001b[36m3.9043\u001b[0m        \u001b[32m3.9684\u001b[0m  104.9279\n",
      "     11        \u001b[36m3.8921\u001b[0m        \u001b[32m3.9607\u001b[0m  105.2096\n",
      "     12        \u001b[36m3.8799\u001b[0m        \u001b[32m3.9442\u001b[0m  105.1257\n",
      "     13        \u001b[36m3.8668\u001b[0m        \u001b[32m3.9314\u001b[0m  105.1587\n",
      "     14        \u001b[36m3.8548\u001b[0m        \u001b[32m3.9287\u001b[0m  105.3505\n",
      "     15        \u001b[36m3.8428\u001b[0m        \u001b[32m3.9249\u001b[0m  106.5552\n",
      "     16        \u001b[36m3.8290\u001b[0m        \u001b[32m3.9216\u001b[0m  106.0408\n",
      "     17        \u001b[36m3.8154\u001b[0m        \u001b[32m3.9164\u001b[0m  106.3554\n",
      "     18        \u001b[36m3.8012\u001b[0m        3.9342  106.5722\n",
      "     19        \u001b[36m3.7894\u001b[0m        \u001b[32m3.9135\u001b[0m  107.3315\n",
      "     20        \u001b[36m3.7737\u001b[0m        3.9247  107.0697\n",
      "200 RMSE: 1.9712181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2399\u001b[0m        \u001b[32m4.2345\u001b[0m  108.4603\n",
      "      2        \u001b[36m4.1665\u001b[0m        \u001b[32m4.0825\u001b[0m  115.7239\n",
      "      3        \u001b[36m4.0586\u001b[0m        \u001b[32m4.0405\u001b[0m  116.4242\n",
      "      4        \u001b[36m4.0103\u001b[0m        4.0741  117.6959\n",
      "      5        \u001b[36m3.9782\u001b[0m        4.0457  119.1364\n",
      "      6        \u001b[36m3.9587\u001b[0m        \u001b[32m4.0234\u001b[0m  119.7767\n",
      "      7        \u001b[36m3.9423\u001b[0m        \u001b[32m4.0097\u001b[0m  122.2073\n",
      "      8        \u001b[36m3.9273\u001b[0m        \u001b[32m4.0000\u001b[0m  121.8047\n",
      "      9        \u001b[36m3.9136\u001b[0m        \u001b[32m3.9838\u001b[0m  121.4321\n",
      "     10        \u001b[36m3.8992\u001b[0m        \u001b[32m3.9753\u001b[0m  142.2142\n",
      "     11        \u001b[36m3.8844\u001b[0m        \u001b[32m3.9637\u001b[0m  135.8511\n",
      "     12        \u001b[36m3.8698\u001b[0m        \u001b[32m3.9499\u001b[0m  137.0353\n",
      "     13        \u001b[36m3.8545\u001b[0m        \u001b[32m3.9335\u001b[0m  134.7927\n",
      "     14        \u001b[36m3.8404\u001b[0m        \u001b[32m3.9290\u001b[0m  143.1794\n",
      "     15        \u001b[36m3.8242\u001b[0m        \u001b[32m3.9115\u001b[0m  142.0846\n",
      "     16        \u001b[36m3.8088\u001b[0m        \u001b[32m3.9070\u001b[0m  130.8611\n",
      "     17        \u001b[36m3.7929\u001b[0m        \u001b[32m3.9064\u001b[0m  128.0619\n",
      "     18        \u001b[36m3.7783\u001b[0m        3.9166  128.3500\n",
      "     19        \u001b[36m3.7618\u001b[0m        3.9187  128.7826\n",
      "     20        \u001b[36m3.7442\u001b[0m        3.9224  128.9923\n",
      "300 RMSE: 1.971892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2402\u001b[0m        \u001b[32m4.2361\u001b[0m  125.8431\n",
      "      2        \u001b[36m4.1690\u001b[0m        \u001b[32m4.0927\u001b[0m  137.5956\n",
      "      3        \u001b[36m4.0496\u001b[0m        \u001b[32m4.0618\u001b[0m  141.4147\n",
      "      4        \u001b[36m3.9983\u001b[0m        \u001b[32m4.0585\u001b[0m  140.2112\n",
      "      5        \u001b[36m3.9699\u001b[0m        \u001b[32m4.0304\u001b[0m  140.8877\n",
      "      6        \u001b[36m3.9504\u001b[0m        \u001b[32m4.0103\u001b[0m  142.7408\n",
      "      7        \u001b[36m3.9332\u001b[0m        \u001b[32m3.9957\u001b[0m  143.5305\n",
      "      8        \u001b[36m3.9182\u001b[0m        \u001b[32m3.9802\u001b[0m  145.4078\n",
      "      9        \u001b[36m3.9043\u001b[0m        \u001b[32m3.9672\u001b[0m  146.3578\n",
      "     10        \u001b[36m3.8901\u001b[0m        \u001b[32m3.9596\u001b[0m  148.8581\n",
      "     11        \u001b[36m3.8748\u001b[0m        \u001b[32m3.9399\u001b[0m  149.5834\n",
      "     12        \u001b[36m3.8603\u001b[0m        3.9402  149.5563\n",
      "     13        \u001b[36m3.8452\u001b[0m        \u001b[32m3.9158\u001b[0m  149.3066\n",
      "     14        \u001b[36m3.8287\u001b[0m        \u001b[32m3.9057\u001b[0m  149.4954\n",
      "     15        \u001b[36m3.8134\u001b[0m        3.9114  150.1148\n",
      "     16        \u001b[36m3.7973\u001b[0m        3.9133  151.4694\n",
      "     17        \u001b[36m3.7800\u001b[0m        \u001b[32m3.9032\u001b[0m  150.9599\n",
      "     18        \u001b[36m3.7646\u001b[0m        3.9087  150.8290\n",
      "     19        \u001b[36m3.7462\u001b[0m        3.9043  152.3475\n",
      "     20        \u001b[36m3.7311\u001b[0m        3.9144  152.0398\n",
      "400 RMSE: 1.9702251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2399\u001b[0m        \u001b[32m4.2351\u001b[0m  156.5172\n",
      "      2        \u001b[36m4.1675\u001b[0m        \u001b[32m4.0858\u001b[0m  171.3881\n",
      "      3        \u001b[36m4.0518\u001b[0m        \u001b[32m4.0569\u001b[0m  173.1822\n",
      "      4        \u001b[36m4.0007\u001b[0m        4.0602  175.5458\n",
      "      5        \u001b[36m3.9710\u001b[0m        \u001b[32m4.0321\u001b[0m  178.8005\n",
      "      6        \u001b[36m3.9506\u001b[0m        \u001b[32m4.0164\u001b[0m  181.9323\n",
      "      7        \u001b[36m3.9329\u001b[0m        \u001b[32m3.9993\u001b[0m  182.9203\n",
      "      8        \u001b[36m3.9172\u001b[0m        \u001b[32m3.9828\u001b[0m  184.6835\n",
      "      9        \u001b[36m3.9022\u001b[0m        \u001b[32m3.9682\u001b[0m  186.1550\n",
      "     10        \u001b[36m3.8869\u001b[0m        \u001b[32m3.9595\u001b[0m  193.2193\n",
      "     11        \u001b[36m3.8714\u001b[0m        \u001b[32m3.9473\u001b[0m  195.5246\n",
      "     12        \u001b[36m3.8554\u001b[0m        \u001b[32m3.9248\u001b[0m  196.6167\n",
      "     13        \u001b[36m3.8388\u001b[0m        \u001b[32m3.9115\u001b[0m  197.8036\n",
      "     14        \u001b[36m3.8197\u001b[0m        \u001b[32m3.9078\u001b[0m  199.8828\n",
      "     15        \u001b[36m3.8015\u001b[0m        3.9106  200.4695\n",
      "     16        \u001b[36m3.7852\u001b[0m        \u001b[32m3.8969\u001b[0m  201.7175\n",
      "     17        \u001b[36m3.7648\u001b[0m        3.9003  202.7969\n",
      "     18        \u001b[36m3.7457\u001b[0m        3.9154  216.0335\n",
      "     19        \u001b[36m3.7268\u001b[0m        3.9220  218.1577\n",
      "     20        \u001b[36m3.7103\u001b[0m        3.9425  217.9451\n",
      "600 RMSE: 1.9759843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2391\u001b[0m        \u001b[32m4.2313\u001b[0m  213.8890\n",
      "      2        \u001b[36m4.1584\u001b[0m        \u001b[32m4.0764\u001b[0m  229.8191\n",
      "      3        \u001b[36m4.0450\u001b[0m        \u001b[32m4.0637\u001b[0m  233.7261\n",
      "      4        \u001b[36m3.9954\u001b[0m        \u001b[32m4.0567\u001b[0m  229.0162\n",
      "      5        \u001b[36m3.9667\u001b[0m        \u001b[32m4.0350\u001b[0m  232.6707\n",
      "      6        \u001b[36m3.9468\u001b[0m        \u001b[32m4.0185\u001b[0m  234.1069\n",
      "      7        \u001b[36m3.9288\u001b[0m        \u001b[32m3.9933\u001b[0m  240.0113\n",
      "      8        \u001b[36m3.9130\u001b[0m        \u001b[32m3.9696\u001b[0m  243.5466\n",
      "      9        \u001b[36m3.8967\u001b[0m        \u001b[32m3.9589\u001b[0m  256.2258\n",
      "     10        \u001b[36m3.8825\u001b[0m        \u001b[32m3.9462\u001b[0m  240.1301\n",
      "     11        \u001b[36m3.8670\u001b[0m        \u001b[32m3.9271\u001b[0m  258.7098\n",
      "     12        \u001b[36m3.8487\u001b[0m        \u001b[32m3.9254\u001b[0m  236.7620\n",
      "     13        \u001b[36m3.8332\u001b[0m        3.9296  236.2105\n",
      "     14        \u001b[36m3.8158\u001b[0m        \u001b[32m3.9235\u001b[0m  233.9563\n",
      "     15        \u001b[36m3.7968\u001b[0m        \u001b[32m3.9062\u001b[0m  236.0631\n",
      "     16        \u001b[36m3.7778\u001b[0m        3.9125  238.1893\n",
      "     17        \u001b[36m3.7584\u001b[0m        3.9163  244.1232\n",
      "     18        \u001b[36m3.7387\u001b[0m        3.9474  244.0335\n",
      "     19        \u001b[36m3.7224\u001b[0m        3.9516  247.8189\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "800 RMSE: 1.9796176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2381\u001b[0m        \u001b[32m4.2269\u001b[0m  224.4839\n",
      "      2        \u001b[36m4.1489\u001b[0m        \u001b[32m4.0696\u001b[0m  245.9677\n",
      "      3        \u001b[36m4.0397\u001b[0m        4.0700  248.6130\n",
      "      4        \u001b[36m3.9918\u001b[0m        \u001b[32m4.0525\u001b[0m  251.7387\n",
      "      5        \u001b[36m3.9643\u001b[0m        \u001b[32m4.0327\u001b[0m  255.7215\n",
      "      6        \u001b[36m3.9435\u001b[0m        \u001b[32m4.0125\u001b[0m  260.7315\n",
      "      7        \u001b[36m3.9271\u001b[0m        \u001b[32m3.9862\u001b[0m  261.2781\n",
      "      8        \u001b[36m3.9108\u001b[0m        \u001b[32m3.9743\u001b[0m  263.9237\n",
      "      9        \u001b[36m3.8942\u001b[0m        \u001b[32m3.9611\u001b[0m  266.4313\n",
      "     10        \u001b[36m3.8770\u001b[0m        \u001b[32m3.9393\u001b[0m  270.6940\n",
      "     11        \u001b[36m3.8605\u001b[0m        \u001b[32m3.9182\u001b[0m  271.3745\n",
      "     12        \u001b[36m3.8433\u001b[0m        \u001b[32m3.9181\u001b[0m  273.7034\n",
      "     13        \u001b[36m3.8252\u001b[0m        3.9212  276.7941\n",
      "     14        \u001b[36m3.8054\u001b[0m        \u001b[32m3.9083\u001b[0m  279.4823\n",
      "     15        \u001b[36m3.7867\u001b[0m        \u001b[32m3.9078\u001b[0m  279.7796\n",
      "     16        \u001b[36m3.7666\u001b[0m        \u001b[32m3.9073\u001b[0m  280.6836\n",
      "     17        \u001b[36m3.7507\u001b[0m        3.9226  284.0996\n",
      "     18        \u001b[36m3.7307\u001b[0m        3.9301  284.4537\n",
      "     19        \u001b[36m3.7120\u001b[0m        3.9542  284.0531\n",
      "     20        \u001b[36m3.6931\u001b[0m        3.9396  285.4355\n",
      "1000 RMSE: 1.976405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2372\u001b[0m        \u001b[32m4.2231\u001b[0m  409.3780\n",
      "      2        \u001b[36m4.1419\u001b[0m        \u001b[32m4.0745\u001b[0m  452.1870\n",
      "      3        \u001b[36m4.0287\u001b[0m        \u001b[32m4.0741\u001b[0m  462.6691\n",
      "      4        \u001b[36m3.9826\u001b[0m        \u001b[32m4.0414\u001b[0m  470.1256\n",
      "      5        \u001b[36m3.9560\u001b[0m        \u001b[32m4.0195\u001b[0m  473.1667\n",
      "      6        \u001b[36m3.9350\u001b[0m        \u001b[32m3.9969\u001b[0m  484.9315\n",
      "      7        \u001b[36m3.9169\u001b[0m        \u001b[32m3.9787\u001b[0m  488.8946\n",
      "      8        \u001b[36m3.8990\u001b[0m        \u001b[32m3.9625\u001b[0m  495.3867\n",
      "      9        \u001b[36m3.8822\u001b[0m        \u001b[32m3.9501\u001b[0m  500.7652\n",
      "     10        \u001b[36m3.8632\u001b[0m        \u001b[32m3.9201\u001b[0m  504.7763\n",
      "     11        \u001b[36m3.8445\u001b[0m        \u001b[32m3.9083\u001b[0m  509.1069\n",
      "     12        \u001b[36m3.8249\u001b[0m        3.9220  514.7958\n",
      "     13        \u001b[36m3.8040\u001b[0m        \u001b[32m3.9000\u001b[0m  516.5440\n",
      "     14        \u001b[36m3.7845\u001b[0m        3.9143  518.5792\n",
      "     15        \u001b[36m3.7675\u001b[0m        3.9222  522.4646\n"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "num_unitslist = [100,200,300,400,600,800,1000,2000]\n",
    "rmselist = []\n",
    "x_trainshape = 5842\n",
    "for num in num_unitslist:\n",
    "    class RegressorModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                num_units=num,\n",
    "                nonlin=F.relu,\n",
    "        ):\n",
    "            super(RegressorModule, self).__init__()\n",
    "            self.num_units = num_units\n",
    "            self.nonlin = nonlin\n",
    "\n",
    "            self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "            self.nonlin = nonlin\n",
    "            self.dense1 = nn.Linear(num_units, num)\n",
    "            self.output = nn.Linear(num, 1)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = self.nonlin(self.dense0(X))\n",
    "            X = F.relu(self.dense1(X))\n",
    "            X = self.output(X)\n",
    "            return X\n",
    "\n",
    "    pole_model = RegressorModule()\n",
    "\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    def typechange(x):\n",
    "        return x.astype(dtype = np.float32)\n",
    "    typetransform = FunctionTransformer(typechange)\n",
    "    def inputneuron(x):\n",
    "        x_trainshape = x.shape[1]\n",
    "    #     return x_trainshape\n",
    "    inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "    # pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "    # pipe = Pipeline([('net', net)])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "    # net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "    pipe.fit(X=x_train, y=y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(num,'RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "\n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", num_unitslist[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2339\u001b[0m        \u001b[32m4.2108\u001b[0m  924.6559\n",
      "      2        \u001b[36m4.1215\u001b[0m        \u001b[32m4.0817\u001b[0m  1004.0532\n",
      "      3        \u001b[36m4.0133\u001b[0m        \u001b[32m4.0655\u001b[0m  1023.2181\n",
      "      4        \u001b[36m3.9705\u001b[0m        \u001b[32m4.0284\u001b[0m  1039.7722\n",
      "      5        \u001b[36m3.9438\u001b[0m        \u001b[32m3.9999\u001b[0m  1057.6827\n",
      "      6        \u001b[36m3.9219\u001b[0m        \u001b[32m3.9779\u001b[0m  1069.0412\n",
      "      7        \u001b[36m3.9018\u001b[0m        \u001b[32m3.9700\u001b[0m  1076.0810\n",
      "      8        \u001b[36m3.8821\u001b[0m        \u001b[32m3.9541\u001b[0m  1084.8490\n",
      "      9        \u001b[36m3.8622\u001b[0m        \u001b[32m3.9219\u001b[0m  1098.4077\n",
      "     10        \u001b[36m3.8425\u001b[0m        \u001b[32m3.9086\u001b[0m  1103.2073\n",
      "     11        \u001b[36m3.8222\u001b[0m        3.9155  1107.1452\n",
      "     12        \u001b[36m3.8017\u001b[0m        \u001b[32m3.8990\u001b[0m  1116.9342\n",
      "     13        \u001b[36m3.7809\u001b[0m        3.9064  1122.8589\n",
      "     14        \u001b[36m3.7608\u001b[0m        3.9109  1125.3985\n",
      "     15        \u001b[36m3.7406\u001b[0m        3.9445  1126.2846\n",
      "     16        \u001b[36m3.7189\u001b[0m        3.9519  1130.1317\n"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "num_unitslist = [3896,11688]\n",
    "rmselist = []\n",
    "x_trainshape = 5844\n",
    "for num in num_unitslist:\n",
    "    class RegressorModule(nn.Module):\n",
    "        def __init__(\n",
    "                self,\n",
    "                num_units=num,\n",
    "                nonlin=F.relu,\n",
    "        ):\n",
    "            super(RegressorModule, self).__init__()\n",
    "            self.num_units = num_units\n",
    "            self.nonlin = nonlin\n",
    "\n",
    "            self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "            self.nonlin = nonlin\n",
    "            self.dense1 = nn.Linear(num_units, num)\n",
    "            self.output = nn.Linear(num, 1)\n",
    "\n",
    "        def forward(self, X, **kwargs):\n",
    "            X = self.nonlin(self.dense0(X))\n",
    "            X = F.relu(self.dense1(X))\n",
    "            X = self.output(X)\n",
    "            return X\n",
    "\n",
    "    pole_model = RegressorModule()\n",
    "\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    def typechange(x):\n",
    "        return x.astype(dtype = np.float32)\n",
    "    typetransform = FunctionTransformer(typechange)\n",
    "    def inputneuron(x):\n",
    "        x_trainshape = x.shape[1]\n",
    "    #     return x_trainshape\n",
    "    inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "    # pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "    # pipe = Pipeline([('net', net)])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "    # net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "    pipe.fit(X=x_train, y=y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(num,'RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "\n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", num_unitslist[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "induced-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71518.68]\n",
      "[35764.336]\n"
     ]
    }
   ],
   "source": [
    "profit = 0\n",
    "for i, (real, pred) in enumerate(zip(y_test, y_pred)):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        realchange = y_test[i] - y_test[i-1]\n",
    "        invest  = (y_pred[i] - y_pred[i-1])\n",
    "        change = (invest * realchange)\n",
    "        profit += change\n",
    "print(profit)\n",
    "profit = 0           \n",
    "for i, (real, pred) in enumerate(zip(y_test, y_pred)):\n",
    "    realmean = y_test.mean()\n",
    "    predmean = y_pred.mean()\n",
    "    realchange = real - realmean\n",
    "    predchange = pred - predmean\n",
    "    change = (predchange * realchange)\n",
    "    profit += change\n",
    "print(profit)\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "composite-deficit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<scipy.stats._distn_infrastructure.rv_frozen object at 0x00000246D1FE4D90>\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform, uniform\n",
    "print(uniform(20, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acquired-lambda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8071\u001b[0m        \u001b[32m3.8260\u001b[0m  51.2935\n",
      "      2        \u001b[36m3.7947\u001b[0m        3.8399  51.5512\n",
      "      3        \u001b[36m3.7888\u001b[0m        3.8498  51.6012\n",
      "      4        \u001b[36m3.7835\u001b[0m        3.8568  52.3434\n",
      "      5        \u001b[36m3.7780\u001b[0m        3.8655  51.8709\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8190\u001b[0m        \u001b[32m3.9146\u001b[0m  51.4773\n",
      "      2        \u001b[36m3.8059\u001b[0m        \u001b[32m3.9112\u001b[0m  51.8639\n",
      "      3        \u001b[36m3.7988\u001b[0m        3.9343  52.0787\n",
      "      4        \u001b[36m3.7930\u001b[0m        3.9281  52.5502\n",
      "      5        \u001b[36m3.7889\u001b[0m        3.9176  52.0397\n",
      "      6        \u001b[36m3.7838\u001b[0m        3.9211  51.9718\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8266\u001b[0m        \u001b[32m3.9289\u001b[0m  51.4523\n",
      "      2        \u001b[36m3.8154\u001b[0m        \u001b[32m3.9252\u001b[0m  52.3564\n",
      "      3        \u001b[36m3.8070\u001b[0m        \u001b[32m3.9100\u001b[0m  51.6252\n",
      "      4        \u001b[36m3.8006\u001b[0m        3.9159  52.0278\n",
      "      5        \u001b[36m3.7969\u001b[0m        3.9256  52.2226\n",
      "      6        \u001b[36m3.7921\u001b[0m        3.9314  52.1246\n",
      "      7        \u001b[36m3.7867\u001b[0m        3.9319  52.3195\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8173\u001b[0m        \u001b[32m3.9047\u001b[0m  51.3115\n",
      "      2        \u001b[36m3.8044\u001b[0m        3.9126  52.3594\n",
      "      3        \u001b[36m3.7976\u001b[0m        3.9213  51.6651\n",
      "      4        \u001b[36m3.7906\u001b[0m        3.9209  52.3384\n",
      "      5        \u001b[36m3.7860\u001b[0m        3.9157  52.6102\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8104\u001b[0m        \u001b[32m3.9196\u001b[0m  51.7940\n",
      "      2        \u001b[36m3.7974\u001b[0m        3.9375  52.2116\n",
      "      3        \u001b[36m3.7900\u001b[0m        3.9397  51.8380\n",
      "      4        \u001b[36m3.7832\u001b[0m        3.9362  52.3255\n",
      "      5        \u001b[36m3.7795\u001b[0m        3.9407  52.5123\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8450\u001b[0m        \u001b[32m3.8743\u001b[0m  51.5342\n",
      "      2        \u001b[36m3.8289\u001b[0m        3.8917  51.7670\n",
      "      3        \u001b[36m3.8230\u001b[0m        3.8805  52.0547\n",
      "      4        \u001b[36m3.8130\u001b[0m        \u001b[32m3.8728\u001b[0m  52.0367\n",
      "      5        \u001b[36m3.8031\u001b[0m        \u001b[32m3.8565\u001b[0m  52.5552\n",
      "      6        \u001b[36m3.7952\u001b[0m        3.8701  52.3145\n",
      "      7        \u001b[36m3.7931\u001b[0m        3.8684  52.2465\n",
      "      8        \u001b[36m3.7865\u001b[0m        3.8623  52.1247\n",
      "      9        \u001b[36m3.7830\u001b[0m        3.8615  52.2855\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8532\u001b[0m        \u001b[32m3.9413\u001b[0m  50.9069\n",
      "      2        \u001b[36m3.8362\u001b[0m        \u001b[32m3.9281\u001b[0m  51.8569\n",
      "      3        \u001b[36m3.8270\u001b[0m        3.9391  51.7830\n",
      "      4        \u001b[36m3.8169\u001b[0m        3.9503  51.8010\n",
      "      5        \u001b[36m3.8110\u001b[0m        3.9546  51.7940\n",
      "      6        \u001b[36m3.8069\u001b[0m        3.9606  52.3354\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8619\u001b[0m        \u001b[32m3.9467\u001b[0m  51.3055\n",
      "      2        \u001b[36m3.8493\u001b[0m        3.9664  51.7960\n",
      "      3        \u001b[36m3.8362\u001b[0m        \u001b[32m3.9442\u001b[0m  52.1127\n",
      "      4        \u001b[36m3.8274\u001b[0m        \u001b[32m3.9360\u001b[0m  51.9099\n",
      "      5        \u001b[36m3.8176\u001b[0m        \u001b[32m3.9273\u001b[0m  52.4323\n",
      "      6        \u001b[36m3.8118\u001b[0m        3.9477  52.4333\n",
      "      7        \u001b[36m3.8063\u001b[0m        3.9363  52.0737\n",
      "      8        \u001b[36m3.8004\u001b[0m        3.9559  52.5133\n",
      "      9        \u001b[36m3.7960\u001b[0m        3.9503  51.5712\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8546\u001b[0m        \u001b[32m3.9312\u001b[0m  52.1436\n",
      "      2        \u001b[36m3.8337\u001b[0m        3.9403  52.1776\n",
      "      3        \u001b[36m3.8256\u001b[0m        3.9435  52.1536\n",
      "      4        \u001b[36m3.8173\u001b[0m        3.9361  51.6981\n",
      "      5        \u001b[36m3.8074\u001b[0m        \u001b[32m3.9260\u001b[0m  51.9019\n",
      "      6        \u001b[36m3.8013\u001b[0m        \u001b[32m3.9238\u001b[0m  52.1376\n",
      "      7        \u001b[36m3.7981\u001b[0m        3.9375  52.4004\n",
      "      8        \u001b[36m3.7913\u001b[0m        3.9496  51.7650\n",
      "      9        \u001b[36m3.7854\u001b[0m        3.9437  51.6641\n",
      "     10        \u001b[36m3.7807\u001b[0m        3.9638  51.9718\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8455\u001b[0m        \u001b[32m3.9573\u001b[0m  51.3954\n",
      "      2        \u001b[36m3.8260\u001b[0m        \u001b[32m3.9422\u001b[0m  51.9968\n",
      "      3        \u001b[36m3.8176\u001b[0m        \u001b[32m3.9299\u001b[0m  52.1546\n",
      "      4        \u001b[36m3.8091\u001b[0m        3.9518  51.8270\n",
      "      5        \u001b[36m3.8005\u001b[0m        3.9410  51.7740\n",
      "      6        \u001b[36m3.7954\u001b[0m        3.9640  52.6002\n",
      "      7        \u001b[36m3.7873\u001b[0m        3.9417  51.9438\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8227\u001b[0m        \u001b[32m3.8559\u001b[0m  51.2136\n",
      "      2        \u001b[36m3.8122\u001b[0m        \u001b[32m3.8478\u001b[0m  51.7191\n",
      "      3        \u001b[36m3.8045\u001b[0m        3.8634  51.7610\n",
      "      4        \u001b[36m3.7983\u001b[0m        3.8701  52.2096\n",
      "      5        \u001b[36m3.7907\u001b[0m        3.8647  51.9209\n",
      "      6        \u001b[36m3.7840\u001b[0m        3.8745  51.9039\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8355\u001b[0m        \u001b[32m3.9321\u001b[0m  51.6831\n",
      "      2        \u001b[36m3.8215\u001b[0m        3.9347  51.8010\n",
      "      3        \u001b[36m3.8098\u001b[0m        3.9372  51.8210\n",
      "      4        \u001b[36m3.8057\u001b[0m        3.9642  51.7361\n",
      "      5        \u001b[36m3.7980\u001b[0m        3.9384  52.5472\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8437\u001b[0m        \u001b[32m3.9367\u001b[0m  52.3574\n",
      "      2        \u001b[36m3.8289\u001b[0m        3.9368  52.2705\n",
      "      3        \u001b[36m3.8202\u001b[0m        3.9424  52.2795\n",
      "      4        \u001b[36m3.8139\u001b[0m        \u001b[32m3.9276\u001b[0m  51.7151\n",
      "      5        \u001b[36m3.8072\u001b[0m        \u001b[32m3.9226\u001b[0m  52.0467\n",
      "      6        \u001b[36m3.8004\u001b[0m        3.9249  52.0058\n",
      "      7        \u001b[36m3.7969\u001b[0m        3.9339  52.4363\n",
      "      8        \u001b[36m3.7918\u001b[0m        3.9396  51.8080\n",
      "      9        \u001b[36m3.7872\u001b[0m        3.9312  52.2475\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8343\u001b[0m        \u001b[32m3.9377\u001b[0m  51.5103\n",
      "      2        \u001b[36m3.8213\u001b[0m        \u001b[32m3.9255\u001b[0m  51.7240\n",
      "      3        \u001b[36m3.8108\u001b[0m        \u001b[32m3.9205\u001b[0m  52.0917\n",
      "      4        \u001b[36m3.8044\u001b[0m        3.9299  51.5682\n",
      "      5        \u001b[36m3.7995\u001b[0m        3.9458  51.8000\n",
      "      6        \u001b[36m3.7918\u001b[0m        3.9385  51.7890\n",
      "      7        \u001b[36m3.7878\u001b[0m        3.9321  51.8160\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8245\u001b[0m        \u001b[32m3.9438\u001b[0m  51.2735\n",
      "      2        \u001b[36m3.8110\u001b[0m        \u001b[32m3.9308\u001b[0m  51.5632\n",
      "      3        \u001b[36m3.8034\u001b[0m        \u001b[32m3.9246\u001b[0m  52.6042\n",
      "      4        \u001b[36m3.7939\u001b[0m        3.9252  51.8340\n",
      "      5        \u001b[36m3.7874\u001b[0m        \u001b[32m3.9229\u001b[0m  52.0178\n",
      "      6        \u001b[36m3.7823\u001b[0m        3.9395  51.6332\n",
      "      7        \u001b[36m3.7790\u001b[0m        3.9317  52.4643\n",
      "      8        \u001b[36m3.7733\u001b[0m        3.9603  51.7660\n",
      "      9        \u001b[36m3.7689\u001b[0m        3.9619  52.0877\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.0433\u001b[0m        \u001b[32m3.9715\u001b[0m  52.2285\n",
      "      2        \u001b[36m4.0104\u001b[0m        \u001b[32m3.9708\u001b[0m  51.9259\n",
      "      3        \u001b[36m4.0040\u001b[0m        3.9755  52.2046\n",
      "      4        \u001b[36m3.9941\u001b[0m        3.9721  52.4793\n",
      "      5        \u001b[36m3.9839\u001b[0m        \u001b[32m3.9623\u001b[0m  52.3474\n",
      "      6        \u001b[36m3.9815\u001b[0m        3.9714  52.2845\n",
      "      7        \u001b[36m3.9788\u001b[0m        3.9655  52.1107\n",
      "      8        \u001b[36m3.9760\u001b[0m        3.9801  52.7560\n",
      "      9        \u001b[36m3.9737\u001b[0m        3.9666  52.6531\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2188\u001b[0m        \u001b[32m4.2394\u001b[0m  51.8539\n",
      "      2        4.2795        4.2394  53.0537\n",
      "      3        4.2795        4.2394  53.1017\n",
      "      4        4.2795        4.2394  53.0237\n",
      "      5        4.2795        4.2394  53.3504\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.1015\u001b[0m        \u001b[32m4.0139\u001b[0m  51.7061\n",
      "      2        \u001b[36m4.0982\u001b[0m        \u001b[32m4.0076\u001b[0m  51.8909\n",
      "      3        \u001b[36m4.0248\u001b[0m        \u001b[32m3.9764\u001b[0m  52.7181\n",
      "      4        \u001b[36m4.0032\u001b[0m        3.9999  51.9998\n",
      "      5        \u001b[36m3.9882\u001b[0m        \u001b[32m3.9640\u001b[0m  52.2455\n",
      "      6        3.9892        \u001b[32m3.9609\u001b[0m  52.3304\n",
      "      7        4.0519        3.9676  51.8819\n",
      "      8        \u001b[36m3.9696\u001b[0m        3.9627  52.5952\n",
      "      9        4.0314        3.9851  52.9288\n",
      "     10        3.9713        3.9697  52.2465\n",
      "     11        \u001b[36m3.9636\u001b[0m        \u001b[32m3.9498\u001b[0m  52.2046\n",
      "     12        \u001b[36m3.9453\u001b[0m        3.9564  51.9049\n",
      "     13        \u001b[36m3.9430\u001b[0m        \u001b[32m3.9484\u001b[0m  52.4723\n",
      "     14        \u001b[36m3.9344\u001b[0m        3.9488  52.4793\n",
      "     15        3.9404        3.9521  52.5912\n",
      "     16        3.9386        3.9497  52.1576\n",
      "     17        \u001b[36m3.9295\u001b[0m        3.9550  52.1057\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.1532\u001b[0m        \u001b[32m4.1242\u001b[0m  51.8929\n",
      "      2        \u001b[36m4.1388\u001b[0m        \u001b[32m4.0184\u001b[0m  52.6351\n",
      "      3        \u001b[36m4.0148\u001b[0m        \u001b[32m3.9905\u001b[0m  52.4134\n",
      "      4        4.0237        4.0076  52.6541\n",
      "      5        \u001b[36m4.0033\u001b[0m        3.9946  52.1097\n",
      "      6        \u001b[36m3.9971\u001b[0m        \u001b[32m3.9752\u001b[0m  52.1426\n",
      "      7        \u001b[36m3.9873\u001b[0m        3.9854  52.6701\n",
      "      8        \u001b[36m3.9736\u001b[0m        \u001b[32m3.9690\u001b[0m  52.4573\n",
      "      9        \u001b[36m3.9603\u001b[0m        \u001b[32m3.9611\u001b[0m  52.2745\n",
      "     10        4.0330        3.9791  52.8809\n",
      "     11        3.9718        4.0052  52.6921\n",
      "     12        3.9637        3.9906  53.0607\n",
      "     13        3.9645        3.9649  52.9888\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.1461\u001b[0m        \u001b[32m4.2895\u001b[0m  51.3604\n",
      "      2        \u001b[36m4.0726\u001b[0m        \u001b[32m4.2487\u001b[0m  52.2525\n",
      "      3        4.1374        \u001b[32m4.1648\u001b[0m  52.3324\n",
      "      4        4.1411        4.1693  52.5782\n",
      "      5        \u001b[36m4.0426\u001b[0m        4.2154  52.4693\n",
      "      6        \u001b[36m4.0172\u001b[0m        \u001b[32m4.0934\u001b[0m  51.6172\n",
      "      7        \u001b[36m4.0122\u001b[0m        \u001b[32m4.0776\u001b[0m  52.3974\n",
      "      8        \u001b[36m3.9724\u001b[0m        4.1787  52.5282\n",
      "      9        3.9844        \u001b[32m4.0495\u001b[0m  51.6911\n",
      "     10        \u001b[36m3.9620\u001b[0m        4.1106  52.3794\n",
      "     11        \u001b[36m3.9492\u001b[0m        4.0843  52.2545\n",
      "     12        \u001b[36m3.9439\u001b[0m        4.0916  52.3474\n",
      "     13        \u001b[36m3.9433\u001b[0m        4.1067  52.7071\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9876\u001b[0m        \u001b[32m3.9508\u001b[0m  51.8260\n",
      "      2        \u001b[36m3.9428\u001b[0m        3.9737  53.1926\n",
      "      3        \u001b[36m3.9264\u001b[0m        3.9529  52.8000\n",
      "      4        \u001b[36m3.9136\u001b[0m        \u001b[32m3.9198\u001b[0m  52.4743\n",
      "      5        \u001b[36m3.9038\u001b[0m        \u001b[32m3.9014\u001b[0m  52.6002\n",
      "      6        \u001b[36m3.8963\u001b[0m        3.9099  52.5522\n",
      "      7        \u001b[36m3.8860\u001b[0m        3.9165  52.8369\n",
      "      8        \u001b[36m3.8792\u001b[0m        3.9296  52.0168\n",
      "      9        \u001b[36m3.8747\u001b[0m        3.9266  52.7480\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9698\u001b[0m        \u001b[32m3.9723\u001b[0m  51.8160\n",
      "      2        \u001b[36m3.9450\u001b[0m        3.9837  52.4224\n",
      "      3        \u001b[36m3.9230\u001b[0m        \u001b[32m3.9628\u001b[0m  53.9848\n",
      "      4        \u001b[36m3.9079\u001b[0m        \u001b[32m3.9502\u001b[0m  52.9348\n",
      "      5        \u001b[36m3.8937\u001b[0m        3.9546  53.3114\n",
      "      6        \u001b[36m3.8829\u001b[0m        \u001b[32m3.9440\u001b[0m  52.9178\n",
      "      7        \u001b[36m3.8776\u001b[0m        \u001b[32m3.9427\u001b[0m  53.0617\n",
      "      8        \u001b[36m3.8670\u001b[0m        \u001b[32m3.9380\u001b[0m  53.1176\n",
      "      9        \u001b[36m3.8606\u001b[0m        3.9381  52.3334\n",
      "     10        \u001b[36m3.8543\u001b[0m        3.9414  52.8809\n",
      "     11        \u001b[36m3.8474\u001b[0m        \u001b[32m3.9373\u001b[0m  52.6152\n",
      "     12        \u001b[36m3.8396\u001b[0m        \u001b[32m3.9285\u001b[0m  52.7450\n",
      "     13        \u001b[36m3.8354\u001b[0m        3.9353  53.1226\n",
      "     14        \u001b[36m3.8351\u001b[0m        3.9311  52.5672\n",
      "     15        \u001b[36m3.8317\u001b[0m        3.9384  52.8759\n",
      "     16        \u001b[36m3.8291\u001b[0m        3.9410  52.8299\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9733\u001b[0m        \u001b[32m3.9642\u001b[0m  52.1147\n",
      "      2        \u001b[36m3.9555\u001b[0m        3.9696  52.7031\n",
      "      3        \u001b[36m3.9341\u001b[0m        \u001b[32m3.9528\u001b[0m  52.5712\n",
      "      4        \u001b[36m3.9131\u001b[0m        3.9592  52.5822\n",
      "      5        \u001b[36m3.8954\u001b[0m        3.9562  52.6661\n",
      "      6        \u001b[36m3.8836\u001b[0m        \u001b[32m3.9306\u001b[0m  52.8979\n",
      "      7        \u001b[36m3.8727\u001b[0m        3.9975  52.7380\n",
      "      8        \u001b[36m3.8677\u001b[0m        3.9466  52.3275\n",
      "      9        \u001b[36m3.8552\u001b[0m        3.9510  52.7470\n",
      "     10        \u001b[36m3.8489\u001b[0m        3.9625  52.3724\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9555\u001b[0m        \u001b[32m4.0601\u001b[0m  51.8289\n",
      "      2        \u001b[36m3.9236\u001b[0m        \u001b[32m3.9557\u001b[0m  52.1117\n",
      "      3        \u001b[36m3.9099\u001b[0m        \u001b[32m3.9514\u001b[0m  52.3914\n",
      "      4        \u001b[36m3.8889\u001b[0m        \u001b[32m3.9455\u001b[0m  52.6751\n",
      "      5        \u001b[36m3.8730\u001b[0m        \u001b[32m3.9308\u001b[0m  52.6032\n",
      "      6        \u001b[36m3.8633\u001b[0m        \u001b[32m3.9273\u001b[0m  52.5103\n",
      "      7        \u001b[36m3.8539\u001b[0m        3.9301  53.3954\n",
      "      8        \u001b[36m3.8439\u001b[0m        \u001b[32m3.9179\u001b[0m  52.9039\n",
      "      9        \u001b[36m3.8397\u001b[0m        3.9479  53.1776\n",
      "     10        \u001b[36m3.8296\u001b[0m        3.9397  52.4513\n",
      "     11        \u001b[36m3.8256\u001b[0m        3.9482  52.4224\n",
      "     12        \u001b[36m3.8198\u001b[0m        3.9497  52.5662\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9468\u001b[0m        \u001b[32m3.9966\u001b[0m  51.8259\n",
      "      2        \u001b[36m3.9168\u001b[0m        4.0739  52.4903\n",
      "      3        \u001b[36m3.8851\u001b[0m        4.0238  52.1976\n",
      "      4        \u001b[36m3.8690\u001b[0m        4.0053  52.5562\n",
      "      5        \u001b[36m3.8619\u001b[0m        4.0419  52.1107\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9976\u001b[0m        \u001b[32m3.9399\u001b[0m  51.2725\n",
      "      2        \u001b[36m3.9790\u001b[0m        3.9865  52.1616\n",
      "      3        \u001b[36m3.9788\u001b[0m        3.9835  52.6941\n",
      "      4        \u001b[36m3.9603\u001b[0m        3.9743  53.0737\n",
      "      5        \u001b[36m3.9512\u001b[0m        \u001b[32m3.9312\u001b[0m  52.6162\n",
      "      6        \u001b[36m3.9480\u001b[0m        3.9525  52.9488\n",
      "      7        \u001b[36m3.9390\u001b[0m        3.9558  53.2445\n",
      "      8        3.9392        3.9753  53.0767\n",
      "      9        \u001b[36m3.9289\u001b[0m        3.9890  53.1676\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9831\u001b[0m        \u001b[32m4.0121\u001b[0m  51.1157\n",
      "      2        \u001b[36m3.9687\u001b[0m        \u001b[32m3.9986\u001b[0m  52.8000\n",
      "      3        \u001b[36m3.9558\u001b[0m        \u001b[32m3.9737\u001b[0m  53.1846\n",
      "      4        \u001b[36m3.9419\u001b[0m        3.9950  52.1037\n",
      "      5        \u001b[36m3.9255\u001b[0m        3.9760  52.8959\n",
      "      6        \u001b[36m3.9152\u001b[0m        \u001b[32m3.9650\u001b[0m  52.3664\n",
      "      7        \u001b[36m3.9069\u001b[0m        \u001b[32m3.9589\u001b[0m  52.9838\n",
      "      8        3.9135        \u001b[32m3.9456\u001b[0m  53.2865\n",
      "      9        3.9240        3.9725  53.1176\n",
      "     10        3.9284        3.9592  54.9847\n",
      "     11        3.9143        3.9494  53.0717\n",
      "     12        \u001b[36m3.9032\u001b[0m        4.0021  53.3924\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9922\u001b[0m        \u001b[32m4.0032\u001b[0m  51.5862\n",
      "      2        \u001b[36m3.9771\u001b[0m        \u001b[32m3.9687\u001b[0m  53.1206\n",
      "      3        \u001b[36m3.9650\u001b[0m        4.0130  54.7150\n",
      "      4        3.9660        4.0002  54.1935\n",
      "      5        \u001b[36m3.9491\u001b[0m        3.9861  52.5512\n",
      "      6        3.9550        4.0593  52.5572\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9742\u001b[0m        \u001b[32m4.0292\u001b[0m  51.0727\n",
      "      2        \u001b[36m3.9658\u001b[0m        \u001b[32m3.9820\u001b[0m  52.1436\n",
      "      3        \u001b[36m3.9640\u001b[0m        4.0183  52.3005\n",
      "      4        \u001b[36m3.9409\u001b[0m        4.0501  52.2595\n",
      "      5        \u001b[36m3.9338\u001b[0m        \u001b[32m3.9747\u001b[0m  52.5602\n",
      "      6        \u001b[36m3.9173\u001b[0m        \u001b[32m3.9729\u001b[0m  51.9798\n",
      "      7        \u001b[36m3.9121\u001b[0m        \u001b[32m3.9612\u001b[0m  51.6911\n",
      "      8        \u001b[36m3.8990\u001b[0m        \u001b[32m3.9492\u001b[0m  52.2445\n",
      "      9        \u001b[36m3.8941\u001b[0m        \u001b[32m3.9426\u001b[0m  52.2425\n",
      "     10        \u001b[36m3.8817\u001b[0m        3.9978  52.5782\n",
      "     11        3.8830        3.9867  52.5462\n",
      "     12        \u001b[36m3.8805\u001b[0m        3.9549  51.9488\n",
      "     13        \u001b[36m3.8730\u001b[0m        3.9997  52.4473\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.9718\u001b[0m        \u001b[32m4.0100\u001b[0m  51.1486\n",
      "      2        \u001b[36m3.9688\u001b[0m        4.0317  52.5093\n",
      "      3        \u001b[36m3.9446\u001b[0m        \u001b[32m3.9882\u001b[0m  52.3205\n",
      "      4        \u001b[36m3.9319\u001b[0m        \u001b[32m3.9797\u001b[0m  51.5672\n",
      "      5        \u001b[36m3.9205\u001b[0m        4.0028  52.3065\n",
      "      6        \u001b[36m3.9074\u001b[0m        \u001b[32m3.9690\u001b[0m  52.2925\n",
      "      7        \u001b[36m3.9029\u001b[0m        \u001b[32m3.9677\u001b[0m  52.1237\n",
      "      8        \u001b[36m3.8939\u001b[0m        \u001b[32m3.9644\u001b[0m  52.7840\n",
      "      9        \u001b[36m3.8847\u001b[0m        \u001b[32m3.9531\u001b[0m  51.8859\n",
      "     10        \u001b[36m3.8809\u001b[0m        3.9808  52.5362\n",
      "     11        \u001b[36m3.8786\u001b[0m        3.9770  52.3035\n",
      "     12        \u001b[36m3.8738\u001b[0m        3.9899  52.5932\n",
      "     13        \u001b[36m3.8637\u001b[0m        3.9818  53.2865\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3122\u001b[0m        \u001b[32m4.2602\u001b[0m  51.3035\n",
      "      2        4.3141        4.2602  52.1057\n",
      "      3        4.3141        4.2602  52.2775\n",
      "      4        4.3141        4.2602  51.9608\n",
      "      5        4.3141        4.2602  51.6911\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3110\u001b[0m        \u001b[32m4.2757\u001b[0m  51.4334\n",
      "      2        4.3155        4.2757  51.9958\n",
      "      3        4.3155        4.2757  52.0308\n",
      "      4        4.3155        4.2757  52.2625\n",
      "      5        4.3155        4.2757  51.3894\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3111\u001b[0m        \u001b[32m4.2757\u001b[0m  51.5472\n",
      "      2        4.3177        4.2757  52.1636\n",
      "      3        4.3177        4.2757  52.0767\n",
      "      4        4.3177        4.2757  51.8779\n",
      "      5        4.3177        4.2757  52.1746\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3022\u001b[0m        \u001b[32m4.2757\u001b[0m  51.8919\n",
      "      2        4.3088        4.2757  51.9608\n",
      "      3        4.3088        \u001b[32m4.2757\u001b[0m  52.3364\n",
      "      4        4.3088        \u001b[32m4.2757\u001b[0m  51.6721\n",
      "      5        4.3089        4.2757  52.6042\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2934\u001b[0m        \u001b[32m4.2854\u001b[0m  51.8529\n",
      "      2        4.3007        \u001b[32m4.2854\u001b[0m  51.9768\n",
      "      3        4.3007        \u001b[32m4.2851\u001b[0m  51.7870\n",
      "      4        4.2995        4.2854  51.9069\n",
      "      5        4.3007        4.2854  52.3314\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3950\u001b[0m        \u001b[32m4.2636\u001b[0m  51.6182\n",
      "      2        4.3967        4.2636  52.4883\n",
      "      3        4.3967        4.2636  51.6921\n",
      "      4        4.3967        4.2636  52.1466\n",
      "      5        4.3967        4.2636  51.6382\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3993\u001b[0m        \u001b[32m4.2793\u001b[0m  51.6621\n",
      "      2        4.4034        4.2793  51.5782\n",
      "      3        4.4034        4.2793  51.7231\n",
      "      4        4.4034        4.2793  51.5842\n",
      "      5        4.4034        4.2793  51.9159\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.4032\u001b[0m        \u001b[32m4.2793\u001b[0m  51.9159\n",
      "      2        4.4073        4.2793  51.4753\n",
      "      3        4.4073        4.2793  51.3964\n",
      "      4        4.4073        4.2793  51.7830\n",
      "      5        4.4073        4.2793  51.3844\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3833\u001b[0m        \u001b[32m4.2793\u001b[0m  51.5712\n",
      "      2        4.3874        4.2793  51.6581\n",
      "      3        4.3874        4.2793  51.7351\n",
      "      4        4.3874        4.2793  51.3724\n",
      "      5        4.3874        4.2793  52.1656\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3847\u001b[0m        \u001b[32m4.2461\u001b[0m  51.4124\n",
      "      2        4.3897        4.2461  51.6052\n",
      "      3        4.3897        4.2461  51.7321\n",
      "      4        4.3897        4.2461  51.8080\n",
      "      5        4.3897        4.2461  50.8410\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7706\u001b[0m        \u001b[32m3.8046\u001b[0m  51.2785\n",
      "      2        \u001b[36m3.7636\u001b[0m        3.8064  51.6921\n",
      "      3        \u001b[36m3.7594\u001b[0m        3.8067  51.5552\n",
      "      4        \u001b[36m3.7560\u001b[0m        3.8093  51.8919\n",
      "      5        \u001b[36m3.7526\u001b[0m        3.8110  52.0048\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7819\u001b[0m        \u001b[32m3.9042\u001b[0m  51.6801\n",
      "      2        \u001b[36m3.7751\u001b[0m        3.9050  51.6192\n",
      "      3        \u001b[36m3.7710\u001b[0m        3.9065  52.4094\n",
      "      4        \u001b[36m3.7677\u001b[0m        3.9050  51.5652\n",
      "      5        \u001b[36m3.7642\u001b[0m        3.9049  51.8729\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7920\u001b[0m        \u001b[32m3.9041\u001b[0m  51.0308\n",
      "      2        \u001b[36m3.7849\u001b[0m        3.9051  51.5762\n",
      "      3        \u001b[36m3.7805\u001b[0m        3.9042  51.3674\n",
      "      4        \u001b[36m3.7770\u001b[0m        3.9052  51.3634\n",
      "      5        \u001b[36m3.7736\u001b[0m        3.9059  51.4024\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7846\u001b[0m        \u001b[32m3.9069\u001b[0m  51.5093\n",
      "      2        \u001b[36m3.7773\u001b[0m        \u001b[32m3.9065\u001b[0m  51.4474\n",
      "      3        \u001b[36m3.7729\u001b[0m        \u001b[32m3.9063\u001b[0m  51.4953\n",
      "      4        \u001b[36m3.7690\u001b[0m        3.9078  51.7810\n",
      "      5        \u001b[36m3.7655\u001b[0m        3.9089  52.1057\n",
      "      6        \u001b[36m3.7623\u001b[0m        3.9105  51.2526\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7789\u001b[0m        \u001b[32m3.9177\u001b[0m  51.0158\n",
      "      2        \u001b[36m3.7712\u001b[0m        \u001b[32m3.9175\u001b[0m  51.4593\n",
      "      3        \u001b[36m3.7665\u001b[0m        \u001b[32m3.9169\u001b[0m  52.0028\n",
      "      4        \u001b[36m3.7624\u001b[0m        3.9172  51.8639\n",
      "      5        \u001b[36m3.7589\u001b[0m        3.9198  51.6002\n",
      "      6        \u001b[36m3.7557\u001b[0m        3.9200  51.1277\n",
      "      7        \u001b[36m3.7528\u001b[0m        3.9203  51.7760\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.0298\u001b[0m        \u001b[32m3.9457\u001b[0m  51.9428\n",
      "      2        \u001b[36m3.9930\u001b[0m        3.9572  52.8229\n",
      "      3        \u001b[36m3.9738\u001b[0m        \u001b[32m3.9321\u001b[0m  52.2146\n",
      "      4        \u001b[36m3.9517\u001b[0m        3.9411  52.2116\n",
      "      5        \u001b[36m3.9465\u001b[0m        \u001b[32m3.9223\u001b[0m  52.3964\n",
      "      6        \u001b[36m3.9398\u001b[0m        3.9284  52.7430\n",
      "      7        \u001b[36m3.9311\u001b[0m        3.9314  52.7360\n",
      "      8        \u001b[36m3.9245\u001b[0m        3.9226  52.4313\n",
      "      9        \u001b[36m3.9187\u001b[0m        3.9254  52.4024\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.0465\u001b[0m        \u001b[32m3.9840\u001b[0m  51.5123\n",
      "      2        \u001b[36m4.0012\u001b[0m        \u001b[32m3.9758\u001b[0m  52.1886\n",
      "      3        \u001b[36m3.9869\u001b[0m        4.0032  52.0807\n",
      "      4        \u001b[36m3.9804\u001b[0m        4.0589  52.0727\n",
      "      5        \u001b[36m3.9754\u001b[0m        3.9900  52.3394\n",
      "      6        \u001b[36m3.9677\u001b[0m        3.9904  52.2935\n",
      "      7        \u001b[36m3.9568\u001b[0m        \u001b[32m3.9591\u001b[0m  52.2515\n",
      "      8        \u001b[36m3.9491\u001b[0m        3.9654  51.9858\n",
      "      9        \u001b[36m3.9407\u001b[0m        \u001b[32m3.9544\u001b[0m  52.2675\n",
      "     10        \u001b[36m3.9341\u001b[0m        3.9588  52.8080\n",
      "     11        \u001b[36m3.9280\u001b[0m        3.9593  52.5153\n",
      "     12        \u001b[36m3.9245\u001b[0m        3.9649  52.7081\n",
      "     13        \u001b[36m3.9203\u001b[0m        3.9591  52.5322\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.0500\u001b[0m        \u001b[32m4.0027\u001b[0m  51.6811\n",
      "      2        \u001b[36m4.0040\u001b[0m        \u001b[32m3.9836\u001b[0m  52.0667\n",
      "      3        \u001b[36m3.9902\u001b[0m        3.9978  52.1237\n",
      "      4        \u001b[36m3.9874\u001b[0m        \u001b[32m3.9649\u001b[0m  52.7830\n",
      "      5        \u001b[36m3.9678\u001b[0m        \u001b[32m3.9632\u001b[0m  52.1926\n",
      "      6        3.9697        \u001b[32m3.9491\u001b[0m  52.7430\n",
      "      7        \u001b[36m3.9609\u001b[0m        3.9703  52.6401\n",
      "      8        \u001b[36m3.9513\u001b[0m        3.9721  52.3564\n",
      "      9        \u001b[36m3.9392\u001b[0m        3.9597  52.5542\n",
      "     10        \u001b[36m3.9303\u001b[0m        3.9719  51.9588\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.0427\u001b[0m        \u001b[32m4.0144\u001b[0m  51.3145\n",
      "      2        \u001b[36m3.9993\u001b[0m        \u001b[32m3.9863\u001b[0m  52.4753\n",
      "      3        \u001b[36m3.9805\u001b[0m        \u001b[32m3.9630\u001b[0m  52.2595\n",
      "      4        \u001b[36m3.9654\u001b[0m        3.9683  52.2885\n",
      "      5        3.9719        3.9743  52.7760\n",
      "      6        \u001b[36m3.9553\u001b[0m        3.9804  52.7940\n",
      "      7        \u001b[36m3.9420\u001b[0m        3.9783  52.2675\n",
      "      8        \u001b[36m3.9341\u001b[0m        \u001b[32m3.9536\u001b[0m  52.1386\n",
      "      9        \u001b[36m3.9310\u001b[0m        3.9662  52.8060\n",
      "     10        \u001b[36m3.9239\u001b[0m        3.9827  52.0647\n",
      "     11        \u001b[36m3.9191\u001b[0m        3.9537  52.4473\n",
      "     12        \u001b[36m3.9160\u001b[0m        3.9549  52.3115\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.0381\u001b[0m        \u001b[32m4.1137\u001b[0m  51.5413\n",
      "      2        \u001b[36m3.9981\u001b[0m        4.1232  52.0567\n",
      "      3        \u001b[36m3.9722\u001b[0m        \u001b[32m4.0383\u001b[0m  51.9428\n",
      "      4        \u001b[36m3.9580\u001b[0m        \u001b[32m4.0183\u001b[0m  52.2685\n",
      "      5        \u001b[36m3.9470\u001b[0m        4.0280  52.1466\n",
      "      6        \u001b[36m3.9388\u001b[0m        4.0280  52.3324\n",
      "      7        \u001b[36m3.9366\u001b[0m        4.0378  51.8769\n",
      "      8        \u001b[36m3.9331\u001b[0m        4.0723  52.7131\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8921\u001b[0m        \u001b[32m3.8891\u001b[0m  51.6881\n",
      "      2        \u001b[36m3.8605\u001b[0m        3.8946  52.2106\n",
      "      3        \u001b[36m3.8471\u001b[0m        \u001b[32m3.8779\u001b[0m  51.9858\n",
      "      4        \u001b[36m3.8346\u001b[0m        3.8850  52.6341\n",
      "      5        \u001b[36m3.8258\u001b[0m        3.9279  52.2745\n",
      "      6        \u001b[36m3.8169\u001b[0m        3.8988  52.0407\n",
      "      7        \u001b[36m3.8114\u001b[0m        3.8891  52.1656\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8921\u001b[0m        \u001b[32m3.9673\u001b[0m  51.1147\n",
      "      2        \u001b[36m3.8650\u001b[0m        \u001b[32m3.9460\u001b[0m  52.2445\n",
      "      3        \u001b[36m3.8519\u001b[0m        \u001b[32m3.9310\u001b[0m  51.8529\n",
      "      4        \u001b[36m3.8456\u001b[0m        3.9530  51.5443\n",
      "      5        \u001b[36m3.8358\u001b[0m        3.9532  52.4204\n",
      "      6        \u001b[36m3.8283\u001b[0m        3.9578  51.7870\n",
      "      7        \u001b[36m3.8169\u001b[0m        3.9568  51.8939\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8908\u001b[0m        \u001b[32m3.9356\u001b[0m  51.7990\n",
      "      2        \u001b[36m3.8797\u001b[0m        3.9650  52.2865\n",
      "      3        \u001b[36m3.8612\u001b[0m        \u001b[32m3.9335\u001b[0m  51.4464\n",
      "      4        \u001b[36m3.8489\u001b[0m        3.9413  52.2276\n",
      "      5        \u001b[36m3.8384\u001b[0m        3.9437  52.3035\n",
      "      6        \u001b[36m3.8322\u001b[0m        3.9391  51.9199\n",
      "      7        \u001b[36m3.8268\u001b[0m        \u001b[32m3.9307\u001b[0m  52.2835\n",
      "      8        \u001b[36m3.8228\u001b[0m        3.9329  51.7780\n",
      "      9        \u001b[36m3.8141\u001b[0m        3.9311  52.0867\n",
      "     10        \u001b[36m3.8062\u001b[0m        3.9308  51.9119\n",
      "     11        \u001b[36m3.7995\u001b[0m        \u001b[32m3.9246\u001b[0m  52.2675\n",
      "     12        \u001b[36m3.7941\u001b[0m        3.9302  52.0268\n",
      "     13        \u001b[36m3.7905\u001b[0m        3.9374  52.0248\n",
      "     14        \u001b[36m3.7874\u001b[0m        3.9548  52.0997\n",
      "     15        \u001b[36m3.7827\u001b[0m        3.9570  52.3964\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8877\u001b[0m        \u001b[32m3.9336\u001b[0m  51.1057\n",
      "      2        \u001b[36m3.8661\u001b[0m        3.9446  51.6072\n",
      "      3        \u001b[36m3.8479\u001b[0m        \u001b[32m3.9319\u001b[0m  51.8150\n",
      "      4        \u001b[36m3.8356\u001b[0m        \u001b[32m3.9292\u001b[0m  52.1516\n",
      "      5        \u001b[36m3.8285\u001b[0m        3.9398  52.2276\n",
      "      6        \u001b[36m3.8284\u001b[0m        3.9368  52.3934\n",
      "      7        \u001b[36m3.8152\u001b[0m        3.9629  51.6022\n",
      "      8        \u001b[36m3.8076\u001b[0m        3.9679  52.4313\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8754\u001b[0m        \u001b[32m3.9692\u001b[0m  51.8050\n",
      "      2        \u001b[36m3.8550\u001b[0m        \u001b[32m3.9562\u001b[0m  51.9998\n",
      "      3        \u001b[36m3.8410\u001b[0m        \u001b[32m3.9489\u001b[0m  52.2735\n",
      "      4        \u001b[36m3.8307\u001b[0m        3.9695  51.9878\n",
      "      5        \u001b[36m3.8205\u001b[0m        3.9833  52.6281\n",
      "      6        \u001b[36m3.8138\u001b[0m        3.9577  52.4553\n",
      "      7        \u001b[36m3.8048\u001b[0m        3.9580  54.3823\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8055\u001b[0m        \u001b[32m3.8343\u001b[0m  52.2795\n",
      "      2        \u001b[36m3.7964\u001b[0m        3.8470  51.7590\n",
      "      3        \u001b[36m3.7893\u001b[0m        3.8548  52.3464\n",
      "      4        \u001b[36m3.7817\u001b[0m        3.8629  51.6132\n",
      "      5        \u001b[36m3.7763\u001b[0m        3.8647  52.6611\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8175\u001b[0m        \u001b[32m3.9101\u001b[0m  51.2376\n",
      "      2        \u001b[36m3.8056\u001b[0m        3.9106  51.9339\n",
      "      3        \u001b[36m3.7999\u001b[0m        \u001b[32m3.9062\u001b[0m  51.6721\n",
      "      4        \u001b[36m3.7944\u001b[0m        3.9195  52.2335\n",
      "      5        \u001b[36m3.7872\u001b[0m        3.9336  52.2315\n",
      "      6        \u001b[36m3.7814\u001b[0m        3.9478  51.9259\n",
      "      7        \u001b[36m3.7778\u001b[0m        3.9136  52.3045\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8249\u001b[0m        \u001b[32m3.9166\u001b[0m  51.6921\n",
      "      2        \u001b[36m3.8142\u001b[0m        3.9193  51.8909\n",
      "      3        \u001b[36m3.8058\u001b[0m        3.9248  51.5043\n",
      "      4        \u001b[36m3.8002\u001b[0m        3.9324  51.7081\n",
      "      5        \u001b[36m3.7966\u001b[0m        3.9224  52.1516\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8183\u001b[0m        \u001b[32m3.9245\u001b[0m  50.8559\n",
      "      2        \u001b[36m3.8052\u001b[0m        \u001b[32m3.9194\u001b[0m  51.5742\n",
      "      3        \u001b[36m3.7975\u001b[0m        3.9236  51.1117\n",
      "      4        \u001b[36m3.7893\u001b[0m        3.9204  51.6461\n",
      "      5        \u001b[36m3.7847\u001b[0m        3.9269  51.4324\n",
      "      6        \u001b[36m3.7808\u001b[0m        3.9288  52.0018\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8105\u001b[0m        \u001b[32m3.9169\u001b[0m  50.6811\n",
      "      2        \u001b[36m3.7975\u001b[0m        3.9268  52.0607\n",
      "      3        \u001b[36m3.7882\u001b[0m        3.9266  51.7411\n",
      "      4        \u001b[36m3.7821\u001b[0m        3.9275  51.7740\n",
      "      5        \u001b[36m3.7786\u001b[0m        3.9327  55.1819\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8623\u001b[0m        \u001b[32m3.9001\u001b[0m  50.3695\n",
      "      2        \u001b[36m3.8439\u001b[0m        \u001b[32m3.8979\u001b[0m  51.3345\n",
      "      3        \u001b[36m3.8296\u001b[0m        \u001b[32m3.8976\u001b[0m  51.3205\n",
      "      4        \u001b[36m3.8206\u001b[0m        \u001b[32m3.8923\u001b[0m  51.5782\n",
      "      5        \u001b[36m3.8132\u001b[0m        \u001b[32m3.8753\u001b[0m  50.9279\n",
      "      6        \u001b[36m3.8066\u001b[0m        3.8842  51.3075\n",
      "      7        \u001b[36m3.8019\u001b[0m        3.8863  52.6661\n",
      "      8        \u001b[36m3.7938\u001b[0m        3.8878  51.2805\n",
      "      9        \u001b[36m3.7887\u001b[0m        3.8838  51.8639\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8664\u001b[0m        \u001b[32m3.9265\u001b[0m  50.9059\n",
      "      2        \u001b[36m3.8498\u001b[0m        3.9286  51.4843\n",
      "      3        \u001b[36m3.8384\u001b[0m        3.9268  51.2226\n",
      "      4        \u001b[36m3.8271\u001b[0m        \u001b[32m3.9177\u001b[0m  51.4623\n",
      "      5        \u001b[36m3.8192\u001b[0m        3.9330  51.4174\n",
      "      6        \u001b[36m3.8146\u001b[0m        3.9185  51.1566\n",
      "      7        \u001b[36m3.8084\u001b[0m        3.9215  51.4124\n",
      "      8        \u001b[36m3.8016\u001b[0m        \u001b[32m3.9116\u001b[0m  51.6991\n",
      "      9        \u001b[36m3.7950\u001b[0m        3.9329  51.1836\n",
      "     10        \u001b[36m3.7929\u001b[0m        3.9289  51.7990\n",
      "     11        \u001b[36m3.7862\u001b[0m        3.9446  51.6282\n",
      "     12        \u001b[36m3.7845\u001b[0m        3.9542  50.8639\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8827\u001b[0m        \u001b[32m3.9330\u001b[0m  51.0867\n",
      "      2        \u001b[36m3.8617\u001b[0m        \u001b[32m3.9141\u001b[0m  50.7061\n",
      "      3        \u001b[36m3.8471\u001b[0m        3.9382  51.0887\n",
      "      4        \u001b[36m3.8388\u001b[0m        3.9602  51.8919\n",
      "      5        \u001b[36m3.8309\u001b[0m        3.9484  51.2176\n",
      "      6        \u001b[36m3.8245\u001b[0m        3.9441  51.1117\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8722\u001b[0m        \u001b[32m3.9297\u001b[0m  50.3804\n",
      "      2        \u001b[36m3.8509\u001b[0m        \u001b[32m3.9171\u001b[0m  51.0058\n",
      "      3        \u001b[36m3.8343\u001b[0m        3.9393  51.3784\n",
      "      4        \u001b[36m3.8269\u001b[0m        3.9637  51.0078\n",
      "      5        \u001b[36m3.8206\u001b[0m        3.9473  51.4334\n",
      "      6        \u001b[36m3.8115\u001b[0m        3.9354  51.6771\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8625\u001b[0m        \u001b[32m3.9434\u001b[0m  50.8759\n",
      "      2        \u001b[36m3.8414\u001b[0m        3.9604  50.8050\n",
      "      3        \u001b[36m3.8303\u001b[0m        \u001b[32m3.9162\u001b[0m  51.2016\n",
      "      4        \u001b[36m3.8173\u001b[0m        3.9243  51.4284\n",
      "      5        \u001b[36m3.8097\u001b[0m        3.9525  51.9019\n",
      "      6        \u001b[36m3.8046\u001b[0m        3.9317  51.7700\n",
      "      7        \u001b[36m3.7973\u001b[0m        3.9522  52.2405\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1       \u001b[36m17.5371\u001b[0m        \u001b[32m4.3027\u001b[0m  50.3635\n",
      "      2        \u001b[36m4.9201\u001b[0m        4.3027  51.1227\n",
      "      3        4.9201        4.3027  50.9039\n",
      "      4        4.9201        4.3027  50.8370\n",
      "      5        4.9201        4.3027  50.2476\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.9059\u001b[0m        \u001b[32m4.3201\u001b[0m  50.0947\n",
      "      2        4.9168        4.3201  51.9878\n",
      "      3        4.9168        4.3201  50.9289\n",
      "      4        4.9168        4.3201  51.2536\n",
      "      5        4.9168        4.3201  51.0757\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.9844\u001b[0m        \u001b[32m4.3201\u001b[0m  50.3175\n",
      "      2        4.9947        4.3201  50.6482\n",
      "      3        4.9947        4.3201  50.8629\n",
      "      4        4.9947        4.3201  51.0058\n",
      "      5        4.9947        4.3201  51.0568\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.9671\u001b[0m        \u001b[32m4.3200\u001b[0m  49.4854\n",
      "      2        4.9774        4.3200  50.9708\n",
      "      3        4.9774        4.3200  51.1926\n",
      "      4        4.9774        4.3200  50.6142\n",
      "      5        4.9774        4.3200  51.5732\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m5.0055\u001b[0m        \u001b[32m4.2694\u001b[0m  50.2326\n",
      "      2        5.0169        4.2694  51.0907\n",
      "      3        5.0169        4.2694  51.3654\n",
      "      4        5.0169        4.2694  51.0737\n",
      "      5        5.0169        4.2694  49.8290\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7711\u001b[0m        \u001b[32m3.8137\u001b[0m  50.6901\n",
      "      2        \u001b[36m3.7645\u001b[0m        \u001b[32m3.8102\u001b[0m  50.7930\n",
      "      3        \u001b[36m3.7594\u001b[0m        3.8144  50.9808\n",
      "      4        \u001b[36m3.7554\u001b[0m        3.8156  50.6602\n",
      "      5        \u001b[36m3.7520\u001b[0m        3.8176  50.7561\n",
      "      6        \u001b[36m3.7490\u001b[0m        3.8180  50.8270\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7828\u001b[0m        \u001b[32m3.9094\u001b[0m  51.0248\n",
      "      2        \u001b[36m3.7761\u001b[0m        \u001b[32m3.9087\u001b[0m  50.6691\n",
      "      3        \u001b[36m3.7712\u001b[0m        3.9103  50.5802\n",
      "      4        \u001b[36m3.7673\u001b[0m        \u001b[32m3.9080\u001b[0m  50.6761\n",
      "      5        \u001b[36m3.7637\u001b[0m        \u001b[32m3.9070\u001b[0m  50.6252\n",
      "      6        \u001b[36m3.7604\u001b[0m        3.9087  50.8659\n",
      "      7        \u001b[36m3.7573\u001b[0m        3.9076  51.2396\n",
      "      8        \u001b[36m3.7543\u001b[0m        3.9090  50.8510\n",
      "      9        \u001b[36m3.7517\u001b[0m        3.9086  51.1806\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7923\u001b[0m        \u001b[32m3.9072\u001b[0m  50.1726\n",
      "      2        \u001b[36m3.7857\u001b[0m        \u001b[32m3.9066\u001b[0m  50.7251\n",
      "      3        \u001b[36m3.7811\u001b[0m        3.9085  51.0677\n",
      "      4        \u001b[36m3.7772\u001b[0m        3.9080  50.9589\n",
      "      5        \u001b[36m3.7731\u001b[0m        3.9076  51.0488\n",
      "      6        \u001b[36m3.7701\u001b[0m        3.9085  50.9638\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7849\u001b[0m        \u001b[32m3.9103\u001b[0m  50.6631\n",
      "      2        \u001b[36m3.7782\u001b[0m        \u001b[32m3.9081\u001b[0m  51.1037\n",
      "      3        \u001b[36m3.7733\u001b[0m        3.9097  51.0617\n",
      "      4        \u001b[36m3.7689\u001b[0m        3.9105  50.9229\n",
      "      5        \u001b[36m3.7651\u001b[0m        3.9099  51.7111\n",
      "      6        \u001b[36m3.7616\u001b[0m        3.9117  51.7011\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7792\u001b[0m        \u001b[32m3.9151\u001b[0m  50.6012\n",
      "      2        \u001b[36m3.7717\u001b[0m        3.9168  51.1047\n",
      "      3        \u001b[36m3.7663\u001b[0m        3.9183  51.5862\n",
      "      4        \u001b[36m3.7622\u001b[0m        3.9199  51.2346\n",
      "      5        \u001b[36m3.7582\u001b[0m        3.9206  51.5253\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.9819\u001b[0m        \u001b[32m4.2456\u001b[0m  49.8370\n",
      "      2        \u001b[36m4.7454\u001b[0m        4.2456  51.4653\n",
      "      3        4.7454        4.2456  50.6032\n",
      "      4        4.7454        4.2456  50.8200\n",
      "      5        4.7454        4.2456  50.7531\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.7378\u001b[0m        \u001b[32m4.2602\u001b[0m  51.0018\n",
      "      2        \u001b[36m4.7356\u001b[0m        4.2602  50.9938\n",
      "      3        4.7356        4.2602  51.0128\n",
      "      4        4.7356        4.2602  50.4833\n",
      "      5        4.7356        4.2602  50.4903\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.7002\u001b[0m        \u001b[32m4.2602\u001b[0m  50.5463\n",
      "      2        \u001b[36m4.6980\u001b[0m        4.2602  50.6981\n",
      "      3        4.6980        4.2602  51.0997\n",
      "      4        4.6980        4.2602  50.6711\n",
      "      5        4.6980        4.2602  50.3964\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.6254\u001b[0m        \u001b[32m4.2602\u001b[0m  50.5912\n",
      "      2        \u001b[36m4.6232\u001b[0m        4.2602  50.8639\n",
      "      3        4.6232        4.2602  50.1527\n",
      "      4        4.6232        4.2602  50.3545\n",
      "      5        4.6232        4.2602  50.6761\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.6398\u001b[0m        \u001b[32m4.2445\u001b[0m  50.7730\n",
      "      2        4.6405        4.2445  50.4124\n",
      "      3        4.6405        4.2445  50.7431\n",
      "      4        4.6405        4.2445  51.3275\n",
      "      5        4.6405        4.2445  50.9169\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.7701\u001b[0m        \u001b[32m4.3857\u001b[0m  50.1017\n",
      "      2        \u001b[36m4.7673\u001b[0m        4.3857  50.7111\n",
      "      3        4.7673        4.3857  51.1277\n",
      "      4        4.7673        4.3857  51.7231\n",
      "      5        4.7673        4.3857  50.3974\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1     \u001b[36m7594.1392\u001b[0m        \u001b[32m4.4055\u001b[0m  50.8689\n",
      "      2        \u001b[36m4.7568\u001b[0m        4.4055  50.9768\n",
      "      3        4.7568        4.4055  50.7251\n",
      "      4        4.7568        4.4055  50.5523\n",
      "      5        4.7568        4.4055  50.8829\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1     \u001b[36m7594.1049\u001b[0m        \u001b[32m4.4055\u001b[0m  50.8799\n",
      "      2        \u001b[36m4.7344\u001b[0m        4.4055  50.9569\n",
      "      3        4.7344        4.4055  50.6751\n",
      "      4        4.7344        4.4055  50.8939\n",
      "      5        4.7344        4.4055  51.2296\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1     \u001b[36m7594.0352\u001b[0m        \u001b[32m4.4055\u001b[0m  50.5682\n",
      "      2        \u001b[36m4.6647\u001b[0m        4.4055  50.6971\n",
      "      3        4.6647        4.4055  51.2346\n",
      "      4        4.6647        4.4055  50.6292\n",
      "      5        4.6647        4.4055  50.7730\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1     \u001b[36m7594.0442\u001b[0m        \u001b[32m4.6369\u001b[0m  50.5403\n",
      "      2        \u001b[36m4.6769\u001b[0m        4.6369  50.8669\n",
      "      3        4.6769        4.6369  50.9708\n",
      "      4        4.6769        4.6369  50.7151\n",
      "      5        4.6769        4.6369  50.5483\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7730\u001b[0m        \u001b[32m3.8070\u001b[0m  51.4503\n",
      "      2        \u001b[36m3.7660\u001b[0m        3.8091  51.3125\n",
      "      3        \u001b[36m3.7611\u001b[0m        3.8114  51.4533\n",
      "      4        \u001b[36m3.7572\u001b[0m        3.8152  51.1557\n",
      "      5        \u001b[36m3.7538\u001b[0m        3.8159  50.6931\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7847\u001b[0m        \u001b[32m3.9032\u001b[0m  51.0138\n",
      "      2        \u001b[36m3.7776\u001b[0m        \u001b[32m3.9024\u001b[0m  50.4354\n",
      "      3        \u001b[36m3.7725\u001b[0m        3.9024  51.4174\n",
      "      4        \u001b[36m3.7691\u001b[0m        3.9034  50.4194\n",
      "      5        \u001b[36m3.7651\u001b[0m        3.9037  50.7261\n",
      "      6        \u001b[36m3.7616\u001b[0m        3.9030  50.4014\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7942\u001b[0m        \u001b[32m3.9036\u001b[0m  50.4284\n",
      "      2        \u001b[36m3.7870\u001b[0m        3.9052  50.1727\n",
      "      3        \u001b[36m3.7821\u001b[0m        \u001b[32m3.9018\u001b[0m  50.6042\n",
      "      4        \u001b[36m3.7781\u001b[0m        3.9038  50.7820\n",
      "      5        \u001b[36m3.7742\u001b[0m        3.9056  50.8350\n",
      "      6        \u001b[36m3.7707\u001b[0m        3.9070  50.4534\n",
      "      7        \u001b[36m3.7673\u001b[0m        3.9078  50.9069\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7866\u001b[0m        \u001b[32m3.9063\u001b[0m  50.2526\n",
      "      2        \u001b[36m3.7792\u001b[0m        \u001b[32m3.9059\u001b[0m  50.5872\n",
      "      3        \u001b[36m3.7742\u001b[0m        3.9060  50.4054\n",
      "      4        \u001b[36m3.7696\u001b[0m        3.9079  50.9199\n",
      "      5        \u001b[36m3.7658\u001b[0m        3.9102  50.4264\n",
      "      6        \u001b[36m3.7624\u001b[0m        3.9104  50.3884\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7809\u001b[0m        \u001b[32m3.9197\u001b[0m  50.2935\n",
      "      2        \u001b[36m3.7727\u001b[0m        \u001b[32m3.9193\u001b[0m  50.5323\n",
      "      3        \u001b[36m3.7676\u001b[0m        3.9195  50.5013\n",
      "      4        \u001b[36m3.7632\u001b[0m        \u001b[32m3.9189\u001b[0m  51.1067\n",
      "      5        \u001b[36m3.7596\u001b[0m        3.9203  50.5453\n",
      "      6        \u001b[36m3.7560\u001b[0m        3.9196  50.6901\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2468\u001b[0m        \u001b[32m4.2295\u001b[0m  50.6212\n",
      "      2        4.3013        4.2295  51.8350\n",
      "      3        4.3013        4.2295  52.1626\n",
      "      4        4.3013        4.2295  51.9488\n",
      "      5        4.3013        4.2295  51.9378\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3006\u001b[0m        \u001b[32m4.2423\u001b[0m  51.2186\n",
      "      2        4.3078        4.2423  51.7311\n",
      "      3        4.3078        4.2423  51.0718\n",
      "      4        4.3078        4.2423  51.2775\n",
      "      5        4.3078        4.2423  51.3794\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3078\u001b[0m        \u001b[32m4.2423\u001b[0m  50.6641\n",
      "      2        4.3150        4.2423  50.9349\n",
      "      3        4.3150        4.2423  51.1277\n",
      "      4        4.3150        4.2423  51.2585\n",
      "      5        4.3150        4.2423  51.0787\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3004\u001b[0m        \u001b[32m4.2423\u001b[0m  50.7960\n",
      "      2        4.3076        4.2423  51.0068\n",
      "      3        4.3076        4.2423  51.5872\n",
      "      4        4.3076        4.2423  51.2116\n",
      "      5        4.3076        4.2423  51.0747\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3010\u001b[0m        \u001b[32m4.3317\u001b[0m  50.7221\n",
      "      2        4.3081        4.3317  51.3804\n",
      "      3        4.3081        4.3317  51.6012\n",
      "      4        4.3081        4.3317  51.2825\n",
      "      5        4.3081        4.3317  50.9489\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m6.6641\u001b[0m       \u001b[32m11.9000\u001b[0m  51.2535\n",
      "      2        \u001b[36m5.0084\u001b[0m       11.9000  51.2506\n",
      "      3        5.0084       11.9000  51.5722\n",
      "      4        5.0084       11.9000  52.3115\n",
      "      5        5.0084       11.9000  52.2525\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1      \u001b[36m765.7959\u001b[0m       \u001b[32m11.9675\u001b[0m  50.5443\n",
      "      2        \u001b[36m5.0056\u001b[0m       11.9675  50.4114\n",
      "      3        5.0056       11.9675  52.7660\n",
      "      4        5.0056       11.9675  53.6551\n",
      "      5        5.0056       11.9675  54.6161\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1      \u001b[36m765.8180\u001b[0m       \u001b[32m11.9675\u001b[0m  54.8188\n",
      "      2        \u001b[36m5.0981\u001b[0m       11.9675  58.1818\n",
      "      3        5.0981       11.9675  58.7618\n",
      "      4        5.0981       11.9675  59.6933\n",
      "      5        5.0981       11.9675  60.1984\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1      \u001b[36m765.7187\u001b[0m       \u001b[32m11.9675\u001b[0m  52.6291\n",
      "      2        \u001b[36m4.9988\u001b[0m       11.9675  54.7935\n",
      "      3        4.9988       11.9675  58.4112\n",
      "      4        4.9988       11.9675  61.7907\n",
      "      5        4.9988       11.9675  57.5859\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1      \u001b[36m765.7069\u001b[0m        \u001b[32m4.2546\u001b[0m  52.1366\n",
      "      2        \u001b[36m4.9837\u001b[0m        4.2546  51.4803\n",
      "      3        4.9837        4.2546  51.7001\n",
      "      4        4.9837        4.2546  51.9748\n",
      "      5        4.9837        4.2546  51.8509\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7725\u001b[0m        \u001b[32m3.9187\u001b[0m  64.0215\n",
      "      2        \u001b[36m3.7670\u001b[0m        3.9200  65.0839\n",
      "      3        \u001b[36m3.7632\u001b[0m        3.9209  65.0295\n",
      "      4        \u001b[36m3.7603\u001b[0m        3.9215  65.1303\n",
      "      5        \u001b[36m3.7575\u001b[0m        3.9219  64.9196\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "RandomizedSearchCV took 42741.39 seconds for 20 candidates parameter settings.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e6b5eaf03aff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n\u001b[0;32m     52\u001b[0m       \" parameter settings.\" % ((time.time() - start), n_iter_search))\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'report' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from scipy.stats import loguniform, uniform\n",
    "params = {\n",
    "    'net__lr': [0.001,0.003,0.01,0.03,0.1,0.3,0.6,0.9,1],\n",
    "    'net__max_epochs': [20,40,50],\n",
    "    'net__optimizer__momentum': [0.95,0.96,0.97,0.98,0.99]\n",
    "}\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {'net__lr': loguniform(0.001,1),\n",
    "              'net__max_epochs': [20,30,40,50],\n",
    "              'net__optimizer__momentum': loguniform(0.9, 0.99)}\n",
    "\n",
    "pipe = Pipeline([(\"typetransform\", typetransform), (\"net\", net)])\n",
    "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')\n",
    "x_train2 = tfidf.fit_transform(x_train)\n",
    "x_trainshape = x_train2.shape[1]\n",
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X\n",
    "\n",
    "pole_model = RegressorModule()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(pole_model.parameters(), lr = 0.1)\n",
    "\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=30, lr=0.1, callbacks =[('earlystopping',EarlyStopping())])\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(pipe, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time.time()\n",
    "random_search.fit(x_train2, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time.time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "\n",
    "# gs = GridSearchCV(pipe, params, n_jobs=-1)\n",
    "# gs.fit(X=x_train, y=y_train);\n",
    "# print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grand-married",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.099 (std: 0.011)\n",
      "Parameters: {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.098 (std: 0.011)\n",
      "Parameters: {'net__lr': 0.0016770124951511836, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9457840905487397}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.097 (std: 0.011)\n",
      "Parameters: {'net__lr': 0.002630441086119309, 'net__max_epochs': 40, 'net__optimizer__momentum': 0.9183456932254296}\n",
      "\n",
      "{'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "report(random_search.cv_results_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "impaired-contributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8644\u001b[0m        \u001b[32m3.9511\u001b[0m  68.8521\n",
      "      2        \u001b[36m3.8590\u001b[0m        \u001b[32m3.9415\u001b[0m  68.8259\n",
      "      3        \u001b[36m3.8525\u001b[0m        3.9416  68.9574\n",
      "      4        \u001b[36m3.8465\u001b[0m        3.9420  69.1866\n",
      "      5        \u001b[36m3.8413\u001b[0m        \u001b[32m3.9412\u001b[0m  69.2820\n",
      "      6        \u001b[36m3.8359\u001b[0m        \u001b[32m3.9374\u001b[0m  69.7446\n",
      "      7        \u001b[36m3.8313\u001b[0m        \u001b[32m3.9369\u001b[0m  68.9858\n",
      "      8        \u001b[36m3.8265\u001b[0m        3.9419  69.9018\n",
      "      9        \u001b[36m3.8217\u001b[0m        3.9387  71.4834\n",
      "     10        \u001b[36m3.8171\u001b[0m        \u001b[32m3.9361\u001b[0m  73.6768\n",
      "     11        \u001b[36m3.8129\u001b[0m        3.9373  74.3237\n",
      "     12        \u001b[36m3.8091\u001b[0m        3.9397  66.4101\n",
      "     13        \u001b[36m3.8048\u001b[0m        3.9407  65.8983\n",
      "     14        \u001b[36m3.8012\u001b[0m        3.9412  66.0906\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Optimised RMSE: 1.9759188\n",
      "Re-initializing optimizer because the following parameters were re-set: momentum.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.7937\u001b[0m        \u001b[32m3.9409\u001b[0m  65.5602\n",
      "      2        \u001b[36m3.7901\u001b[0m        \u001b[32m3.9341\u001b[0m  65.2272\n",
      "      3        \u001b[36m3.7858\u001b[0m        3.9359  65.7110\n",
      "      4        \u001b[36m3.7823\u001b[0m        3.9355  65.7200\n",
      "      5        \u001b[36m3.7791\u001b[0m        3.9382  65.1797\n",
      "      6        \u001b[36m3.7760\u001b[0m        3.9387  65.9037\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Original RMSE: 1.9748926\n"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('Optimised RMSE:', rmse)\n",
    "\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=30, lr=0.1, callbacks =[('earlystopping',EarlyStopping())])\n",
    "\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('Original RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "framed-emphasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2384\u001b[0m        \u001b[32m4.2271\u001b[0m  85.9500\n",
      "      2        \u001b[36m4.1518\u001b[0m        \u001b[32m4.0940\u001b[0m  87.0139\n",
      "      3        \u001b[36m4.0593\u001b[0m        \u001b[32m4.0404\u001b[0m  87.2406\n",
      "      4        \u001b[36m4.0206\u001b[0m        4.0667  91.2488\n",
      "      5        \u001b[36m3.9876\u001b[0m        4.0535  89.7361\n",
      "      6        \u001b[36m3.9645\u001b[0m        \u001b[32m4.0235\u001b[0m  88.5633\n",
      "      7        \u001b[36m3.9467\u001b[0m        \u001b[32m4.0080\u001b[0m  87.4314\n",
      "      8        \u001b[36m3.9313\u001b[0m        \u001b[32m3.9954\u001b[0m  87.5183\n",
      "      9        \u001b[36m3.9171\u001b[0m        \u001b[32m3.9796\u001b[0m  87.8530\n",
      "     10        \u001b[36m3.9051\u001b[0m        \u001b[32m3.9638\u001b[0m  88.5243\n",
      "     11        \u001b[36m3.8915\u001b[0m        \u001b[32m3.9478\u001b[0m  87.9529\n",
      "     12        \u001b[36m3.8793\u001b[0m        \u001b[32m3.9421\u001b[0m  88.9259\n",
      "     13        \u001b[36m3.8669\u001b[0m        \u001b[32m3.9284\u001b[0m  88.5673\n",
      "     14        \u001b[36m3.8554\u001b[0m        3.9294  88.2296\n",
      "     15        \u001b[36m3.8445\u001b[0m        \u001b[32m3.9275\u001b[0m  88.4524\n",
      "     16        \u001b[36m3.8339\u001b[0m        \u001b[32m3.9218\u001b[0m  88.4943\n",
      "     17        \u001b[36m3.8202\u001b[0m        \u001b[32m3.9173\u001b[0m  89.2845\n",
      "     18        \u001b[36m3.8100\u001b[0m        \u001b[32m3.9156\u001b[0m  88.7341\n",
      "     19        \u001b[36m3.7985\u001b[0m        \u001b[32m3.9134\u001b[0m  89.5922\n",
      "     20        \u001b[36m3.7876\u001b[0m        \u001b[32m3.9092\u001b[0m  89.5595\n",
      "ReLU RMSE: 1.9688857\n",
      "Tanh\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.functional' has no attribute 'Tanh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bca7d9e281a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mpipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tfidf_vector_com\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midentity_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"array\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msublinear_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'[^\\s]+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"typetransform\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypetransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"net\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\regressor.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# this is actually a pylint bug:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralNetRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_train_begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_epoch_begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mon_epoch_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             self.run_single_epoch(dataset_train, training=True, prefix=\"train\",\n\u001b[0m\u001b[0;32m    776\u001b[0m                                   step_fn=self.train_step, **fit_params)\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mrun_single_epoch\u001b[1;34m(self, dataset, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[0myi_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myi\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_placeholder_y\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_batch_begin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myi_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_batch_size\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_accumulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mstep_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m             \u001b[0mstep_accumulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstore_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mtrain_step_single\u001b[1;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \"\"\"\n\u001b[0;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36minfer\u001b[1;34m(self, x, **fit_params)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[0mx_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_x_and_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_predict_nonlinearity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-bca7d9e281a8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonlin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'Tanh'"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "x_trainshape = 5844\n",
    "for act in ['ReLU','Tanh', 'Sigmoid']:\n",
    "    print(act)\n",
    "    \n",
    "        \n",
    "    if act == 'ReLU':        \n",
    "        class RegressorModule(nn.Module):\n",
    "            def __init__(\n",
    "                    self,\n",
    "                    num_units=100,\n",
    "                    nonlin=F.relu,\n",
    "            ):\n",
    "                super(RegressorModule, self).__init__()\n",
    "                self.num_units = num_units\n",
    "                self.nonlin = nonlin\n",
    "\n",
    "                self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "                self.nonlin = nonlin\n",
    "                self.dense1 = nn.Linear(num_units, 100)\n",
    "                self.output = nn.Linear(100, 1)\n",
    "\n",
    "            def forward(self, X, **kwargs):\n",
    "                X = self.nonlin(self.dense0(X))\n",
    "                X = F.relu(self.dense1(X))\n",
    "                X = self.output(X)\n",
    "                return X\n",
    "\n",
    "    if act == 'Tanh':         \n",
    "        class RegressorModule(nn.Module):\n",
    "            def __init__(\n",
    "                    self,\n",
    "                    num_units=100,\n",
    "                    nonlin=F.relu,\n",
    "            ):\n",
    "                super(RegressorModule, self).__init__()\n",
    "                self.num_units = num_units\n",
    "                self.nonlin = nonlin\n",
    "\n",
    "                self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "                self.nonlin = nonlin\n",
    "                self.dense1 = nn.Linear(num_units, 100)\n",
    "                self.output = nn.Linear(100, 1)\n",
    "\n",
    "            def forward(self, X, **kwargs):\n",
    "                X = self.nonlin(self.dense0(X))\n",
    "                X = F.Tanh(self.dense1(X))\n",
    "                X = self.output(X)\n",
    "                return X\n",
    "            \n",
    "    elif act == 'Sigmoid':  \n",
    "        class RegressorModule(nn.Module):\n",
    "            def __init__(\n",
    "                    self,\n",
    "                    num_units=100,\n",
    "                    nonlin=F.relu,\n",
    "            ):\n",
    "                super(RegressorModule, self).__init__()\n",
    "                self.num_units = num_units\n",
    "                self.nonlin = nonlin\n",
    "\n",
    "                self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "                self.nonlin = nonlin\n",
    "                self.dense1 = nn.Linear(num_units, 100)\n",
    "                self.output = nn.Linear(100, 1)\n",
    "\n",
    "            def forward(self, X, **kwargs):\n",
    "                X = self.nonlin(self.dense0(X))\n",
    "                X = F.Sigmoid(self.dense1(X))\n",
    "                X = self.output(X)\n",
    "                return X\n",
    "            \n",
    "    pole_model = RegressorModule()\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "    pipe.fit(X=x_train, y=y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(act,'RMSE:', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-coalition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2255\u001b[0m        \u001b[32m4.1949\u001b[0m  96.1022\n",
      "      2        \u001b[36m4.1338\u001b[0m        \u001b[32m4.0891\u001b[0m  97.2646\n",
      "      3        \u001b[36m4.0531\u001b[0m        4.1203  103.3378\n",
      "      4        \u001b[36m4.0212\u001b[0m        4.1149  96.4300\n",
      "      5        \u001b[36m4.0039\u001b[0m        4.1029  93.6004\n",
      "      6        \u001b[36m3.9912\u001b[0m        4.0921  92.7252\n",
      "      7        \u001b[36m3.9809\u001b[0m        \u001b[32m4.0743\u001b[0m  93.7762\n",
      "      8        \u001b[36m3.9719\u001b[0m        \u001b[32m4.0485\u001b[0m  93.4255\n",
      "      9        \u001b[36m3.9636\u001b[0m        \u001b[32m4.0319\u001b[0m  93.4076\n",
      "     10        \u001b[36m3.9554\u001b[0m        \u001b[32m4.0066\u001b[0m  96.6600\n",
      "     11        \u001b[36m3.9477\u001b[0m        \u001b[32m3.9928\u001b[0m  103.8739\n",
      "     12        \u001b[36m3.9404\u001b[0m        \u001b[32m3.9810\u001b[0m  102.1352\n",
      "     13        \u001b[36m3.9330\u001b[0m        \u001b[32m3.9707\u001b[0m  99.4711\n",
      "     14        \u001b[36m3.9255\u001b[0m        \u001b[32m3.9645\u001b[0m  94.1818\n",
      "     15        \u001b[36m3.9182\u001b[0m        \u001b[32m3.9591\u001b[0m  93.9350\n",
      "     16        \u001b[36m3.9110\u001b[0m        \u001b[32m3.9554\u001b[0m  94.3885\n",
      "     17        \u001b[36m3.9036\u001b[0m        \u001b[32m3.9503\u001b[0m  93.9939\n",
      "     18        \u001b[36m3.8965\u001b[0m        \u001b[32m3.9475\u001b[0m  94.6388\n",
      "     19        \u001b[36m3.8894\u001b[0m        \u001b[32m3.9450\u001b[0m  94.1009\n",
      "     20        \u001b[36m3.8824\u001b[0m        \u001b[32m3.9432\u001b[0m  93.2801\n",
      "ReLU RMSE: 1.9769257\n",
      "Tanh\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2158\u001b[0m        \u001b[32m4.1782\u001b[0m  87.8572\n",
      "      2        \u001b[36m4.1164\u001b[0m        \u001b[32m4.1003\u001b[0m  91.9389\n",
      "      3        \u001b[36m4.0513\u001b[0m        4.1260  92.2812\n",
      "      4        \u001b[36m4.0292\u001b[0m        \u001b[32m4.0894\u001b[0m  92.1498\n",
      "      5        \u001b[36m4.0181\u001b[0m        \u001b[32m4.0760\u001b[0m  92.6094\n",
      "      6        \u001b[36m4.0106\u001b[0m        \u001b[32m4.0726\u001b[0m  92.1768\n",
      "      7        \u001b[36m4.0050\u001b[0m        4.0735  91.8252\n",
      "      8        \u001b[36m4.0004\u001b[0m        4.0762  92.0509\n",
      "      9        \u001b[36m3.9967\u001b[0m        4.0797  92.1698\n",
      "     10        \u001b[36m3.9936\u001b[0m        4.0833  92.3598\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Tanh RMSE: 2.011593\n",
      "Sigmoid\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2760\u001b[0m        \u001b[32m4.2643\u001b[0m  89.0353\n",
      "      2        \u001b[36m4.2722\u001b[0m        4.2675  93.2597\n",
      "      3        \u001b[36m4.2628\u001b[0m        \u001b[32m4.2629\u001b[0m  93.6483\n",
      "      4        \u001b[36m4.2446\u001b[0m        \u001b[32m4.2466\u001b[0m  92.8841\n",
      "      5        \u001b[36m4.2185\u001b[0m        \u001b[32m4.2223\u001b[0m  93.7063\n",
      "      6        \u001b[36m4.1873\u001b[0m        \u001b[32m4.1929\u001b[0m  93.4365\n",
      "      7        \u001b[36m4.1530\u001b[0m        \u001b[32m4.1619\u001b[0m  93.1648\n",
      "      8        \u001b[36m4.1211\u001b[0m        \u001b[32m4.1350\u001b[0m  95.7342\n",
      "      9        \u001b[36m4.0960\u001b[0m        \u001b[32m4.1153\u001b[0m  100.2915\n",
      "     10        \u001b[36m4.0780\u001b[0m        \u001b[32m4.1024\u001b[0m  101.6295\n",
      "     11        \u001b[36m4.0650\u001b[0m        \u001b[32m4.0943\u001b[0m  100.5004\n",
      "     12        \u001b[36m4.0551\u001b[0m        \u001b[32m4.0899\u001b[0m  101.8200\n",
      "     13        \u001b[36m4.0474\u001b[0m        \u001b[32m4.0880\u001b[0m  92.7991\n",
      "     14        \u001b[36m4.0411\u001b[0m        4.0881  92.9880\n",
      "     15        \u001b[36m4.0359\u001b[0m        4.0896  92.8381\n",
      "     16        \u001b[36m4.0315\u001b[0m        4.0921  94.3856\n",
      "     17        \u001b[36m4.0277\u001b[0m        4.0953  93.3756\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Sigmoid RMSE: 2.015517\n"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')\n",
    "x_train2 = tfidf.fit_transform(x_train)\n",
    "x_test2 = tfidf.fit_transform(x_test)\n",
    "x_trainshape = x_train2.shape[1]\n",
    "\n",
    "in_dimensionopt = xtrainshape\n",
    "hid_dimensionopt = 160\n",
    "out_dimensionopt = 1\n",
    "for act in ['ReLU', 'Tanh', 'Sigmoid']:\n",
    "    print(act)\n",
    "\n",
    "        \n",
    "    if act == 'ReLU':        \n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionopt)\n",
    "                self.fc2 = nn.Linear(hid_dimensionopt,out_dimensionopt)\n",
    "                self.ReLU = torch.nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc2(hidden)\n",
    "                return output\n",
    "\n",
    "    elif act == 'Tanh':         \n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionopt)\n",
    "                self.fc2 = nn.Linear(hid_dimensionopt,out_dimensionopt)\n",
    "                self.Tanh = torch.nn.Tanh()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.Tanh(hidden)\n",
    "                output = self.fc2(hidden)\n",
    "                return output\n",
    "            \n",
    "    elif act == 'Sigmoid':  \n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionopt)\n",
    "                self.fc2 = nn.Linear(hid_dimensionopt,out_dimensionopt)\n",
    "                self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.sigmoid(hidden)\n",
    "                output = self.fc2(hidden)\n",
    "                return output\n",
    "\n",
    "    \n",
    "    pole_model = PoleNN_opt()\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    pipe = Pipeline([(\"typetransform\", typetransform), (\"net\", net)])\n",
    "    pipe.fit(X=x_train2, y=y_train)\n",
    "    y_pred = pipe.predict(x_test2)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(act,'RMSE:', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geographic-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2231\u001b[0m        \u001b[32m4.1904\u001b[0m  86.4767\n",
      "      2        \u001b[36m4.1292\u001b[0m        \u001b[32m4.0921\u001b[0m  91.0921\n",
      "      3        \u001b[36m4.0536\u001b[0m        4.1316  94.5392\n",
      "      4        \u001b[36m4.0256\u001b[0m        4.1033  94.7549\n",
      "      5        \u001b[36m4.0100\u001b[0m        4.0930  98.2438\n",
      "      6        \u001b[36m3.9978\u001b[0m        \u001b[32m4.0900\u001b[0m  95.9205\n",
      "      7        \u001b[36m3.9868\u001b[0m        \u001b[32m4.0881\u001b[0m  95.1803\n",
      "      8        \u001b[36m3.9769\u001b[0m        \u001b[32m4.0827\u001b[0m  99.9847\n",
      "      9        \u001b[36m3.9678\u001b[0m        \u001b[32m4.0676\u001b[0m  97.3442\n",
      "     10        \u001b[36m3.9595\u001b[0m        \u001b[32m4.0482\u001b[0m  98.7189\n",
      "     11        \u001b[36m3.9518\u001b[0m        \u001b[32m4.0258\u001b[0m  100.8778\n",
      "     12        \u001b[36m3.9443\u001b[0m        \u001b[32m4.0077\u001b[0m  97.4086\n",
      "     13        \u001b[36m3.9371\u001b[0m        \u001b[32m3.9915\u001b[0m  90.7352\n",
      "     14        \u001b[36m3.9301\u001b[0m        \u001b[32m3.9793\u001b[0m  90.8990\n",
      "     15        \u001b[36m3.9232\u001b[0m        \u001b[32m3.9704\u001b[0m  90.5943\n",
      "     16        \u001b[36m3.9160\u001b[0m        \u001b[32m3.9630\u001b[0m  90.1158\n",
      "     17        \u001b[36m3.9091\u001b[0m        \u001b[32m3.9570\u001b[0m  90.7581\n",
      "     18        \u001b[36m3.9022\u001b[0m        \u001b[32m3.9520\u001b[0m  94.9956\n",
      "     19        \u001b[36m3.8952\u001b[0m        \u001b[32m3.9469\u001b[0m  99.3056\n",
      "     20        \u001b[36m3.8884\u001b[0m        \u001b[32m3.9413\u001b[0m  109.5887\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8816\u001b[0m        \u001b[32m3.8782\u001b[0m  82.3051\n",
      "      2        \u001b[36m3.8746\u001b[0m        \u001b[32m3.8780\u001b[0m  83.9290\n",
      "      3        \u001b[36m3.8679\u001b[0m        3.8790  83.4667\n",
      "      4        \u001b[36m3.8614\u001b[0m        3.8784  82.1124\n",
      "      5        \u001b[36m3.8548\u001b[0m        3.8783  81.7181\n",
      "      6        \u001b[36m3.8484\u001b[0m        \u001b[32m3.8771\u001b[0m  72.6095\n",
      "      7        \u001b[36m3.8419\u001b[0m        3.8772  79.3179\n",
      "      8        \u001b[36m3.8360\u001b[0m        3.8785  86.4032\n",
      "      9        \u001b[36m3.8299\u001b[0m        3.8795  84.4770\n",
      "     10        \u001b[36m3.8238\u001b[0m        3.8801  83.2519\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8880\u001b[0m        \u001b[32m3.9279\u001b[0m  78.5130\n",
      "      2        \u001b[36m3.8807\u001b[0m        \u001b[32m3.9257\u001b[0m  82.4291\n",
      "      3        \u001b[36m3.8738\u001b[0m        \u001b[32m3.9239\u001b[0m  82.9389\n",
      "      4        \u001b[36m3.8673\u001b[0m        3.9239  81.4889\n",
      "      5        \u001b[36m3.8604\u001b[0m        \u001b[32m3.9216\u001b[0m  81.8609\n",
      "      6        \u001b[36m3.8537\u001b[0m        \u001b[32m3.9193\u001b[0m  82.0737\n",
      "      7        \u001b[36m3.8471\u001b[0m        3.9228  81.2152\n",
      "      8        \u001b[36m3.8411\u001b[0m        3.9195  73.0748\n",
      "      9        \u001b[36m3.8346\u001b[0m        3.9219  71.9154\n",
      "     10        \u001b[36m3.8285\u001b[0m        3.9211  71.9394\n",
      "     11        \u001b[36m3.8221\u001b[0m        \u001b[32m3.9186\u001b[0m  71.5548\n",
      "     12        \u001b[36m3.8160\u001b[0m        3.9205  71.2591\n",
      "     13        \u001b[36m3.8101\u001b[0m        3.9202  72.7523\n",
      "     14        \u001b[36m3.8039\u001b[0m        3.9219  70.9874\n",
      "     15        \u001b[36m3.7980\u001b[0m        3.9205  71.1972\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8942\u001b[0m        \u001b[32m3.9285\u001b[0m  68.4090\n",
      "      2        \u001b[36m3.8867\u001b[0m        \u001b[32m3.9264\u001b[0m  70.9664\n",
      "      3        \u001b[36m3.8797\u001b[0m        \u001b[32m3.9251\u001b[0m  70.0064\n",
      "      4        \u001b[36m3.8726\u001b[0m        \u001b[32m3.9218\u001b[0m  70.6957\n",
      "      5        \u001b[36m3.8662\u001b[0m        \u001b[32m3.9213\u001b[0m  70.5478\n",
      "      6        \u001b[36m3.8597\u001b[0m        \u001b[32m3.9189\u001b[0m  70.7656\n",
      "      7        \u001b[36m3.8530\u001b[0m        3.9193  69.7526\n",
      "      8        \u001b[36m3.8466\u001b[0m        \u001b[32m3.9162\u001b[0m  71.0643\n",
      "      9        \u001b[36m3.8404\u001b[0m        \u001b[32m3.9153\u001b[0m  73.7334\n",
      "     10        \u001b[36m3.8341\u001b[0m        \u001b[32m3.9148\u001b[0m  83.5811\n",
      "     11        \u001b[36m3.8277\u001b[0m        \u001b[32m3.9138\u001b[0m  82.6371\n",
      "     12        \u001b[36m3.8217\u001b[0m        \u001b[32m3.9122\u001b[0m  83.9301\n",
      "     13        \u001b[36m3.8154\u001b[0m        \u001b[32m3.9118\u001b[0m  82.9450\n",
      "     14        \u001b[36m3.8089\u001b[0m        3.9145  83.4534\n",
      "     15        \u001b[36m3.8028\u001b[0m        3.9142  85.0912\n",
      "     16        \u001b[36m3.7965\u001b[0m        3.9158  82.4005\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8879\u001b[0m        \u001b[32m3.9270\u001b[0m  73.8522\n",
      "      2        \u001b[36m3.8801\u001b[0m        \u001b[32m3.9245\u001b[0m  70.9754\n",
      "      3        \u001b[36m3.8731\u001b[0m        \u001b[32m3.9228\u001b[0m  70.9943\n",
      "      4        \u001b[36m3.8663\u001b[0m        \u001b[32m3.9213\u001b[0m  71.5248\n",
      "      5        \u001b[36m3.8595\u001b[0m        \u001b[32m3.9193\u001b[0m  72.6856\n",
      "      6        \u001b[36m3.8531\u001b[0m        \u001b[32m3.9175\u001b[0m  81.0008\n",
      "      7        \u001b[36m3.8464\u001b[0m        3.9193  82.1999\n",
      "      8        \u001b[36m3.8399\u001b[0m        \u001b[32m3.9173\u001b[0m  83.1465\n",
      "      9        \u001b[36m3.8335\u001b[0m        3.9180  83.4706\n",
      "     10        \u001b[36m3.8273\u001b[0m        3.9177  82.8889\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.8805\u001b[0m        \u001b[32m3.9315\u001b[0m  69.7854\n",
      "      2        \u001b[36m3.8732\u001b[0m        \u001b[32m3.9265\u001b[0m  74.2503\n",
      "      3        \u001b[36m3.8662\u001b[0m        \u001b[32m3.9228\u001b[0m  73.9427\n",
      "      4        \u001b[36m3.8592\u001b[0m        \u001b[32m3.9197\u001b[0m  73.2383\n",
      "      5        \u001b[36m3.8522\u001b[0m        \u001b[32m3.9169\u001b[0m  74.7190\n",
      "      6        \u001b[36m3.8454\u001b[0m        \u001b[32m3.9142\u001b[0m  74.0077\n",
      "      7        \u001b[36m3.8390\u001b[0m        3.9150  75.7754\n",
      "      8        \u001b[36m3.8323\u001b[0m        \u001b[32m3.9076\u001b[0m  76.5718\n",
      "      9        \u001b[36m3.8260\u001b[0m        3.9093  75.6538\n",
      "     10        \u001b[36m3.8198\u001b[0m        \u001b[32m3.9062\u001b[0m  79.8440\n",
      "     11        \u001b[36m3.8130\u001b[0m        \u001b[32m3.9053\u001b[0m  91.2728\n",
      "     12        \u001b[36m3.8068\u001b[0m        \u001b[32m3.9010\u001b[0m  92.9930\n",
      "     13        \u001b[36m3.8007\u001b[0m        \u001b[32m3.8992\u001b[0m  88.0251\n",
      "     14        \u001b[36m3.7944\u001b[0m        \u001b[32m3.8992\u001b[0m  88.5716\n",
      "     15        \u001b[36m3.7881\u001b[0m        \u001b[32m3.8975\u001b[0m  88.0532\n",
      "     16        \u001b[36m3.7822\u001b[0m        \u001b[32m3.8974\u001b[0m  82.0405\n",
      "     17        \u001b[36m3.7762\u001b[0m        \u001b[32m3.8947\u001b[0m  79.6038\n",
      "     18        \u001b[36m3.7699\u001b[0m        \u001b[32m3.8945\u001b[0m  81.5783\n",
      "     19        \u001b[36m3.7640\u001b[0m        \u001b[32m3.8931\u001b[0m  81.6250\n",
      "     20        \u001b[36m3.7581\u001b[0m        3.8932  80.4386\n",
      "[0.07564159 0.08146327 0.08400602 0.08643798 0.08821664]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-248724a83c58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RMSE:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mlosslist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "losslist = []\n",
    "\n",
    "for act in ['ReLU', 'Tanh', 'Sigmoid']:\n",
    "    print(act)\n",
    "    \n",
    "    tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')\n",
    "    x_train2 = tfidf.fit_transform(x_train)\n",
    "    x_test2 = tfidf.fit_transform(x_test)\n",
    "    x_trainshape = x_train2.shape[1]\n",
    "\n",
    "    in_dimensionopt = x_trainshape\n",
    "    hid_dimensionopt = 160\n",
    "    out_dimensionopt = 1\n",
    "\n",
    "        \n",
    "    if act == 'ReLU':        \n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionopt)\n",
    "                self.fc2 = nn.Linear(hid_dimensionopt,out_dimensionopt)\n",
    "                self.ReLU = torch.nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc2(hidden)\n",
    "                return output\n",
    "\n",
    "    elif act == 'Tanh':         \n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionopt)\n",
    "                self.fc2 = nn.Linear(hid_dimensionopt,out_dimensionopt)\n",
    "                self.Tanh = torch.nn.Tanh()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.Tanh(hidden)\n",
    "                output = self.fc2(hidden)\n",
    "                return output\n",
    "            \n",
    "    elif act == 'Sigmoid':  \n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionopt)\n",
    "                self.fc2 = nn.Linear(hid_dimensionopt,out_dimensionopt)\n",
    "                self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.sigmoid(hidden)\n",
    "                output = self.fc2(hidden)\n",
    "                return output\n",
    "\n",
    "    \n",
    "    pole_model = PoleNN_opt()\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    pipe = Pipeline([(\"typetransform\", typetransform), (\"net\", net)])\n",
    "    pipe.fit(X=x_train2, y=y_train)\n",
    "#     y_pred = pipe.predict(x_test2)\n",
    "\n",
    "    cv = cross_validate(pipe,x_train2,y_train)\n",
    "    cvlist = cv['test_score']\n",
    "    print(cv['test_score'])\n",
    "    \n",
    "#     rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "#     print(act,'RMSE:', rmse)\n",
    "    losslist.append((sum(cvlist)/len(cvlist)))\n",
    "\n",
    "print((losslist.index(max(losslist)),max(losslist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "capital-federal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en' 'th' 'ko' 'ja' 'de' 'es' 'fr' 'und' 'nl' 'it' 'tr' 'ar' 'kn' 'pt'\n",
      " 'ro' 'tl' 'pl' 'et' 'fi' 'el' 'ca' 'cs' 'hi' 'in' 'zh' 'te' 'fa' 'ru'\n",
      " 'bg' 'da' 'uk' 'ur' 'gu' 'ml' 'sl' 'vi' 'cy' 'ht' 'ta' 'ne' 'lt' 'sv'\n",
      " 'is' 'bn' 'mr' 'eu' 'no' 'hu' 'pa' 'lv' 'si' 'iw' 'sr' 'hy' 'ckb' 'ka'\n",
      " 'or' 'my' 'ps' 'am']\n",
      "79        0.8800\n",
      "110       1.0900\n",
      "162      -2.2000\n",
      "167      -0.8200\n",
      "207      -4.5000\n",
      "           ...  \n",
      "507986    0.9625\n",
      "508064   -2.3000\n",
      "508068    1.8500\n",
      "508072    1.3800\n",
      "508134    1.0250\n",
      "Name: Change, Length: 12705, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(merged['lang'].unique())\n",
    "print(merged['Change'].loc[merged['lang'] == 'it'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "embedded-bargain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1155\u001b[0m        \u001b[32m4.0043\u001b[0m  1.5314\n",
      "      2        \u001b[36m4.1141\u001b[0m        \u001b[32m4.0038\u001b[0m  1.6064\n",
      "      3        \u001b[36m4.1129\u001b[0m        \u001b[32m4.0033\u001b[0m  1.5234\n",
      "      4        \u001b[36m4.1118\u001b[0m        \u001b[32m4.0030\u001b[0m  1.5264\n",
      "      5        \u001b[36m4.1108\u001b[0m        \u001b[32m4.0028\u001b[0m  1.5564\n",
      "      6        \u001b[36m4.1097\u001b[0m        \u001b[32m4.0026\u001b[0m  1.6473\n",
      "      7        \u001b[36m4.1086\u001b[0m        \u001b[32m4.0024\u001b[0m  1.6833\n",
      "      8        \u001b[36m4.1074\u001b[0m        \u001b[32m4.0022\u001b[0m  1.6373\n",
      "      9        \u001b[36m4.1063\u001b[0m        \u001b[32m4.0020\u001b[0m  1.5894\n",
      "     10        \u001b[36m4.1050\u001b[0m        \u001b[32m4.0019\u001b[0m  1.6203\n",
      "     11        \u001b[36m4.1037\u001b[0m        \u001b[32m4.0018\u001b[0m  1.5194\n",
      "     12        \u001b[36m4.1024\u001b[0m        \u001b[32m4.0017\u001b[0m  1.5095\n",
      "     13        \u001b[36m4.1011\u001b[0m        4.0017  1.5194\n",
      "     14        \u001b[36m4.0998\u001b[0m        4.0017  1.5204\n",
      "     15        \u001b[36m4.0984\u001b[0m        4.0018  1.6034\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "RMSE: 2.0425456\n",
      "Optimum parameters: it : 2.0425456\n"
     ]
    }
   ],
   "source": [
    "# all_tweets = merged[['text','lang']]\n",
    "# all_tweetst = all_tweets['text'].to_list()\n",
    "langlist = merged['lang'].unique()\n",
    "langlist = ['it']\n",
    "rmselist = []\n",
    "for lang in langlist:\n",
    "    \n",
    "    print(lang)\n",
    "    y = merged['Change'].loc[merged['lang'] == lang]\n",
    "    index = merged.index[merged['lang'] == lang].tolist()\n",
    "    X = pd.DataFrame(processed_tweets)\n",
    "    X['lang'] = merged['lang']\n",
    "    X = X[0].loc[X['lang'] == lang]\n",
    "    X = X.to_list()\n",
    "    from sklearn.model_selection import train_test_split  \n",
    "    x_train2, x_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    y_train2 = y_train2.values.reshape(-1,1)\n",
    "    y_test2 = y_test2.values.reshape(-1,1)\n",
    "    y_train2 = y_train2.astype(np.float32)\n",
    "    y_test2 = y_test2.astype(np.float32)\n",
    "    \n",
    "    tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')\n",
    "    x_train3 = tfidf.fit_transform(x_train2)\n",
    "    x_test3 = tfidf.fit_transform(x_test2)\n",
    "    x_trainshape = x_train3.shape[1]\n",
    "\n",
    "    optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "    in_dimensionopt = x_trainshape\n",
    "    hid_dimensionopt = 160\n",
    "    out_dimensionopt = 1\n",
    "\n",
    "    class PoleNN_opt(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(PoleNN_opt, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionopt)\n",
    "            self.fc2 = nn.Linear(hid_dimensionopt,out_dimensionopt)\n",
    "            self.ReLU = torch.nn.ReLU()\n",
    "\n",
    "        def forward(self, X):\n",
    "            hidden = self.fc1(X)\n",
    "            hidden = self.ReLU(hidden)\n",
    "            output = self.fc2(hidden)\n",
    "            return output\n",
    "\n",
    "    pole_model = PoleNN_opt()\n",
    "\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    def typechange(x):\n",
    "        return x.astype(dtype = np.float32)\n",
    "    typetransform = FunctionTransformer(typechange)\n",
    "    # pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "    # pipe = Pipeline([('net', net)])\n",
    "#     pipe = Pipeline([(\"typetransform\", typetransform), (\"net\", net)])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "    # net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "    pipe.fit(X=x_train2, y=y_train2)\n",
    "    y_pred = pipe.predict(x_test2)\n",
    "    rmse = mean_squared_error(y_test2, y_pred, squared = False)\n",
    "    print('RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "\n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", langlist[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "australian-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2248\u001b[0m        \u001b[32m4.1937\u001b[0m  95.1401\n",
      "      2        \u001b[36m4.1330\u001b[0m        \u001b[32m4.0905\u001b[0m  99.4402\n",
      "      3        \u001b[36m4.0543\u001b[0m        4.1293  100.6971\n",
      "      4        \u001b[36m4.0239\u001b[0m        4.1083  101.0911\n",
      "      5        \u001b[36m4.0071\u001b[0m        4.0956  100.3421\n",
      "      6        \u001b[36m3.9940\u001b[0m        \u001b[32m4.0904\u001b[0m  100.8420\n",
      "      7        \u001b[36m3.9827\u001b[0m        \u001b[32m4.0866\u001b[0m  101.3059\n",
      "      8        \u001b[36m3.9732\u001b[0m        \u001b[32m4.0756\u001b[0m  102.0866\n",
      "      9        \u001b[36m3.9647\u001b[0m        \u001b[32m4.0564\u001b[0m  101.0782\n",
      "     10        \u001b[36m3.9565\u001b[0m        \u001b[32m4.0299\u001b[0m  102.2372\n",
      "     11        \u001b[36m3.9491\u001b[0m        \u001b[32m4.0122\u001b[0m  101.1941\n",
      "     12        \u001b[36m3.9420\u001b[0m        \u001b[32m3.9961\u001b[0m  102.1762\n",
      "     13        \u001b[36m3.9352\u001b[0m        \u001b[32m3.9836\u001b[0m  120.4084\n",
      "     14        \u001b[36m3.9283\u001b[0m        \u001b[32m3.9748\u001b[0m  119.1072\n",
      "     15        \u001b[36m3.9214\u001b[0m        \u001b[32m3.9677\u001b[0m  119.3522\n",
      "     16        \u001b[36m3.9145\u001b[0m        \u001b[32m3.9617\u001b[0m  116.8121\n",
      "     17        \u001b[36m3.9075\u001b[0m        \u001b[32m3.9577\u001b[0m  117.0473\n",
      "     18        \u001b[36m3.9006\u001b[0m        \u001b[32m3.9538\u001b[0m  115.3673\n",
      "     19        \u001b[36m3.8935\u001b[0m        \u001b[32m3.9493\u001b[0m  113.9351\n",
      "     20        \u001b[36m3.8863\u001b[0m        \u001b[32m3.9451\u001b[0m  112.3032\n",
      "1 RMSE: 1.9774234\n",
      "2\n",
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2236\u001b[0m        \u001b[32m4.1910\u001b[0m  103.0381\n",
      "      2        \u001b[36m4.1285\u001b[0m        \u001b[32m4.0846\u001b[0m  107.5213\n",
      "      3        \u001b[36m4.0494\u001b[0m        4.1056  107.0090\n",
      "      4        \u001b[36m4.0178\u001b[0m        4.1066  95.5001\n",
      "      5        \u001b[36m4.0005\u001b[0m        4.0940  91.7163\n",
      "      6        \u001b[36m3.9880\u001b[0m        \u001b[32m4.0792\u001b[0m  89.8152\n",
      "      7        \u001b[36m3.9776\u001b[0m        \u001b[32m4.0576\u001b[0m  88.4516\n",
      "      8        \u001b[36m3.9685\u001b[0m        \u001b[32m4.0360\u001b[0m  89.2668\n",
      "      9        \u001b[36m3.9601\u001b[0m        \u001b[32m4.0160\u001b[0m  88.9211\n",
      "     10        \u001b[36m3.9529\u001b[0m        \u001b[32m3.9996\u001b[0m  89.1129\n",
      "     11        \u001b[36m3.9462\u001b[0m        \u001b[32m3.9888\u001b[0m  89.5715\n",
      "     12        \u001b[36m3.9395\u001b[0m        \u001b[32m3.9803\u001b[0m  89.2198\n",
      "     13        \u001b[36m3.9331\u001b[0m        \u001b[32m3.9735\u001b[0m  89.3307\n",
      "     14        \u001b[36m3.9269\u001b[0m        \u001b[32m3.9678\u001b[0m  90.1139\n",
      "     15        \u001b[36m3.9207\u001b[0m        \u001b[32m3.9634\u001b[0m  89.5665\n",
      "     16        \u001b[36m3.9147\u001b[0m        \u001b[32m3.9588\u001b[0m  89.9381\n",
      "     17        \u001b[36m3.9084\u001b[0m        \u001b[32m3.9556\u001b[0m  92.8072\n",
      "     18        \u001b[36m3.9024\u001b[0m        \u001b[32m3.9536\u001b[0m  93.6583\n",
      "     19        \u001b[36m3.8962\u001b[0m        \u001b[32m3.9495\u001b[0m  92.0489\n",
      "     20        \u001b[36m3.8896\u001b[0m        \u001b[32m3.9492\u001b[0m  91.0160\n",
      "2 RMSE: 1.978194\n",
      "3\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2278\u001b[0m        \u001b[32m4.1990\u001b[0m  88.7898\n",
      "      2        \u001b[36m4.1393\u001b[0m        \u001b[32m4.0938\u001b[0m  91.9410\n",
      "      3        \u001b[36m4.0577\u001b[0m        4.1324  90.9990\n",
      "      4        \u001b[36m4.0264\u001b[0m        4.1063  90.7812\n",
      "      5        \u001b[36m4.0104\u001b[0m        \u001b[32m4.0923\u001b[0m  90.8572\n",
      "      6        \u001b[36m3.9988\u001b[0m        \u001b[32m4.0886\u001b[0m  90.1858\n",
      "      7        \u001b[36m3.9894\u001b[0m        \u001b[32m4.0877\u001b[0m  89.2158\n",
      "      8        \u001b[36m3.9811\u001b[0m        \u001b[32m4.0833\u001b[0m  91.9296\n",
      "      9        \u001b[36m3.9738\u001b[0m        \u001b[32m4.0742\u001b[0m  93.5507\n",
      "     10        \u001b[36m3.9669\u001b[0m        \u001b[32m4.0608\u001b[0m  92.0497\n",
      "     11        \u001b[36m3.9603\u001b[0m        \u001b[32m4.0422\u001b[0m  94.2698\n",
      "     12        \u001b[36m3.9538\u001b[0m        \u001b[32m4.0263\u001b[0m  93.5921\n",
      "     13        \u001b[36m3.9475\u001b[0m        \u001b[32m4.0098\u001b[0m  92.4101\n",
      "     14        \u001b[36m3.9413\u001b[0m        \u001b[32m3.9949\u001b[0m  93.4715\n",
      "     15        \u001b[36m3.9353\u001b[0m        \u001b[32m3.9852\u001b[0m  93.3706\n",
      "     16        \u001b[36m3.9297\u001b[0m        \u001b[32m3.9742\u001b[0m  93.4171\n",
      "     17        \u001b[36m3.9238\u001b[0m        \u001b[32m3.9678\u001b[0m  91.5904\n",
      "     18        \u001b[36m3.9184\u001b[0m        \u001b[32m3.9610\u001b[0m  93.0250\n",
      "     19        \u001b[36m3.9128\u001b[0m        \u001b[32m3.9580\u001b[0m  92.0869\n",
      "     20        \u001b[36m3.9072\u001b[0m        \u001b[32m3.9537\u001b[0m  95.6864\n",
      "3 RMSE: 1.979502\n",
      "4\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2212\u001b[0m        \u001b[32m4.1864\u001b[0m  81.8284\n",
      "      2        \u001b[36m4.1235\u001b[0m        \u001b[32m4.0867\u001b[0m  83.9232\n",
      "      3        \u001b[36m4.0492\u001b[0m        4.1268  84.6635\n",
      "      4        \u001b[36m4.0206\u001b[0m        4.1110  84.8763\n",
      "      5        \u001b[36m4.0047\u001b[0m        4.1017  83.7914\n",
      "      6        \u001b[36m3.9927\u001b[0m        4.0951  85.3987\n",
      "      7        \u001b[36m3.9830\u001b[0m        \u001b[32m4.0857\u001b[0m  84.7024\n",
      "      8        \u001b[36m3.9748\u001b[0m        \u001b[32m4.0684\u001b[0m  84.2979\n",
      "      9        \u001b[36m3.9674\u001b[0m        \u001b[32m4.0491\u001b[0m  84.3648\n",
      "     10        \u001b[36m3.9607\u001b[0m        \u001b[32m4.0284\u001b[0m  83.5376\n",
      "     11        \u001b[36m3.9549\u001b[0m        \u001b[32m4.0116\u001b[0m  84.5736\n",
      "     12        \u001b[36m3.9494\u001b[0m        \u001b[32m3.9983\u001b[0m  84.0641\n",
      "     13        \u001b[36m3.9439\u001b[0m        \u001b[32m3.9878\u001b[0m  84.3518\n",
      "     14        \u001b[36m3.9387\u001b[0m        \u001b[32m3.9801\u001b[0m  84.7284\n",
      "     15        \u001b[36m3.9337\u001b[0m        \u001b[32m3.9744\u001b[0m  84.0911\n",
      "     16        \u001b[36m3.9292\u001b[0m        \u001b[32m3.9703\u001b[0m  84.2559\n",
      "     17        \u001b[36m3.9245\u001b[0m        \u001b[32m3.9672\u001b[0m  84.4087\n",
      "     18        \u001b[36m3.9198\u001b[0m        \u001b[32m3.9625\u001b[0m  84.7514\n",
      "     19        \u001b[36m3.9149\u001b[0m        \u001b[32m3.9597\u001b[0m  84.4467\n",
      "     20        \u001b[36m3.9101\u001b[0m        \u001b[32m3.9559\u001b[0m  84.8603\n",
      "4 RMSE: 1.9796351\n",
      "5\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2300\u001b[0m        \u001b[32m4.2039\u001b[0m  82.9962\n",
      "      2        \u001b[36m4.1418\u001b[0m        \u001b[32m4.0931\u001b[0m  85.0391\n",
      "      3        \u001b[36m4.0487\u001b[0m        \u001b[32m4.0472\u001b[0m  84.1280\n",
      "      4        \u001b[36m4.0127\u001b[0m        \u001b[32m4.0312\u001b[0m  84.4617\n",
      "      5        \u001b[36m3.9942\u001b[0m        \u001b[32m4.0154\u001b[0m  84.8313\n",
      "      6        \u001b[36m3.9811\u001b[0m        \u001b[32m4.0042\u001b[0m  84.5416\n",
      "      7        \u001b[36m3.9704\u001b[0m        \u001b[32m3.9947\u001b[0m  84.3698\n",
      "      8        \u001b[36m3.9611\u001b[0m        \u001b[32m3.9870\u001b[0m  84.1280\n",
      "      9        \u001b[36m3.9529\u001b[0m        \u001b[32m3.9814\u001b[0m  84.7424\n",
      "     10        \u001b[36m3.9453\u001b[0m        \u001b[32m3.9750\u001b[0m  83.9452\n",
      "     11        \u001b[36m3.9384\u001b[0m        \u001b[32m3.9714\u001b[0m  82.0302\n",
      "     12        \u001b[36m3.9323\u001b[0m        \u001b[32m3.9674\u001b[0m  85.4956\n",
      "     13        \u001b[36m3.9271\u001b[0m        \u001b[32m3.9634\u001b[0m  85.0191\n",
      "     14        \u001b[36m3.9222\u001b[0m        \u001b[32m3.9603\u001b[0m  86.7693\n",
      "     15        \u001b[36m3.9174\u001b[0m        \u001b[32m3.9591\u001b[0m  91.5740\n",
      "     16        \u001b[36m3.9131\u001b[0m        \u001b[32m3.9559\u001b[0m  92.6838\n",
      "     17        \u001b[36m3.9085\u001b[0m        \u001b[32m3.9543\u001b[0m  87.6168\n",
      "     18        \u001b[36m3.9043\u001b[0m        \u001b[32m3.9530\u001b[0m  93.8006\n",
      "     19        \u001b[36m3.9001\u001b[0m        \u001b[32m3.9518\u001b[0m  96.2284\n",
      "     20        \u001b[36m3.8960\u001b[0m        \u001b[32m3.9489\u001b[0m  99.4998\n",
      "5 RMSE: 1.9784541\n",
      "6\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2272\u001b[0m        \u001b[32m4.1968\u001b[0m  98.9711\n",
      "      2        \u001b[36m4.1365\u001b[0m        \u001b[32m4.0936\u001b[0m  98.7772\n",
      "      3        \u001b[36m4.0574\u001b[0m        4.1324  92.5426\n",
      "      4        \u001b[36m4.0280\u001b[0m        4.0975  87.0590\n",
      "      5        \u001b[36m4.0129\u001b[0m        \u001b[32m4.0816\u001b[0m  87.7743\n",
      "      6        \u001b[36m4.0014\u001b[0m        \u001b[32m4.0786\u001b[0m  87.1759\n",
      "      7        \u001b[36m3.9912\u001b[0m        4.0794  87.7164\n",
      "      8        \u001b[36m3.9821\u001b[0m        4.0821  91.3167\n",
      "      9        \u001b[36m3.9740\u001b[0m        4.0817  90.2678\n",
      "     10        \u001b[36m3.9670\u001b[0m        \u001b[32m4.0748\u001b[0m  88.8582\n",
      "     11        \u001b[36m3.9605\u001b[0m        \u001b[32m4.0649\u001b[0m  87.1599\n",
      "     12        \u001b[36m3.9547\u001b[0m        \u001b[32m4.0487\u001b[0m  85.6525\n",
      "     13        \u001b[36m3.9493\u001b[0m        \u001b[32m4.0337\u001b[0m  86.8073\n",
      "     14        \u001b[36m3.9442\u001b[0m        \u001b[32m4.0162\u001b[0m  86.5925\n",
      "     15        \u001b[36m3.9397\u001b[0m        \u001b[32m4.0095\u001b[0m  85.9492\n",
      "     16        \u001b[36m3.9353\u001b[0m        \u001b[32m3.9952\u001b[0m  85.6804\n",
      "     17        \u001b[36m3.9308\u001b[0m        \u001b[32m3.9879\u001b[0m  86.2658\n",
      "     18        \u001b[36m3.9265\u001b[0m        \u001b[32m3.9849\u001b[0m  86.1300\n",
      "     19        \u001b[36m3.9223\u001b[0m        \u001b[32m3.9784\u001b[0m  85.9971\n",
      "     20        \u001b[36m3.9183\u001b[0m        \u001b[32m3.9755\u001b[0m  86.1420\n",
      "6 RMSE: 1.984563\n",
      "7\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2193\u001b[0m        \u001b[32m4.1836\u001b[0m  85.4777\n",
      "      2        \u001b[36m4.1221\u001b[0m        \u001b[32m4.1016\u001b[0m  87.3447\n",
      "      3        \u001b[36m4.0527\u001b[0m        4.1215  87.0091\n",
      "      4        \u001b[36m4.0294\u001b[0m        \u001b[32m4.0831\u001b[0m  87.5246\n",
      "      5        \u001b[36m4.0176\u001b[0m        \u001b[32m4.0712\u001b[0m  87.2748\n",
      "      6        \u001b[36m4.0090\u001b[0m        \u001b[32m4.0683\u001b[0m  87.2968\n",
      "      7        \u001b[36m4.0018\u001b[0m        4.0692  87.3477\n",
      "      8        \u001b[36m3.9956\u001b[0m        4.0721  87.3717\n",
      "      9        \u001b[36m3.9896\u001b[0m        4.0783  87.3677\n",
      "     10        \u001b[36m3.9844\u001b[0m        4.0832  87.3737\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "7 RMSE: 2.0111628\n",
      "8\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2245\u001b[0m        \u001b[32m4.1920\u001b[0m  84.9592\n",
      "      2        \u001b[36m4.1311\u001b[0m        \u001b[32m4.0942\u001b[0m  87.3857\n",
      "      3        \u001b[36m4.0554\u001b[0m        4.1305  86.8063\n",
      "      4        \u001b[36m4.0283\u001b[0m        \u001b[32m4.0908\u001b[0m  86.8463\n",
      "      5        \u001b[36m4.0142\u001b[0m        \u001b[32m4.0751\u001b[0m  86.5016\n",
      "      6        \u001b[36m4.0036\u001b[0m        \u001b[32m4.0707\u001b[0m  86.4796\n",
      "      7        \u001b[36m3.9946\u001b[0m        \u001b[32m4.0645\u001b[0m  86.6295\n",
      "      8        \u001b[36m3.9870\u001b[0m        \u001b[32m4.0632\u001b[0m  87.7144\n",
      "      9        \u001b[36m3.9807\u001b[0m        4.0685  86.7593\n",
      "     10        \u001b[36m3.9751\u001b[0m        4.0703  86.5875\n",
      "     11        \u001b[36m3.9700\u001b[0m        4.0758  87.5825\n",
      "     12        \u001b[36m3.9655\u001b[0m        4.0737  86.4507\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "8 RMSE: 2.007808\n",
      "9\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2237\u001b[0m        \u001b[32m4.1905\u001b[0m  85.6485\n",
      "      2        \u001b[36m4.1295\u001b[0m        \u001b[32m4.0928\u001b[0m  93.4989\n",
      "      3        \u001b[36m4.0542\u001b[0m        4.1313  92.0588\n",
      "      4        \u001b[36m4.0264\u001b[0m        4.0989  91.1416\n",
      "      5        \u001b[36m4.0114\u001b[0m        \u001b[32m4.0878\u001b[0m  92.3859\n",
      "      6        \u001b[36m3.9998\u001b[0m        \u001b[32m4.0851\u001b[0m  88.5402\n",
      "      7        \u001b[36m3.9900\u001b[0m        4.0865  87.8980\n",
      "      8        \u001b[36m3.9816\u001b[0m        4.0865  87.3513\n",
      "      9        \u001b[36m3.9744\u001b[0m        \u001b[32m4.0829\u001b[0m  92.4532\n",
      "     10        \u001b[36m3.9682\u001b[0m        \u001b[32m4.0723\u001b[0m  92.0173\n",
      "     11        \u001b[36m3.9627\u001b[0m        \u001b[32m4.0562\u001b[0m  89.7752\n",
      "     12        \u001b[36m3.9578\u001b[0m        \u001b[32m4.0395\u001b[0m  88.6388\n",
      "     13        \u001b[36m3.9533\u001b[0m        \u001b[32m4.0205\u001b[0m  87.9094\n",
      "     14        \u001b[36m3.9488\u001b[0m        \u001b[32m4.0064\u001b[0m  88.8862\n",
      "     15        \u001b[36m3.9448\u001b[0m        \u001b[32m3.9962\u001b[0m  86.7156\n",
      "     16        \u001b[36m3.9410\u001b[0m        \u001b[32m3.9883\u001b[0m  87.5012\n",
      "     17        \u001b[36m3.9371\u001b[0m        \u001b[32m3.9815\u001b[0m  85.9944\n",
      "     18        \u001b[36m3.9332\u001b[0m        \u001b[32m3.9758\u001b[0m  87.0308\n",
      "     19        \u001b[36m3.9291\u001b[0m        \u001b[32m3.9724\u001b[0m  85.7186\n",
      "     20        \u001b[36m3.9253\u001b[0m        \u001b[32m3.9689\u001b[0m  86.2991\n",
      "9 RMSE: 1.982967\n",
      "10\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2216\u001b[0m        \u001b[32m4.1896\u001b[0m  80.4563\n",
      "      2        \u001b[36m4.1272\u001b[0m        \u001b[32m4.0863\u001b[0m  80.9629\n",
      "      3        \u001b[36m4.0494\u001b[0m        4.1192  81.1771\n",
      "      4        \u001b[36m4.0193\u001b[0m        4.1135  79.5472\n",
      "      5        \u001b[36m4.0036\u001b[0m        4.1038  78.9090\n",
      "      6        \u001b[36m3.9926\u001b[0m        4.0940  79.0491\n",
      "      7        \u001b[36m3.9836\u001b[0m        \u001b[32m4.0805\u001b[0m  78.5961\n",
      "      8        \u001b[36m3.9756\u001b[0m        \u001b[32m4.0641\u001b[0m  82.8555\n",
      "      9        \u001b[36m3.9686\u001b[0m        \u001b[32m4.0436\u001b[0m  80.5513\n",
      "     10        \u001b[36m3.9613\u001b[0m        \u001b[32m4.0245\u001b[0m  81.1162\n",
      "     11        \u001b[36m3.9548\u001b[0m        \u001b[32m4.0076\u001b[0m  80.3093\n",
      "     12        \u001b[36m3.9484\u001b[0m        \u001b[32m3.9949\u001b[0m  80.1183\n",
      "     13        \u001b[36m3.9425\u001b[0m        \u001b[32m3.9827\u001b[0m  79.6862\n",
      "     14        \u001b[36m3.9368\u001b[0m        \u001b[32m3.9753\u001b[0m  78.4618\n",
      "     15        \u001b[36m3.9317\u001b[0m        \u001b[32m3.9695\u001b[0m  80.8161\n",
      "     16        \u001b[36m3.9267\u001b[0m        \u001b[32m3.9676\u001b[0m  80.5157\n",
      "     17        \u001b[36m3.9222\u001b[0m        \u001b[32m3.9653\u001b[0m  81.1869\n",
      "     18        \u001b[36m3.9177\u001b[0m        \u001b[32m3.9626\u001b[0m  81.0774\n",
      "     19        \u001b[36m3.9136\u001b[0m        \u001b[32m3.9583\u001b[0m  80.8559\n",
      "     20        \u001b[36m3.9091\u001b[0m        \u001b[32m3.9557\u001b[0m  81.7191\n",
      "10 RMSE: 1.9803934\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_unitslist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e774fbbd8c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[0mmin_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmselist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmselist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Optimum parameters:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_unitslist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmselist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'num_unitslist' is not defined"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "in_dimensionopt = 5844\n",
    "hid_dimensionopt = 160\n",
    "out_dimensionopt = 1\n",
    "rmselist = []\n",
    "layers = [1,2,3,4,5,6,7,8,9,10]\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "    \n",
    "\n",
    "        \n",
    "    if layer == 1:        \n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = torch.nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc2(hidden)\n",
    "                return output\n",
    "\n",
    "    elif layer == 2:        \n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = torch.nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc3(hidden)\n",
    "                return output\n",
    "\n",
    "    if layer == 3:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc4(hidden)\n",
    "                return output\n",
    "            \n",
    "    if layer == 4:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc5(hidden)\n",
    "                return output\n",
    "            \n",
    "    if layer == 5:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc6(hidden)\n",
    "                return output\n",
    "\n",
    "    if layer == 6:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc7(hidden)\n",
    "                return output\n",
    "\n",
    "    if layer == 7:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc8 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc7(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc8(hidden)\n",
    "                return output\n",
    "            \n",
    "    if layer == 8:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc8 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc9 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc7(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc8(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc9(hidden)\n",
    "                return output\n",
    "            \n",
    "    if layer == 9:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc8 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc9 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc10 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc7(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc8(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc9(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc10(hidden)\n",
    "                return output\n",
    "\n",
    "    if layer == 10:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc8 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc9 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc10 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc11 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc7(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc8(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc9(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc10(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc11(hidden)\n",
    "                return output\n",
    "\n",
    "    pole_model = PoleNN_opt()\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "    pipe.fit(X=x_train, y=y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(layer,'RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "    \n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", layers[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outdoor-earth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum Hidden Layer Number: 1 : 1.9774234\n"
     ]
    }
   ],
   "source": [
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum Hidden Layer Number:\", layers[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "owned-transcription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2296\u001b[0m        \u001b[32m4.2007\u001b[0m  93.5902\n",
      "      2        \u001b[36m4.1415\u001b[0m        \u001b[32m4.0978\u001b[0m  93.3645\n",
      "      3        \u001b[36m4.0622\u001b[0m        4.1321  94.5493\n",
      "      4        \u001b[36m4.0326\u001b[0m        \u001b[32m4.0858\u001b[0m  92.6812\n",
      "      5        \u001b[36m4.0188\u001b[0m        \u001b[32m4.0693\u001b[0m  93.0608\n",
      "      6        \u001b[36m4.0092\u001b[0m        \u001b[32m4.0663\u001b[0m  93.3155\n",
      "      7        \u001b[36m4.0012\u001b[0m        4.0689  89.0179\n",
      "      8        \u001b[36m3.9941\u001b[0m        4.0734  90.6882\n",
      "      9        \u001b[36m3.9875\u001b[0m        4.0772  90.9220\n",
      "     10        \u001b[36m3.9813\u001b[0m        4.0798  93.7151\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "15 RMSE: 2.009249\n",
      "20\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2220\u001b[0m        \u001b[32m4.1883\u001b[0m  93.5812\n",
      "      2        \u001b[36m4.1279\u001b[0m        \u001b[32m4.0987\u001b[0m  95.0947\n",
      "      3        \u001b[36m4.0555\u001b[0m        4.1247  93.2286\n",
      "      4        \u001b[36m4.0312\u001b[0m        \u001b[32m4.0835\u001b[0m  94.8130\n",
      "      5        \u001b[36m4.0196\u001b[0m        \u001b[32m4.0704\u001b[0m  94.2965\n",
      "      6        \u001b[36m4.0118\u001b[0m        \u001b[32m4.0671\u001b[0m  93.7421\n",
      "      7        \u001b[36m4.0060\u001b[0m        4.0681  92.8520\n",
      "      8        \u001b[36m4.0013\u001b[0m        4.0706  92.9069\n",
      "      9        \u001b[36m3.9974\u001b[0m        4.0740  93.1287\n",
      "     10        \u001b[36m3.9942\u001b[0m        4.0777  93.1137\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "20 RMSE: 2.0103073\n",
      "Optimum parameters: 15 : 2.009249\n"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "in_dimensionopt = 5844\n",
    "hid_dimensionopt = 160\n",
    "out_dimensionopt = 1\n",
    "rmselist = []\n",
    "layers = [15,20]\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "\n",
    "    if layer == 15:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc8 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc9 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc10 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc11 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc12 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc13 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc14 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc15 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc16 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc7(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc8(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc9(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc10(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc11(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc12(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc13(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc14(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc15(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc16(hidden)\n",
    "                return output\n",
    "            \n",
    "    if layer == 20:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc8 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc9 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc10 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc11 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc12 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc13 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc14 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc15 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc16 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc17 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc18 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc19 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc20 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc21 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc7(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc8(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc9(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc10(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc11(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc12(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc13(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc14(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc15(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc16(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc17(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc18(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc19(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc20(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc21(hidden)\n",
    "                return output\n",
    "            \n",
    "            \n",
    "    pole_model = PoleNN_opt()\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "    pipe.fit(X=x_train, y=y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(layer,'RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "    \n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", layers[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "virgin-riverside",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2232\u001b[0m        \u001b[32m4.1895\u001b[0m  83.8142\n",
      "      2        \u001b[36m4.1286\u001b[0m        \u001b[32m4.0994\u001b[0m  83.7203\n",
      "      3        \u001b[36m4.0557\u001b[0m        4.1237  84.8452\n",
      "      4        \u001b[36m4.0313\u001b[0m        \u001b[32m4.0814\u001b[0m  84.1469\n",
      "      5        \u001b[36m4.0197\u001b[0m        \u001b[32m4.0680\u001b[0m  83.3547\n",
      "      6        \u001b[36m4.0118\u001b[0m        \u001b[32m4.0648\u001b[0m  83.7603\n",
      "      7        \u001b[36m4.0057\u001b[0m        4.0653  84.1389\n",
      "      8        \u001b[36m4.0007\u001b[0m        4.0676  83.1449\n",
      "      9        \u001b[36m3.9963\u001b[0m        4.0698  84.4346\n",
      "     10        \u001b[36m3.9923\u001b[0m        4.0713  83.8952\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "12 RMSE: 2.0079663\n",
      "14\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [128 x 5844], m2: [11 x 1] at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-e5c8dddg\\aten\\src\\TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d36f2e878e8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mpipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tfidf_vector_com\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midentity_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"array\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msublinear_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'[^\\s]+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"typetransform\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtypetransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"net\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\regressor.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;31m# this is actually a pylint bug:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNeuralNetRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_train_begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_epoch_begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mon_epoch_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             self.run_single_epoch(dataset_train, training=True, prefix=\"train\",\n\u001b[0m\u001b[0;32m    776\u001b[0m                                   step_fn=self.train_step, **fit_params)\n\u001b[0;32m    777\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mrun_single_epoch\u001b[1;34m(self, dataset, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[0myi_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myi\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_placeholder_y\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_batch_begin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myi_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_batch_size\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_accumulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\torch\\optim\\sgd.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mstep_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step_single\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m             \u001b[0mstep_accumulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstore_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36mtrain_step_single\u001b[1;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \"\"\"\n\u001b[0;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\skorch\\net.py\u001b[0m in \u001b[0;36minfer\u001b[1;34m(self, x, **fit_params)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[0mx_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_x_and_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_predict_nonlinearity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d36f2e878e8e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc14\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                 \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc15\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Documents\\anaconda3\\envs\\DataSciEnv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [128 x 5844], m2: [11 x 1] at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-e5c8dddg\\aten\\src\\TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "in_dimensionopt = 5844\n",
    "hid_dimensionopt = 160\n",
    "out_dimensionopt = 1\n",
    "rmselist = []\n",
    "layers = [12,14]\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "\n",
    "    if layer == 12:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc8 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc9 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc10 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc11 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc12 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc13 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc7(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc8(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc9(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc10(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc11(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc12(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc13(hidden)\n",
    "                return output\n",
    "            \n",
    "    if layer == 14:\n",
    "        hid_dimensionoptnew = int((hid_dimensionopt/layer))\n",
    "        class PoleNN_opt(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(PoleNN_opt, self).__init__()\n",
    "                self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc2 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc3 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc4 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc5 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc6 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc7 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc8 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc9 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc10 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc11 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc12 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc13 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc14 = nn.Linear(in_dimensionopt,hid_dimensionoptnew)\n",
    "                self.fc15 = nn.Linear(hid_dimensionoptnew,out_dimensionopt)\n",
    "                self.ReLU = nn.ReLU()\n",
    "\n",
    "            def forward(self, X):\n",
    "                hidden = self.fc1(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc2(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc3(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc4(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc5(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc6(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc7(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc8(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc9(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc10(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc11(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc12(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc13(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc14(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                hidden = self.fc15(X)\n",
    "                hidden = self.ReLU(hidden)\n",
    "                output = self.fc16(hidden)\n",
    "                return output\n",
    "            \n",
    "            \n",
    "    pole_model = PoleNN_opt()\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True, token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "    pipe.fit(X=x_train, y=y_train)\n",
    "    y_pred = pipe.predict(x_test)\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "    print(layer,'RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "    \n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", layers[min_index],\":\",min(rmselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "duplicate-washer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  2.,  4.,  6.,  8., 10., 12.]),\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "fig_dims = (10, 6)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "sns.lineplot(x=layers,y=rmselist)\n",
    "ax.set(xlabel='Number of Hidden Layers',ylabel='RMSE',title='Number of Hidden Layers Modelled Against RMSE')\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-default",
   "metadata": {},
   "source": [
    "### Optimised MLP on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cognitive-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.0793\u001b[0m        \u001b[32m3.9687\u001b[0m  791.0166\n",
      "      2        \u001b[36m3.9358\u001b[0m        \u001b[32m3.9142\u001b[0m  808.8528\n",
      "      3        \u001b[36m3.8899\u001b[0m        \u001b[32m3.8847\u001b[0m  970.3454\n",
      "      4        \u001b[36m3.8598\u001b[0m        \u001b[32m3.8637\u001b[0m  811.5620\n",
      "      5        \u001b[36m3.8352\u001b[0m        \u001b[32m3.8486\u001b[0m  825.8654\n",
      "      6        \u001b[36m3.8128\u001b[0m        \u001b[32m3.8312\u001b[0m  855.9991\n",
      "      7        \u001b[36m3.7920\u001b[0m        \u001b[32m3.8207\u001b[0m  868.1499\n",
      "      8        \u001b[36m3.7720\u001b[0m        \u001b[32m3.8099\u001b[0m  894.6507\n",
      "      9        \u001b[36m3.7529\u001b[0m        \u001b[32m3.7960\u001b[0m  988.0558\n",
      "     10        \u001b[36m3.7344\u001b[0m        \u001b[32m3.7844\u001b[0m  844.6302\n",
      "     11        \u001b[36m3.7163\u001b[0m        \u001b[32m3.7762\u001b[0m  838.5144\n",
      "     12        \u001b[36m3.6988\u001b[0m        \u001b[32m3.7710\u001b[0m  847.2402\n",
      "     13        \u001b[36m3.6826\u001b[0m        \u001b[32m3.7691\u001b[0m  872.7549\n",
      "     14        \u001b[36m3.6665\u001b[0m        \u001b[32m3.7688\u001b[0m  870.9664\n",
      "     15        \u001b[36m3.6512\u001b[0m        \u001b[32m3.7613\u001b[0m  842.6142\n",
      "     16        \u001b[36m3.6364\u001b[0m        \u001b[32m3.7545\u001b[0m  847.6625\n",
      "     17        \u001b[36m3.6231\u001b[0m        3.7593  844.9485\n",
      "     18        \u001b[36m3.6102\u001b[0m        \u001b[32m3.7526\u001b[0m  890.9675\n",
      "     19        \u001b[36m3.5982\u001b[0m        \u001b[32m3.7497\u001b[0m  917.9245\n",
      "     20        \u001b[36m3.5873\u001b[0m        \u001b[32m3.7495\u001b[0m  891.6957\n",
      "RMSE: 1.933993\n"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "\n",
    "x_trainshape = 7703\n",
    "\n",
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=160,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 160)\n",
    "        self.output = nn.Linear(160, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X\n",
    "\n",
    "pole_model = RegressorModule()\n",
    "\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "def inputneuron(x):\n",
    "    x_trainshape = x.shape[1]\n",
    "#     return x_trainshape\n",
    "inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "# pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "# pipe = Pipeline([('net', net)])\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "# net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "pipe.fit(X=x_train, y=y_train)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "described-reynolds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout RMSE: 1.9135916\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_holdout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3fd90886387b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Holdout RMSE:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my_pred_holdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_holdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_holdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_holdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Holdout RMSE:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_holdout' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred_train = pipe.predict(x_train)\n",
    "rmse = mean_squared_error(y_train, y_pred_train, squared = False)\n",
    "print('Training RMSE:', rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instant-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_holdout.txt\", \"rb\") as fp:   # Unpickling\n",
    "    x_holdout = pickle.load(fp)\n",
    "with open(\"y_holdout.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_holdout = pickle.load(fp)\n",
    "with open(\"y_holdout_dates.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_holdout_dates = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "young-bennett",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout RMSE: 11.951104253908436\n"
     ]
    }
   ],
   "source": [
    "y_holdout = y_holdout['Change']\n",
    "\n",
    "y_pred_holdout = pipe.predict(x_holdout)\n",
    "rmse = mean_squared_error(y_holdout, y_pred_holdout, squared = False)\n",
    "print('Holdout RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "young-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_params(f_params='SameDayTestModelParams.pkl')\n",
    "\n",
    "# x_trainshape = 7703\n",
    "\n",
    "# class RegressorModule(nn.Module):\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             num_units=160,\n",
    "#             nonlin=F.relu,\n",
    "#     ):\n",
    "#         super(RegressorModule, self).__init__()\n",
    "#         self.num_units = num_units\n",
    "#         self.nonlin = nonlin\n",
    "\n",
    "#         self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "#         self.nonlin = nonlin\n",
    "#         self.dense1 = nn.Linear(num_units, 160)\n",
    "#         self.output = nn.Linear(160, 1)\n",
    "\n",
    "#     def forward(self, X, **kwargs):\n",
    "#         X = self.nonlin(self.dense0(X))\n",
    "#         X = F.relu(self.dense1(X))\n",
    "#         X = self.output(X)\n",
    "#         return X\n",
    "\n",
    "# pole_model = RegressorModule()\n",
    "\n",
    "# net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "# # new_net.initialize()  # This is important!\n",
    "# new_net.load_params(f_params='SameDayTestModelParams.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "closing-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5886867303446403\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, (real, pred) in enumerate(zip(y_test, y_pred)):\n",
    "    if real > 0 and pred > 0:\n",
    "        correct += 1\n",
    "    if real < 0 and pred < 0:\n",
    "        correct += 1\n",
    "print(correct/(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungry-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit: [34268.26]\n",
      "Accuracy: 0.6904761904761905\n",
      "Sum Invested: [16657.725]\n",
      "Profitability: [2.0571995]\n"
     ]
    }
   ],
   "source": [
    "modelpreds = y_pred\n",
    "y = y_test\n",
    "z = y_testdates\n",
    "unique = z.unique()\n",
    "profit = 0\n",
    "bullorbearcount = 0\n",
    "invested = 0\n",
    "for uni in unique:\n",
    "    predsum = 0\n",
    "    reala = 0\n",
    "    for i, (pred, real, date) in enumerate(zip(modelpreds, y, z)):\n",
    "        if date == uni:\n",
    "            predsum += pred\n",
    "            reala = real\n",
    "    invested += abs(predsum)\n",
    "    daychange = predsum * reala\n",
    "    profit += daychange\n",
    "    if predsum > 0 and reala > 0:\n",
    "        bullorbearcount += 1\n",
    "    elif predsum < 0 and reala < 0:\n",
    "        bullorbearcount += 1\n",
    "print(\"Profit:\", profit)\n",
    "print(\"Accuracy:\", (bullorbearcount/len(unique)))\n",
    "print(\"Sum Invested:\", invested)\n",
    "print(\"Profitability:\", (profit/invested))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlike-benefit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "heard-night",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33723.45]\n"
     ]
    }
   ],
   "source": [
    "profit = 0           \n",
    "for i, (real, pred) in enumerate(zip(y_test, y_pred)):\n",
    "    realmean = y_test.mean()\n",
    "    predmean = y_pred.mean()\n",
    "    realchange = real - realmean\n",
    "    predchange = pred - predmean\n",
    "    change = (predchange * realchange)\n",
    "    change = pred - real\n",
    "    profit += change\n",
    "print(profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nuclear-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang\n",
      "en     1962786.0\n",
      "ja      346167.0\n",
      "ko      216566.0\n",
      "es      162353.0\n",
      "fr      136451.0\n",
      "und     132419.0\n",
      "it       84533.0\n",
      "th       78724.0\n",
      "de       67168.0\n",
      "pt       36000.0\n",
      "ar       32496.0\n",
      "tr       25692.0\n",
      "ru       15342.0\n",
      "nl       14748.0\n",
      "in       13811.0\n",
      "pl        9169.0\n",
      "hi        5970.0\n",
      "zh        4806.0\n",
      "ca        4133.0\n",
      "et        4072.0\n",
      "cs        3000.0\n",
      "da        2987.0\n",
      "el        2919.0\n",
      "ta        2575.0\n",
      "tl        2395.0\n",
      "ht        1745.0\n",
      "ro        1715.0\n",
      "uk        1620.0\n",
      "sv        1419.0\n",
      "ur        1339.0\n",
      "lt        1292.0\n",
      "fa        1282.0\n",
      "vi        1197.0\n",
      "fi        1189.0\n",
      "mr        1025.0\n",
      "ml         877.0\n",
      "hu         711.0\n",
      "no         644.0\n",
      "te         560.0\n",
      "gu         544.0\n",
      "eu         462.0\n",
      "cy         459.0\n",
      "bg         404.0\n",
      "kn         338.0\n",
      "sl         312.0\n",
      "bn         259.0\n",
      "pa         257.0\n",
      "iw         229.0\n",
      "lv         178.0\n",
      "ne         134.0\n",
      "is         103.0\n",
      "sr          91.0\n",
      "si          80.0\n",
      "or          38.0\n",
      "ka          30.0\n",
      "ps          13.0\n",
      "hy          11.0\n",
      "am          10.0\n",
      "my          10.0\n",
      "ckb          9.0\n",
      "lo           4.0\n",
      "sd           2.0\n",
      "ug           1.0\n",
      "km           1.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "merged2 = merged\n",
    "merged2['count'] = 1\n",
    "mergedlangcheck = merged2.groupby(['lang']).sum()\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(mergedlangcheck['count'].sort_values(ascending = False))\n",
    "pd.reset_option('^display.', silent=True)\n",
    "# print(mergedlangcheck.index())\n",
    "# rmselist2 = rmselist2[:-3]\n",
    "# # rmselist2 = rmselist\n",
    "# # rmselist2.append('NaN')\n",
    "# # rmselist2.append('NaN')\n",
    "# # rmselist2.append('NaN')\n",
    "# mergedlangcheck['rmse'] = rmselist2\n",
    "# print(mergedlangcheck[['count','rmse']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "attempted-gamma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "3201\n",
      "  epoch    train_loss    valid_loss       dur\n",
      "-------  ------------  ------------  --------\n",
      "      1        \u001b[36m4.2459\u001b[0m        \u001b[32m4.2262\u001b[0m  323.5521\n",
      "      2        \u001b[36m4.2220\u001b[0m        \u001b[32m4.2053\u001b[0m  333.1847\n",
      "      3        \u001b[36m4.1991\u001b[0m        \u001b[32m4.1813\u001b[0m  329.2757\n",
      "      4        \u001b[36m4.1725\u001b[0m        \u001b[32m4.1584\u001b[0m  330.7571\n",
      "      5        \u001b[36m4.1488\u001b[0m        \u001b[32m4.1398\u001b[0m  335.4003\n",
      "      6        \u001b[36m4.1296\u001b[0m        \u001b[32m4.1245\u001b[0m  330.0791\n",
      "      7        \u001b[36m4.1140\u001b[0m        \u001b[32m4.1091\u001b[0m  328.7126\n",
      "      8        \u001b[36m4.1015\u001b[0m        \u001b[32m4.0999\u001b[0m  328.7945\n",
      "      9        \u001b[36m4.0909\u001b[0m        \u001b[32m4.0948\u001b[0m  352.6424\n",
      "     10        \u001b[36m4.0818\u001b[0m        \u001b[32m4.0845\u001b[0m  350.1431\n",
      "     11        \u001b[36m4.0740\u001b[0m        \u001b[32m4.0771\u001b[0m  354.6817\n",
      "     12        \u001b[36m4.0667\u001b[0m        \u001b[32m4.0695\u001b[0m  359.2493\n",
      "     13        \u001b[36m4.0600\u001b[0m        \u001b[32m4.0627\u001b[0m  353.0213\n",
      "     14        \u001b[36m4.0548\u001b[0m        \u001b[32m4.0589\u001b[0m  332.4482\n",
      "     15        \u001b[36m4.0497\u001b[0m        \u001b[32m4.0535\u001b[0m  333.5141\n",
      "     16        \u001b[36m4.0448\u001b[0m        \u001b[32m4.0456\u001b[0m  333.3234\n",
      "     17        \u001b[36m4.0407\u001b[0m        \u001b[32m4.0440\u001b[0m  334.2274\n",
      "     18        \u001b[36m4.0363\u001b[0m        \u001b[32m4.0409\u001b[0m  333.3508\n",
      "     19        \u001b[36m4.0324\u001b[0m        \u001b[32m4.0392\u001b[0m  333.5985\n",
      "     20        \u001b[36m4.0292\u001b[0m        \u001b[32m4.0343\u001b[0m  333.1130\n",
      "Training RMSE: 2.0068266\n",
      "Test RMSE: 2.0127087\n",
      "Holdout RMSE: 11.959303879857647\n",
      "ja\n",
      "4014\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.3508\u001b[0m        \u001b[32m4.2193\u001b[0m  51.7260\n",
      "      2        \u001b[36m4.2090\u001b[0m        \u001b[32m4.1394\u001b[0m  53.7050\n",
      "      3        \u001b[36m4.1565\u001b[0m        \u001b[32m4.1103\u001b[0m  53.6471\n",
      "      4        \u001b[36m4.1274\u001b[0m        \u001b[32m4.0917\u001b[0m  54.3733\n",
      "      5        \u001b[36m4.1045\u001b[0m        \u001b[32m4.0782\u001b[0m  54.7050\n",
      "      6        \u001b[36m4.0830\u001b[0m        \u001b[32m4.0655\u001b[0m  55.0167\n",
      "      7        \u001b[36m4.0612\u001b[0m        \u001b[32m4.0514\u001b[0m  55.6670\n",
      "      8        \u001b[36m4.0388\u001b[0m        \u001b[32m4.0372\u001b[0m  55.9817\n",
      "      9        \u001b[36m4.0154\u001b[0m        \u001b[32m4.0222\u001b[0m  56.1945\n",
      "     10        \u001b[36m3.9906\u001b[0m        \u001b[32m4.0068\u001b[0m  55.2275\n",
      "     11        \u001b[36m3.9638\u001b[0m        \u001b[32m3.9957\u001b[0m  55.4742\n",
      "     12        \u001b[36m3.9348\u001b[0m        \u001b[32m3.9865\u001b[0m  55.5002\n",
      "     13        \u001b[36m3.9036\u001b[0m        \u001b[32m3.9802\u001b[0m  55.6920\n",
      "     14        \u001b[36m3.8697\u001b[0m        \u001b[32m3.9780\u001b[0m  55.5007\n",
      "     15        \u001b[36m3.8332\u001b[0m        \u001b[32m3.9650\u001b[0m  55.6440\n",
      "     16        \u001b[36m3.7935\u001b[0m        \u001b[32m3.9450\u001b[0m  55.6890\n",
      "     17        \u001b[36m3.7510\u001b[0m        \u001b[32m3.9195\u001b[0m  55.2215\n",
      "     18        \u001b[36m3.7057\u001b[0m        \u001b[32m3.8873\u001b[0m  55.5531\n",
      "     19        \u001b[36m3.6569\u001b[0m        \u001b[32m3.8596\u001b[0m  55.7899\n",
      "     20        \u001b[36m3.6071\u001b[0m        \u001b[32m3.8351\u001b[0m  55.5411\n",
      "Training RMSE: 1.9255003\n",
      "Test RMSE: 1.9689416\n",
      "Holdout RMSE: 12.032523456007691\n",
      "ko\n",
      "1312\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m1.9006\u001b[0m        \u001b[32m0.9115\u001b[0m  26.9464\n",
      "      2        \u001b[36m0.8957\u001b[0m        \u001b[32m0.8425\u001b[0m  27.7576\n",
      "      3        \u001b[36m0.8612\u001b[0m        \u001b[32m0.8248\u001b[0m  28.2531\n",
      "      4        \u001b[36m0.8480\u001b[0m        \u001b[32m0.8152\u001b[0m  28.3809\n",
      "      5        \u001b[36m0.8402\u001b[0m        \u001b[32m0.8091\u001b[0m  27.3880\n",
      "      6        \u001b[36m0.8348\u001b[0m        \u001b[32m0.8046\u001b[0m  27.7296\n",
      "      7        \u001b[36m0.8309\u001b[0m        \u001b[32m0.8012\u001b[0m  27.7406\n",
      "      8        \u001b[36m0.8277\u001b[0m        \u001b[32m0.7986\u001b[0m  27.1462\n",
      "      9        \u001b[36m0.8252\u001b[0m        \u001b[32m0.7965\u001b[0m  27.8357\n",
      "     10        \u001b[36m0.8231\u001b[0m        \u001b[32m0.7948\u001b[0m  27.6697\n",
      "     11        \u001b[36m0.8214\u001b[0m        \u001b[32m0.7932\u001b[0m  28.0763\n",
      "     12        \u001b[36m0.8198\u001b[0m        \u001b[32m0.7922\u001b[0m  27.5656\n",
      "     13        \u001b[36m0.8185\u001b[0m        \u001b[32m0.7909\u001b[0m  27.9854\n",
      "     14        \u001b[36m0.8172\u001b[0m        \u001b[32m0.7899\u001b[0m  27.8625\n",
      "     15        \u001b[36m0.8161\u001b[0m        \u001b[32m0.7891\u001b[0m  28.1183\n",
      "     16        \u001b[36m0.8151\u001b[0m        \u001b[32m0.7882\u001b[0m  27.7696\n",
      "     17        \u001b[36m0.8141\u001b[0m        \u001b[32m0.7874\u001b[0m  27.8025\n",
      "     18        \u001b[36m0.8133\u001b[0m        \u001b[32m0.7866\u001b[0m  27.8595\n",
      "     19        \u001b[36m0.8125\u001b[0m        \u001b[32m0.7860\u001b[0m  27.4579\n",
      "     20        \u001b[36m0.8118\u001b[0m        \u001b[32m0.7853\u001b[0m  27.6637\n",
      "Training RMSE: 0.8956164\n",
      "Test RMSE: 0.8988355\n",
      "Holdout RMSE: 12.129489799401714\n",
      "es\n",
      "918\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.2928\u001b[0m        \u001b[32m4.2746\u001b[0m  19.9296\n",
      "      2        \u001b[36m4.2455\u001b[0m        \u001b[32m4.2192\u001b[0m  20.1724\n",
      "      3        \u001b[36m4.2230\u001b[0m        \u001b[32m4.2077\u001b[0m  20.1124\n",
      "      4        \u001b[36m4.2161\u001b[0m        \u001b[32m4.2024\u001b[0m  20.1354\n",
      "      5        \u001b[36m4.2111\u001b[0m        \u001b[32m4.1979\u001b[0m  19.8187\n",
      "      6        \u001b[36m4.2069\u001b[0m        \u001b[32m4.1938\u001b[0m  20.2802\n",
      "      7        \u001b[36m4.2030\u001b[0m        \u001b[32m4.1903\u001b[0m  19.9226\n",
      "      8        \u001b[36m4.1993\u001b[0m        \u001b[32m4.1867\u001b[0m  20.0375\n",
      "      9        \u001b[36m4.1955\u001b[0m        \u001b[32m4.1833\u001b[0m  20.7078\n",
      "     10        \u001b[36m4.1916\u001b[0m        \u001b[32m4.1798\u001b[0m  20.2203\n",
      "     11        \u001b[36m4.1875\u001b[0m        \u001b[32m4.1756\u001b[0m  20.1484\n",
      "     12        \u001b[36m4.1829\u001b[0m        \u001b[32m4.1714\u001b[0m  20.8407\n",
      "     13        \u001b[36m4.1783\u001b[0m        \u001b[32m4.1667\u001b[0m  20.4071\n",
      "     14        \u001b[36m4.1735\u001b[0m        \u001b[32m4.1620\u001b[0m  20.0125\n",
      "     15        \u001b[36m4.1683\u001b[0m        \u001b[32m4.1573\u001b[0m  20.1684\n",
      "     16        \u001b[36m4.1634\u001b[0m        \u001b[32m4.1531\u001b[0m  20.8197\n",
      "     17        \u001b[36m4.1581\u001b[0m        \u001b[32m4.1480\u001b[0m  20.8557\n",
      "     18        \u001b[36m4.1526\u001b[0m        \u001b[32m4.1434\u001b[0m  20.4546\n",
      "     19        \u001b[36m4.1472\u001b[0m        \u001b[32m4.1399\u001b[0m  20.8587\n",
      "     20        \u001b[36m4.1420\u001b[0m        \u001b[32m4.1352\u001b[0m  20.4780\n",
      "Training RMSE: 2.0348566\n",
      "Test RMSE: 2.0287142\n",
      "Holdout RMSE: 11.94179048015957\n",
      "fr\n",
      "524\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m4.0145\u001b[0m        \u001b[32m4.0033\u001b[0m  16.2044\n",
      "      2        \u001b[36m3.9744\u001b[0m        \u001b[32m3.9514\u001b[0m  15.7998\n",
      "      3        \u001b[36m3.9264\u001b[0m        \u001b[32m3.9040\u001b[0m  15.7729\n",
      "      4        \u001b[36m3.8913\u001b[0m        \u001b[32m3.8754\u001b[0m  15.9812\n",
      "      5        \u001b[36m3.8677\u001b[0m        \u001b[32m3.8551\u001b[0m  16.3752\n",
      "      6        \u001b[36m3.8474\u001b[0m        \u001b[32m3.8344\u001b[0m  15.7689\n",
      "      7        \u001b[36m3.8296\u001b[0m        \u001b[32m3.8185\u001b[0m  15.9297\n",
      "      8        \u001b[36m3.8150\u001b[0m        \u001b[32m3.8060\u001b[0m  16.3603\n",
      "      9        \u001b[36m3.8016\u001b[0m        \u001b[32m3.7942\u001b[0m  16.4961\n",
      "     10        \u001b[36m3.7886\u001b[0m        \u001b[32m3.7823\u001b[0m  16.0496\n",
      "     11        \u001b[36m3.7761\u001b[0m        \u001b[32m3.7712\u001b[0m  16.1395\n",
      "     12        \u001b[36m3.7644\u001b[0m        \u001b[32m3.7618\u001b[0m  16.1395\n",
      "     13        \u001b[36m3.7530\u001b[0m        \u001b[32m3.7521\u001b[0m  16.5361\n",
      "     14        \u001b[36m3.7422\u001b[0m        \u001b[32m3.7444\u001b[0m  15.9647\n",
      "     15        \u001b[36m3.7320\u001b[0m        \u001b[32m3.7353\u001b[0m  16.1475\n",
      "     16        \u001b[36m3.7220\u001b[0m        \u001b[32m3.7271\u001b[0m  16.2694\n",
      "     17        \u001b[36m3.7123\u001b[0m        \u001b[32m3.7192\u001b[0m  16.5770\n",
      "     18        \u001b[36m3.7029\u001b[0m        \u001b[32m3.7115\u001b[0m  16.1555\n",
      "     19        \u001b[36m3.6940\u001b[0m        \u001b[32m3.7033\u001b[0m  16.1734\n",
      "     20        \u001b[36m3.6852\u001b[0m        \u001b[32m3.6948\u001b[0m  16.0716\n",
      "Training RMSE: 1.9203074\n",
      "Test RMSE: 1.9429172\n",
      "Holdout RMSE: 11.92402116404062\n",
      "Optimum parameters: ko : 0.8988355\n",
      "Time Elapsed: 10019.991878032684\n"
     ]
    }
   ],
   "source": [
    "langlist = merged['lang'].unique()\n",
    "# New langlist of languages with more than 100,000 tweets, equivalent to 3.33% of total tweet number\n",
    "# 'und','it','th','de','pt','ar','tr','ru','nl','in','pl'\n",
    "langlist = ['en','ja','ko','es','fr']\n",
    "rmselist = []\n",
    "y_holdout = y_holdout['Change']\n",
    "\n",
    "start = time.time()\n",
    "for lang in langlist:\n",
    "    \n",
    "    print(lang)\n",
    "    y = merged['Change'].loc[merged['lang'] == lang]\n",
    "    index = merged.index[merged['lang'] == lang].tolist()\n",
    "    X = pd.DataFrame(processed_tweets)\n",
    "    X['lang'] = merged['lang']\n",
    "    X = X[0].loc[merged['lang'] == lang]\n",
    "    X = X.to_list()\n",
    "    from sklearn.model_selection import train_test_split  \n",
    "    try:\n",
    "        x_train2, x_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    except ValueError:\n",
    "        print(\"Received a value error at train-test split, will pass\")\n",
    "        pass\n",
    "\n",
    "    y_train2 = y_train2.values.reshape(-1,1)\n",
    "    y_test2 = y_test2.values.reshape(-1,1)\n",
    "    y_train2 = y_train2.astype(np.float32)\n",
    "    y_test2 = y_test2.astype(np.float32)\n",
    "    \n",
    "    tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')\n",
    "    x_train3 = tfidf.fit_transform(x_train2)\n",
    "    x_test3 = tfidf.fit_transform(x_test2)\n",
    "    x_trainshape = x_train3.shape[1]\n",
    "\n",
    "    optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "    in_dimensionopt = x_trainshape\n",
    "    hid_dimensionopt = 160\n",
    "    out_dimensionopt = 1\n",
    "    print(in_dimensionopt)\n",
    "    class PoleNN_opt(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(PoleNN_opt, self).__init__()\n",
    "            self.fc1 = nn.Linear(in_dimensionopt,hid_dimensionopt)\n",
    "            self.fc2 = nn.Linear(hid_dimensionopt,out_dimensionopt)\n",
    "            self.ReLU = torch.nn.ReLU()\n",
    "\n",
    "        def forward(self, X):\n",
    "            hidden = self.fc1(X)\n",
    "            hidden = self.ReLU(hidden)\n",
    "            output = self.fc2(hidden)\n",
    "            return output\n",
    "\n",
    "    pole_model = PoleNN_opt()\n",
    "\n",
    "    net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "    def typechange(x):\n",
    "        return x.astype(dtype = np.float32)\n",
    "    typetransform = FunctionTransformer(typechange)\n",
    "    # pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "    # pipe = Pipeline([('net', net)])\n",
    "#     pipe = Pipeline([(\"typetransform\", typetransform), (\"net\", net)])\n",
    "    pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "    try:\n",
    "        pipe.fit(X=x_train2, y=y_train2)\n",
    "    except ValueError:\n",
    "        print(\"Received a value error at model fitting, will pass\")\n",
    "        pass\n",
    "    \n",
    "    y_pred_train = pipe.predict(x_train2)\n",
    "    rmse = mean_squared_error(y_train2, y_pred_train, squared = False)\n",
    "    print('Training RMSE:', rmse)\n",
    "\n",
    "    y_pred = pipe.predict(x_test2)\n",
    "    rmse = mean_squared_error(y_test2, y_pred, squared = False)\n",
    "    print('Test RMSE:', rmse)\n",
    "    rmselist.append(rmse)\n",
    "    \n",
    "    y_pred_holdout = pipe.predict(x_holdout)\n",
    "    rmse = mean_squared_error(y_holdout, y_pred_holdout, squared = False)\n",
    "    print('Holdout RMSE:', rmse)\n",
    "\n",
    "min_index = rmselist.index((min(rmselist)))\n",
    "print(\"Optimum parameters:\", langlist[min_index],\":\",min(rmselist))\n",
    "end = time.time()\n",
    "print(\"Time Elapsed:\", (end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-temperature",
   "metadata": {},
   "source": [
    "### Holdout Test for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "altered-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('mergedfullholdout.csv')\n",
    "merged = merged.dropna(subset=['Change1','Change2','Change3','Change4','Change5'])\n",
    "# Obtaining the tweet contents into a list\n",
    "all_tweets = merged[\"text\"]\n",
    "all_tweets = all_tweets.to_list()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemming(tweet):\n",
    "    a = word_tokenize(tweet)\n",
    "    answer = list(map(lambda x: lemmatizer.lemmatize(x), a))\n",
    "    return answer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "# https://python.gotrained.com/scraping-tweets-sentiment-analysis/\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed_tweets = []\n",
    "X = all_tweets\n",
    "for tweet in range(0, len(X)):  \n",
    "    \n",
    "    processed_tweet = re.sub(r\"http\\S+\", \"\", str(X[tweet]))\n",
    "    # Remove all the special characters\n",
    "    processed_tweet = re.sub(r'\\W', ' ', processed_tweet)\n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    # Remove single characters from the start\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "    processed_tweet = re.sub(r'of|to|has|keep|ll', '', processed_tweet)\n",
    "    # Converting to Lowercase\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "    processed_tweet = lemming(processed_tweet)\n",
    "    processed_tweet = [word for word in processed_tweet if word not in stop_words]\n",
    "    processed_tweet = TreebankWordDetokenizer().detokenize(processed_tweet)    \n",
    "    \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    processed_tweets.append(processed_tweet)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "killing-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged[['Change','Change1','Change2','Change3','Change4','Change5','usedate','usedate1','usedate2','usedate3','usedate4','usedate5']]\n",
    "X = processed_tweets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_trainholdout, x_testholdout, y_trainholdout, y_testholdout = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "y_traindatesholdout = y_trainholdout['usedate1']\n",
    "y_testdatesholdout = y_testholdout['usedate1']\n",
    "y_trainholdout = y_trainholdout['Change1']\n",
    "y_testholdout = y_testholdout['Change1']\n",
    "y_trainholdout = y_trainholdout.values.reshape(-1,1)\n",
    "y_testholdout = y_testholdout.values.reshape(-1,1)\n",
    "y_trainholdout = y_trainholdout.astype(np.float32)\n",
    "y_testholdout = y_testholdout.astype(np.float32)\n",
    "\n",
    "with open(\"x_trainholdout.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(x_trainholdout, fp)\n",
    "with open(\"y_trainholdout.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_trainholdout, fp)\n",
    "with open(\"x_testholdout.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(x_testholdout, fp)\n",
    "with open(\"y_testholdout.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_testholdout, fp)\n",
    "with open(\"y_traindatesholdout.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_traindatesholdout, fp)\n",
    "with open(\"y_testdatesholdout.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(y_testdatesholdout, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "packed-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"x_trainholdout.txt\", \"rb\") as fp:   # Unpickling\n",
    "    x_trainholdout = pickle.load(fp)\n",
    "with open(\"y_trainholdout.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_trainholdout = pickle.load(fp)\n",
    "with open(\"x_testholdout.txt\", \"rb\") as fp:   # Unpickling\n",
    "    x_testholdout = pickle.load(fp)\n",
    "with open(\"y_testholdout.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_testholdout = pickle.load(fp)\n",
    "with open(\"y_traindatesholdout.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_traindatesholdout = pickle.load(fp)\n",
    "with open(\"y_testdatesholdout.txt\", \"rb\") as fp:   # Unpickling\n",
    "    y_testdatesholdout = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "limited-stanford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m1.6618\u001b[0m        \u001b[32m1.6611\u001b[0m  64.1137\n",
      "      2        \u001b[36m1.6597\u001b[0m        \u001b[32m1.6607\u001b[0m  67.4916\n",
      "      3        \u001b[36m1.6591\u001b[0m        \u001b[32m1.6599\u001b[0m  66.9404\n",
      "      4        \u001b[36m1.6578\u001b[0m        \u001b[32m1.6583\u001b[0m  67.6903\n",
      "      5        \u001b[36m1.6557\u001b[0m        \u001b[32m1.6561\u001b[0m  66.9580\n",
      "      6        \u001b[36m1.6529\u001b[0m        \u001b[32m1.6539\u001b[0m  67.7187\n",
      "      7        \u001b[36m1.6501\u001b[0m        \u001b[32m1.6513\u001b[0m  67.1417\n",
      "      8        \u001b[36m1.6472\u001b[0m        \u001b[32m1.6477\u001b[0m  67.8199\n",
      "      9        \u001b[36m1.6437\u001b[0m        \u001b[32m1.6436\u001b[0m  65.9516\n",
      "     10        \u001b[36m1.6398\u001b[0m        \u001b[32m1.6393\u001b[0m  65.9873\n",
      "     11        \u001b[36m1.6357\u001b[0m        \u001b[32m1.6352\u001b[0m  67.7189\n",
      "     12        \u001b[36m1.6315\u001b[0m        \u001b[32m1.6312\u001b[0m  68.5210\n",
      "     13        \u001b[36m1.6271\u001b[0m        \u001b[32m1.6271\u001b[0m  68.8802\n",
      "     14        \u001b[36m1.6223\u001b[0m        \u001b[32m1.6240\u001b[0m  68.6248\n",
      "     15        \u001b[36m1.6175\u001b[0m        \u001b[32m1.6215\u001b[0m  67.4819\n",
      "     16        \u001b[36m1.6125\u001b[0m        \u001b[32m1.6195\u001b[0m  66.8349\n",
      "     17        \u001b[36m1.6074\u001b[0m        \u001b[32m1.6174\u001b[0m  67.0323\n",
      "     18        \u001b[36m1.6022\u001b[0m        \u001b[32m1.6157\u001b[0m  68.2225\n",
      "     19        \u001b[36m1.5973\u001b[0m        \u001b[32m1.6126\u001b[0m  67.9543\n",
      "     20        \u001b[36m1.5922\u001b[0m        \u001b[32m1.6093\u001b[0m  70.3587\n",
      "RMSE: 1.2692634\n"
     ]
    }
   ],
   "source": [
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')\n",
    "x_trainholdout2 = tfidf.fit_transform(x_trainholdout)\n",
    "x_testholdout2 = tfidf.fit_transform(x_testholdout)\n",
    "x_trainshape = x_trainholdout2.shape[1]\n",
    "\n",
    "\n",
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=160,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 160)\n",
    "        self.output = nn.Linear(160, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X\n",
    "\n",
    "pole_model = RegressorModule()\n",
    "\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "pipe.fit(X=x_trainholdout, y=y_trainholdout)\n",
    "y_predholdout = pipe.predict(x_testholdout)\n",
    "rmse = mean_squared_error(y_testholdout, y_predholdout, squared = False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataSciEnv]",
   "language": "python",
   "name": "conda-env-DataSciEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
