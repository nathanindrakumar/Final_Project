{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reported-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime, date, timedelta\n",
    "import torch\n",
    "import skorch\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from skorch.helper import DataFrameTransformer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skorch import NeuralNetRegressor\n",
    "import pickle\n",
    "import emoji\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "maritime-delhi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>Date</th>\n",
       "      <th>time</th>\n",
       "      <th>usedate</th>\n",
       "      <th>usedate1</th>\n",
       "      <th>usedate2</th>\n",
       "      <th>usedate3</th>\n",
       "      <th>...</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Change</th>\n",
       "      <th>Change1</th>\n",
       "      <th>Change2</th>\n",
       "      <th>Change3</th>\n",
       "      <th>Change4</th>\n",
       "      <th>Change5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1147845</th>\n",
       "      <td>2020 is almost ended\\n\\nBRAND NEW SEALED FACTO...</td>\n",
       "      <td>1.317031e+18</td>\n",
       "      <td>1317047077411737601</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>10:17:47</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>...</td>\n",
       "      <td>115393800.0</td>\n",
       "      <td>121.2800</td>\n",
       "      <td>121.5480</td>\n",
       "      <td>118.810</td>\n",
       "      <td>-2.260</td>\n",
       "      <td>-3.980</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.7000</td>\n",
       "      <td>-1.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318305</th>\n",
       "      <td>If you feel like Apple has no love for you by ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1361013406829060106</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>18:04:17</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>...</td>\n",
       "      <td>80576320.0</td>\n",
       "      <td>135.4900</td>\n",
       "      <td>136.0100</td>\n",
       "      <td>132.790</td>\n",
       "      <td>-2.300</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-2.0100</td>\n",
       "      <td>2.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772897</th>\n",
       "      <td>üì¢NEW RIP IS LIVEüì¢\\n\\n2W1B 051 - iPhone, Capita...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1318150624626790402</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>11:22:53</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>...</td>\n",
       "      <td>120639300.0</td>\n",
       "      <td>119.9600</td>\n",
       "      <td>120.4190</td>\n",
       "      <td>115.660</td>\n",
       "      <td>-3.980</td>\n",
       "      <td>1.310</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-1.3500</td>\n",
       "      <td>1.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952614</th>\n",
       "      <td>#Apple has introduced a new #macOS version of ...</td>\n",
       "      <td>1.272588e+18</td>\n",
       "      <td>1272595399673630722</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>18:22:41</td>\n",
       "      <td>2020-06-15</td>\n",
       "      <td>2020-06-16</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>...</td>\n",
       "      <td>138808920.0</td>\n",
       "      <td>83.3125</td>\n",
       "      <td>86.4200</td>\n",
       "      <td>83.145</td>\n",
       "      <td>2.435</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.2287</td>\n",
       "      <td>1.8825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33341</th>\n",
       "      <td>Good Dealüòç #MacBookPro #AppleEvent #Apple\\n\\nN...</td>\n",
       "      <td>1.389114e+18</td>\n",
       "      <td>1389114470304305154</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>07:07:52</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>2021-05-04</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>...</td>\n",
       "      <td>75135100.0</td>\n",
       "      <td>132.0400</td>\n",
       "      <td>134.0700</td>\n",
       "      <td>131.830</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-3.340</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-0.6400</td>\n",
       "      <td>-2.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169957</th>\n",
       "      <td>Foreign Exchange History: How it All Started?\\...</td>\n",
       "      <td>1.316240e+18</td>\n",
       "      <td>1316312507431051264</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>09:38:52</td>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>...</td>\n",
       "      <td>151062300.0</td>\n",
       "      <td>121.0000</td>\n",
       "      <td>123.0300</td>\n",
       "      <td>119.620</td>\n",
       "      <td>0.190</td>\n",
       "      <td>1.990</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-3.98</td>\n",
       "      <td>1.3100</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531839</th>\n",
       "      <td>Tropicana Apple Juice, 10 oz., 24 Count\\n\\nSta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1339593079318200320</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>15:27:33</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>2020-12-18</td>\n",
       "      <td>2020-12-21</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>...</td>\n",
       "      <td>94359810.0</td>\n",
       "      <td>128.9000</td>\n",
       "      <td>129.5800</td>\n",
       "      <td>128.045</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-2.305</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-1.2000</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305376</th>\n",
       "      <td>\"emotional conclusion to a dazzling series!\"\\n...</td>\n",
       "      <td>1.303296e+18</td>\n",
       "      <td>1307074421098766336</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>21:50:00</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>...</td>\n",
       "      <td>287104900.0</td>\n",
       "      <td>110.4000</td>\n",
       "      <td>110.8800</td>\n",
       "      <td>106.090</td>\n",
       "      <td>-3.560</td>\n",
       "      <td>5.540</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>3.0500</td>\n",
       "      <td>3.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266310</th>\n",
       "      <td>3ÔºÖË∂Ö‰∏äÊòá„Åó„ÅüÈäòÊüÑ\\n4434  „Çµ„Éº„Éê„Éº„ÉØ„Éº„ÇØ„Çπ\\n4625  „Ç¢„Éà„Éü„ÇØ„Çπ\\n6777  ...</td>\n",
       "      <td>1.311853e+18</td>\n",
       "      <td>1311853293589725184</td>\n",
       "      <td>ja</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>02:19:32</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>...</td>\n",
       "      <td>144712000.0</td>\n",
       "      <td>112.8900</td>\n",
       "      <td>115.3700</td>\n",
       "      <td>112.220</td>\n",
       "      <td>0.130</td>\n",
       "      <td>2.590</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-1.2800</td>\n",
       "      <td>1.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634525</th>\n",
       "      <td>EP 42: @seanmagers and @keithrconrad discuss t...</td>\n",
       "      <td>1.346227e+18</td>\n",
       "      <td>1346226671293243393</td>\n",
       "      <td>en</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>22:47:04</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>...</td>\n",
       "      <td>143301900.0</td>\n",
       "      <td>133.5200</td>\n",
       "      <td>133.6116</td>\n",
       "      <td>126.760</td>\n",
       "      <td>-4.110</td>\n",
       "      <td>2.120</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>2.56</td>\n",
       "      <td>-0.3800</td>\n",
       "      <td>-0.2100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501281 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  referenced_tweets  \\\n",
       "1147845  2020 is almost ended\\n\\nBRAND NEW SEALED FACTO...       1.317031e+18   \n",
       "2318305  If you feel like Apple has no love for you by ...                NaN   \n",
       "2772897  üì¢NEW RIP IS LIVEüì¢\\n\\n2W1B 051 - iPhone, Capita...                NaN   \n",
       "1952614  #Apple has introduced a new #macOS version of ...       1.272588e+18   \n",
       "33341    Good Dealüòç #MacBookPro #AppleEvent #Apple\\n\\nN...       1.389114e+18   \n",
       "...                                                    ...                ...   \n",
       "1169957  Foreign Exchange History: How it All Started?\\...       1.316240e+18   \n",
       "2531839  Tropicana Apple Juice, 10 oz., 24 Count\\n\\nSta...                NaN   \n",
       "1305376  \"emotional conclusion to a dazzling series!\"\\n...       1.303296e+18   \n",
       "1266310  3ÔºÖË∂Ö‰∏äÊòá„Åó„ÅüÈäòÊüÑ\\n4434  „Çµ„Éº„Éê„Éº„ÉØ„Éº„ÇØ„Çπ\\n4625  „Ç¢„Éà„Éü„ÇØ„Çπ\\n6777  ...       1.311853e+18   \n",
       "634525   EP 42: @seanmagers and @keithrconrad discuss t...       1.346227e+18   \n",
       "\n",
       "                          id lang        Date      time     usedate  \\\n",
       "1147845  1317047077411737601   en  2020-10-16  10:17:47  2020-10-16   \n",
       "2318305  1361013406829060106   en  2021-02-14  18:04:17  2021-02-16   \n",
       "2772897  1318150624626790402   en  2020-10-19  11:22:53  2020-10-19   \n",
       "1952614  1272595399673630722   en  2020-06-15  18:22:41  2020-06-15   \n",
       "33341    1389114470304305154   en  2021-05-03  07:07:52  2021-05-03   \n",
       "...                      ...  ...         ...       ...         ...   \n",
       "1169957  1316312507431051264   en  2020-10-14  09:38:52  2020-10-14   \n",
       "2531839  1339593079318200320   en  2020-12-17  15:27:33  2020-12-17   \n",
       "1305376  1307074421098766336   en  2020-09-18  21:50:00  2020-09-18   \n",
       "1266310  1311853293589725184   ja  2020-10-02  02:19:32  2020-10-02   \n",
       "634525   1346226671293243393   en  2021-01-04  22:47:04  2021-01-04   \n",
       "\n",
       "           usedate1    usedate2    usedate3  ...       Volume      Open  \\\n",
       "1147845  2020-10-19  2020-10-20  2020-10-21  ...  115393800.0  121.2800   \n",
       "2318305  2021-02-17  2021-02-18  2021-02-19  ...   80576320.0  135.4900   \n",
       "2772897  2020-10-20  2020-10-21  2020-10-22  ...  120639300.0  119.9600   \n",
       "1952614  2020-06-16  2020-06-17  2020-06-18  ...  138808920.0   83.3125   \n",
       "33341    2021-05-04  2021-05-05  2021-05-06  ...   75135100.0  132.0400   \n",
       "...             ...         ...         ...  ...          ...       ...   \n",
       "1169957  2020-10-15  2020-10-16  2020-10-19  ...  151062300.0  121.0000   \n",
       "2531839  2020-12-18  2020-12-21  2020-12-22  ...   94359810.0  128.9000   \n",
       "1305376  2020-09-21  2020-09-22  2020-09-23  ...  287104900.0  110.4000   \n",
       "1266310  2020-10-05  2020-10-06  2020-10-07  ...  144712000.0  112.8900   \n",
       "634525   2021-01-05  2021-01-06  2021-01-07  ...  143301900.0  133.5200   \n",
       "\n",
       "             High      Low  Change  Change1  Change2  Change3  Change4  \\\n",
       "1147845  121.5480  118.810  -2.260   -3.980     1.31     0.20  -1.7000   \n",
       "2318305  136.0100  132.790  -2.300   -0.410     0.51    -0.37  -2.0100   \n",
       "2772897  120.4190  115.660  -3.980    1.310     0.20    -1.70  -1.3500   \n",
       "1952614   86.4200   83.145   2.435    0.155    -0.89     0.08  -1.2287   \n",
       "33341    134.0700  131.830   0.500   -3.340    -1.10     1.85  -0.6400   \n",
       "...           ...      ...     ...      ...      ...      ...      ...   \n",
       "1169957  123.0300  119.620   0.190    1.990    -2.26    -3.98   1.3100   \n",
       "2531839  129.5800  128.045  -0.200   -2.305     3.21     0.27  -1.2000   \n",
       "1305376  110.8800  106.090  -3.560    5.540    -0.87    -4.50   3.0500   \n",
       "1266310  115.3700  112.220   0.130    2.590    -2.54     0.46  -1.2800   \n",
       "634525   133.6116  126.760  -4.110    2.120    -1.12     2.56  -0.3800   \n",
       "\n",
       "         Change5  \n",
       "1147845  -1.3500  \n",
       "2318305   2.1000  \n",
       "2772897   1.0400  \n",
       "1952614   1.8825  \n",
       "33341    -2.5600  \n",
       "...          ...  \n",
       "1169957   0.2000  \n",
       "2531839   0.6500  \n",
       "1305376   3.8500  \n",
       "1266310   1.6900  \n",
       "634525   -0.2100  \n",
       "\n",
       "[501281 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.read_csv('mergedfullwithmoredates.csv')\n",
    "from sklearn.model_selection import train_test_split  \n",
    "mergedbig, mergedsmall = train_test_split(merged, test_size=0.15, random_state=0)\n",
    "# mergedsmall.to_csv(\"mergedsmall.csv\", index = False)\n",
    "# mergedsmall = pd.read_csv('mergedsmall.csv')\n",
    "merged = mergedsmall\n",
    "merged = merged.dropna(subset=['Change1','Change2','Change3','Change4','Change5'])\n",
    "# Obtaining the tweet contents into a list\n",
    "all_tweets = merged[\"text\"]\n",
    "all_tweets = all_tweets.to_list()\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemming(tweet):\n",
    "    a = word_tokenize(tweet)\n",
    "    answer = list(map(lambda x: lemmatizer.lemmatize(x), a))\n",
    "    return answer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surrounded-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "processed_tweets = []\n",
    "X = all_tweets\n",
    "for tweet in range(0, len(X)):  \n",
    "    \n",
    "    \n",
    "    processed_tweet = re.sub(r\"http\\S+\", \"\", str(X[tweet]))\n",
    "    # Replace all emojis with text\n",
    "    processed_tweet = emoji.demojize(processed_tweet)\n",
    "    # Remove all the special characters\n",
    "    processed_tweet = re.sub(r'\\W', ' ', processed_tweet)\n",
    "    \n",
    "#     processed_tweet = re.sub(r'http\\S+', '', processed_tweet)\n",
    "    \n",
    "    \n",
    "#     processed_tweet = re.sub(r'co\\S+', '', processed_tweet) \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    " \n",
    "    # Remove single characters from the start\n",
    "#     processed_tweet = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_tweet) \n",
    " \n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    " \n",
    "    # Removing prefixed 'b'\n",
    "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "    \n",
    "\n",
    "    \n",
    "    processed_tweet = re.sub(r'of|to|has|keep|ll', '', processed_tweet)\n",
    "    # Converting to Lowercase\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "    \n",
    "    processed_tweet = lemming(processed_tweet)\n",
    "    \n",
    "    processed_tweet = [word for word in processed_tweet if word not in stop_words]\n",
    "    \n",
    "    processed_tweet = TreebankWordDetokenizer().detokenize(processed_tweet)    \n",
    "    \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    processed_tweets.append(processed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "animated-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged[['Change','Change1','Change2','Change3','Change4','Change5','usedate','usedate1','usedate2','usedate3','usedate4','usedate5']]\n",
    "# X = df3\n",
    "# X = df2\n",
    "# X = df2array\n",
    "X = processed_tweets\n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spare-edmonton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m3.6967\u001b[0m        \u001b[32m3.6667\u001b[0m  93.3811\n",
      "      2        \u001b[36m3.6546\u001b[0m        \u001b[32m3.5696\u001b[0m  97.4661\n",
      "      3        \u001b[36m3.5588\u001b[0m        \u001b[32m3.4940\u001b[0m  97.6575\n",
      "      4        \u001b[36m3.5225\u001b[0m        \u001b[32m3.4771\u001b[0m  98.3332\n",
      "      5        \u001b[36m3.4968\u001b[0m        \u001b[32m3.4471\u001b[0m  98.1125\n",
      "      6        \u001b[36m3.4737\u001b[0m        \u001b[32m3.4397\u001b[0m  99.2393\n",
      "      7        \u001b[36m3.4536\u001b[0m        \u001b[32m3.4310\u001b[0m  99.6159\n",
      "      8        \u001b[36m3.4356\u001b[0m        \u001b[32m3.4187\u001b[0m  100.0694\n",
      "      9        \u001b[36m3.4185\u001b[0m        \u001b[32m3.4075\u001b[0m  100.8247\n",
      "     10        \u001b[36m3.4023\u001b[0m        \u001b[32m3.4035\u001b[0m  101.3559\n",
      "     11        \u001b[36m3.3865\u001b[0m        \u001b[32m3.3910\u001b[0m  100.8347\n",
      "     12        \u001b[36m3.3732\u001b[0m        \u001b[32m3.3846\u001b[0m  101.5290\n",
      "     13        \u001b[36m3.3604\u001b[0m        \u001b[32m3.3789\u001b[0m  101.4121\n",
      "     14        \u001b[36m3.3475\u001b[0m        3.3808  101.9255\n",
      "     15        \u001b[36m3.3358\u001b[0m        3.3832  101.8666\n",
      "     16        \u001b[36m3.3240\u001b[0m        3.3864  102.3681\n",
      "     17        \u001b[36m3.3124\u001b[0m        3.3840  102.7836\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "RMSE: 1.8437229\n"
     ]
    }
   ],
   "source": [
    "y_train2 = y_train['Change1']\n",
    "y_test2 = y_test['Change1']\n",
    "y_train2 = y_train2.values.reshape(-1,1)\n",
    "y_test2 = y_test2.values.reshape(-1,1)\n",
    "y_train2 = y_train2.astype(np.float32)\n",
    "y_test2 = y_test2.astype(np.float32)\n",
    "in_dimension = 5765\n",
    "hid_dimension = 160\n",
    "out_dimension = 1\n",
    "\n",
    "\n",
    "class PoleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dimension,hid_dimension)\n",
    "        self.fc2 = nn.Linear(hid_dimension,out_dimension)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        hidden = self.fc1(X)\n",
    "        hidden = self.sigmoid(hidden)\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "x_trainshape = 5765\n",
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=160,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(x_trainshape, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 160)\n",
    "        self.output = nn.Linear(160, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X\n",
    "\n",
    "pole_model = RegressorModule()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(pole_model.parameters(), lr = 0.1)\n",
    "optimum_params = {'net__lr': 0.0015539382932245303, 'net__max_epochs': 20, 'net__optimizer__momentum': 0.9375124227337543}\n",
    "net = NeuralNetRegressor(module=pole_model, max_epochs=optimum_params['net__max_epochs'], lr=optimum_params['net__lr'], optimizer__momentum=optimum_params['net__optimizer__momentum'], callbacks =[('earlystopping',EarlyStopping())])\n",
    "def typechange(x):\n",
    "    return x.astype(dtype = np.float32)\n",
    "typetransform = FunctionTransformer(typechange)\n",
    "def inputneuron(x):\n",
    "    x_trainshape = x.shape[1]\n",
    "#     return x_trainshape\n",
    "inputneuronnumber = FunctionTransformer(inputneuron)\n",
    "# pipe = Pipeline([('transform', DataFrameTransformer()),('net', net)])\n",
    "# pipe = Pipeline([('net', net)])\n",
    "pipe = Pipeline([(\"tfidf_vector_com\", TfidfVectorizer(tokenizer=identity_tokenizer, input=\"array\", lowercase=False, norm=\"l2\", max_features=None, sublinear_tf=True,token_pattern=r'[^\\s]+')), (\"typetransform\", typetransform), (\"net\", net)])\n",
    "\n",
    "\n",
    "# net = skorch.NeuralNetClassifier(module=PoleNN, max_epochs=20, lr=0.1, criterion=torch.nn.NLLLoss)\n",
    "pipe.fit(X=x_train, y=y_train2)\n",
    "y_pred = pipe.predict(x_test)\n",
    "rmse = mean_squared_error(y_test2, y_pred, squared = False)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "higher-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit: [793.101]\n",
      "Accuracy: 0.708502024291498\n",
      "Sum Invested: [381.49945]\n",
      "Profitability: [2.0789046]\n"
     ]
    }
   ],
   "source": [
    "modelpreds = y_pred\n",
    "y = y_test2\n",
    "z = y_test['usedate1']\n",
    "unique = z.unique()\n",
    "profit = 0\n",
    "bullorbearcount = 0\n",
    "invested = 0\n",
    "predsumlist = []\n",
    "realalist = []\n",
    "for uni in unique:\n",
    "    predsum = 0\n",
    "    reala = 0\n",
    "    predcount = 0\n",
    "    for i, (pred, real, date) in enumerate(zip(modelpreds, y, z)):\n",
    "        if date == uni:\n",
    "            predsum += pred\n",
    "            predcount += 1\n",
    "            reala = real\n",
    "    predsum = (predsum/predcount)*14.77377722861989\n",
    "    invested += abs(predsum)\n",
    "    daychange = predsum * reala\n",
    "    predsumlist.append(predsum)\n",
    "    realalist.append(reala)\n",
    "    profit += daychange\n",
    "    if predsum > 0 and reala > 0:\n",
    "        bullorbearcount += 1\n",
    "    elif predsum < 0 and reala < 0:\n",
    "        bullorbearcount += 1\n",
    "print(\"Profit:\", profit)\n",
    "print(\"Accuracy:\", (bullorbearcount/len(unique)))\n",
    "print(\"Sum Invested:\", invested)\n",
    "print(\"Profitability:\", (profit/invested))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "following-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv('mergedfullholdout.csv')\n",
    "merged = merged.dropna(subset=['Change1','Change2','Change3','Change4','Change5'])\n",
    "all_tweets = merged[\"text\"]\n",
    "all_tweets = all_tweets.to_list()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemming(tweet):\n",
    "    a = word_tokenize(tweet)\n",
    "    answer = list(map(lambda x: lemmatizer.lemmatize(x), a))\n",
    "    return answer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "# https://python.gotrained.com/scraping-tweets-sentiment-analysis/\n",
    "stop_words = set(stopwords.words('english'))\n",
    "processed_tweets = []\n",
    "X = all_tweets\n",
    "for tweet in range(0, len(X)):  \n",
    "    \n",
    "    processed_tweet = re.sub(r\"http\\S+\", \"\", str(X[tweet]))\n",
    "    # Replace all emojis with text\n",
    "    processed_tweet = emoji.demojize(processed_tweet)\n",
    "    # Remove all the special characters\n",
    "    processed_tweet = re.sub(r'\\W', ' ', processed_tweet)\n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    # Remove single characters from the start\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_tweet= re.sub(r'\\s+', ' ', processed_tweet, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    processed_tweet = re.sub(r'^b\\s+', '', processed_tweet)\n",
    "    processed_tweet = re.sub(r'of|to|has|keep|ll', '', processed_tweet)\n",
    "    # Converting to Lowercase\n",
    "    processed_tweet = processed_tweet.lower()\n",
    "    processed_tweet = lemming(processed_tweet)\n",
    "    processed_tweet = [word for word in processed_tweet if word not in stop_words]\n",
    "    processed_tweet = TreebankWordDetokenizer().detokenize(processed_tweet)    \n",
    "    \n",
    "    # remove all single characters\n",
    "    processed_tweet = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_tweet)\n",
    "    processed_tweets.append(processed_tweet)\n",
    "x_holdout = processed_tweets\n",
    "y_holdout = merged['Change1']\n",
    "y_holdout_dates = merged['usedate1']\n",
    "y_holdout = y_holdout.values.reshape(-1,1)\n",
    "y_holdout = y_holdout.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "emotional-martial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.401254\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_holdout= pipe.predict(x_holdout)\n",
    "rmse = mean_squared_error(y_holdout, y_pred_holdout, squared = False)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "romantic-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profit: [-6.8676763]\n",
      "Accuracy: 0.5\n",
      "Sum Invested: [17.5193]\n",
      "Profitability: [-0.3920063]\n"
     ]
    }
   ],
   "source": [
    "modelpreds = y_pred_holdout\n",
    "y = y_holdout\n",
    "z = y_holdout_dates\n",
    "unique = z.unique()\n",
    "profit = 0\n",
    "bullorbearcount = 0\n",
    "invested = 0\n",
    "predsumlist = []\n",
    "realalist = []\n",
    "for uni in unique:\n",
    "    predsum = 0\n",
    "    reala = 0\n",
    "    predcount = 0\n",
    "    for i, (pred, real, date) in enumerate(zip(modelpreds, y, z)):\n",
    "        if date == uni:`\n",
    "            predsum += pred\n",
    "            predcount += 1\n",
    "            reala = real\n",
    "    predsum = (predsum/predcount)*14.77377722861989\n",
    "    invested += abs(predsum)\n",
    "    daychange = predsum * reala\n",
    "    predsumlist.append(predsum)\n",
    "    realalist.append(reala)\n",
    "    profit += daychange\n",
    "    if predsum > 0 and reala > 0:\n",
    "        bullorbearcount += 1\n",
    "    elif predsum < 0 and reala < 0:\n",
    "        bullorbearcount += 1\n",
    "print(\"Profit:\", profit)\n",
    "print(\"Accuracy:\", (bullorbearcount/len(unique)))\n",
    "print(\"Sum Invested:\", invested)\n",
    "print(\"Profitability:\", (profit/invested))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-maximum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataSciEnv]",
   "language": "python",
   "name": "conda-env-DataSciEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
